{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This is the Master Process notebook for Lyrics Lab Project\n",
    "\n",
    "**Each referenced notebook offers more granular details, down to the actual code used to implement our designed processes**\n",
    "\n",
    "Please visit the [Lyrics Lab Website](http://michaeljohns.github.io/lyrics-lab/) to see and engage our most interesting discoveries. And check out our [2-minute video](https://vimeo.com/148576080) highlighting our process and findings.\n",
    "\n",
    "Also to learn more about the proposal which drove our goals, and some very early concepts of what we might implement -- along with an entrypoint to the code, visit the [Lyrics Lab Repository](../)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The more formal aspects of the Master Process notebook. [Lyrics Lab Website](http://michaeljohns.github.io/lyrics-lab) reflects a massive amount of work, we will not reproduce it in these notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Overview and Motivation\n",
    "**Provide an overview of the project goals and the motivation for it. Consider that this will be read by people who did not see your project proposal.**\n",
    "\n",
    "###Overview\n",
    "*Please reference [Overview](http://michaeljohns.github.io/lyrics-lab/#grp-overview) section of our website for the most up to date information.*\n",
    "\n",
    "###Motivation\n",
    "\n",
    "This project focused on the lyrics of songs that have been elevated into the popular consciousness, considering hits from this and previous decades. While music is often layered with context and nuanced with subtext, this project sought to uncover those themes and sentiments that both reflect and have served shape generations, to identify what is fleeting and what endures. \n",
    "\n",
    "Lyrics Lab employed powerful tools of data science to myriad experiences and ideals as articulated in lyrics, to approximate how they express what it means to be human. The project leveraged modern statistical, natural language processing, and machine learning techniques to accomplish our objectives. A guiding intuition to our approach was that vice and virtue are classifiable dividing lines in song lyrics among other enduring themes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Related Work\n",
    "**Anything that inspired you, such as a paper, a web site, or something we discussed in class.**\n",
    "\n",
    "It has long been recognized that studying a culture’s popular music can yield insight into its values and mood, but until recently analysis was confined to subjective examination of small samples. Over most of the history of cultural musicology, research was hampered by the lack of available data. And when songs themselves became data stored on Compact Discs, the computing power necessary to conduct analysis was being devoted to other uses. Only recently has the abundance of storage and computational capacity made it feasible to study music’s messages empirically.\n",
    "\n",
    "In recent years, considerable effort has been devoted to studying and classifying two of the three basic ingredients of music- tones and rhythms. *We propose to study the third one, words, which have received comparatively less attention*. In the 2008 Proceedings of the Association for Computational Linguistics Xia et al wrote “research efforts on lyric-based song classification are very few.” ([Sentiment Vector Space Model for Lyric-based Song Sentiment Classification](https://www.aclweb.org/anthology/P/P08/P08-2034.pdf), Proceedings of ACL 2008). Other representative papers include Zhong, et al (2012), [Music Sentiment Classification Integrating Audio with Lyrics](http://www.joics.com/publishedpapers/2012_9_1_35_44.pdf), JOICS 9:35. The most prominent work in empirical musicology to date is the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) which primarily contains features attributed to the tones and rhythms. The set does contain lyrics in reduced form, but not full text.\n",
    "\n",
    "We expect to apply the tools of machine learning to extract thematic content from the lyrics of popular songs in the United States and, if possible, internationally, reaching as far back in time as we can get usable data. We hope to find themes that change over time and correlate them with significant historical events. And if it goes better than we expect, we may be able to produce a classifier that can accept text and predict its genre and era.\n",
    "\n",
    "We have not yet found an existing study that assembles a large corpus of lyrics and classifies them based on their semantic content. Studying song lyrics is different than general sentiment analysis of, say, a culture’s literature. Lyrics can have attributes that would be out of place in literature or formal prose, such as repetition, rhyming, and rhythmic delivery. Moreover, one might speculate that lyrics may have a higher tendency to be formulaic or even clichéd, making them more amenable to pattern analysis than prose generally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initial Questions\n",
    "**What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis? - Data: Source, scraping method, cleanup, storage, etc.**\n",
    "\n",
    "**Here are primary questions Lyrics Lab identified to assist in answering:**\n",
    "* What are the topics raised within popular music? Are there any enduring topics?\n",
    "* When are select topics present? At what ranks? How long are they present?\n",
    "* Some genres of music are criticized for lack of depth (Rap, Pop, and others) while some have greater variation. Are those variations observable?\n",
    "* What artists, songs, and topics reflect vice? What reflect virtue? What is their sentiment towards vice/virtue?\n",
    "* Given any combination of artists, songs, and topics, what else might be of interest?\n",
    "\n",
    "**Here are secondary questions that Lyrics Lab would be potentially relevant to assist in answering:**\n",
    "* Given any song’s lyrics, how well might the song perform in select year? Given a sample of text, can we infer what genre it fits, and in what time period?\n",
    "* What topics has an artist expressed? Does an artist consistently express any topics?\n",
    "* What are topic preferences for a given geographic area?\n",
    "* Do musical trends correlate to select cultural trends? Do musical trends correlate to select historic / marked events? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exploratory Data Analysis\n",
    "**What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?**\n",
    "\n",
    "*A large number of exploratory visualizations can be reviewed within the [viz](../viz) folder, to include Tableau Workbooks that we employed for various exploration. Please review our website for final versions of data analysis in addition to the sub-notebooks presented later in this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Final Analysis: \n",
    "**What did you learn about the data? How did you answer the questions? How can you justify your answers?**\n",
    "\n",
    "*Please reference [Conclusion](http://michaeljohns.github.io/lyrics-lab/#grp-conclude) section of our website for the most up to date information.*\n",
    "\n",
    "###Here is our summary of how well we answered the questions\n",
    "\n",
    "**Here are primary guiding questions for the project which we approached to varying degrees of success:**\n",
    "\n",
    "* What are the topics raised within popular music? Are there any enduring topics?\n",
    "\n",
    "  * *We engaged this question but could have condensed topics down further for more thematic understanding.*\n",
    "\n",
    "* When are select topics present? At what ranks? How long are they present?\n",
    "\n",
    "  * *We engaged this question.*\n",
    "\n",
    "* Some genres of music are criticized for lack of depth (Rap, Pop, and others) while some have greater variation. Are those variations observable?\n",
    "\n",
    "  * *We were not able to engage this question at a granular level.*\n",
    "\n",
    "* What artists, songs, and topics reflect vice? What reflect virtue? What is their sentiment towards vice/virtue?\n",
    "\n",
    "  * *We engaged this question from the offensive word analysis but were not able to pivot further towards more thematic vice / virtue clustering.*\n",
    "\n",
    "* Given any combination of artists, songs, and topics, what else might be of interest?\n",
    "\n",
    "  * *We were not able to explore recommenders.*\n",
    "\n",
    "**Here are secondary questions, some of which the project assisted in answering:**\n",
    "\n",
    "* Given any song’s lyrics, how well might the song perform in select year? Given a sample of text, can we infer what genre it fits, and in what time period?\n",
    "\n",
    "  * *We focused on position and genre prediction but did not infer time period.*\n",
    "\n",
    "* What topics has an artist expressed? Does an artist consistently express any topics? \n",
    "\n",
    "  * *We took a broad view on artist topics.*\n",
    "\n",
    "* What are topic preferences for a given geographic area? \n",
    "\n",
    "  * *We did not engage this question.*\n",
    "\n",
    "* Do musical trends correlate to select cultural trends? Do musical trends correlate to select historic / marked events? \n",
    "\n",
    "  * *We did not engage this question.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The following is a light summary of multi-step processing, notably Data Conditioning and Harvesting as well as NLP Part of Speech Tagging and Vocabulary Generation. All notebooks used in our exploration, data processing, analysis, and visualization are linked for contextual reference.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-1: Data Conditioning\n",
    "\n",
    "All referenced artifacts for this section are within [data](../data) folder. Given some GitHub quirks handling relative urls, it may be easier to navigate the hierarchy directly after reading this summary.\n",
    "\n",
    "**The master dataframe used in analysis which is the consolidation of harvesting efforts can be found at [use-this-master-lyricsdf-extracted.csv](../data/conditioned/use-this-master-lyricsdf-extracted.csv)**\n",
    "\n",
    "###Exploration\n",
    "All Data Conditioning Notebook combined or extended lessons learned from [Data-Exploration Notebook](mj/Data-Exploration.ipynb) and [Process-Missing-Lyrics Notebook](mj/Process-Missing-Lyrics.ipynb) to accomplish the finalized conditioning.\n",
    "\n",
    "\n",
    "### Provided Data\n",
    "\n",
    "1. We were able to integrate Billboard Top 100 chart data from [HW1](https://github.com/cs109-students/michaeljohns-2015hw/tree/hw1) **Note: HW1 only considered 1992-2014 (we are using 1970+), so it is a separate integration for specialized use in analysis**\n",
    "  1. The output of HW1 has been placed in [hw1-largedf.csv](../data/provided/hw1-largedf.csv)\n",
    "  1. The integration of our processing pipeline with hw1 (inner join) is at [master-lyricsdf-genre_inner.csv](../data/conditioned/master-lyricsdf-genre_inner.csv)\n",
    "1. We were also able to locate some partial data from a student named Samantha Stephens at [HEC Paris](http://www.hec.edu/) who is doing her dissertation on environmental messages put forward by various artists, considering their lyrics:\n",
    "  1. [lyrics from 1970 - 2014](../data/provided/all%20billboard%20top%20100%20songs%20from%201970-2014.xlsx)\n",
    "  1. [key artist popular music](../data/provided/Individual%20Artists%20Data.xlsx)\n",
    "\n",
    "### Harvested Data\n",
    "\n",
    "1. pipeline process implemented to leverage api from lyrics.wikia for song lyrics both abstracts (suitable for partial display to users) and full (suitable for processing needs)\n",
    "    1. URL e.g. [Paul Simon's \"Bridge Over Troubled Water](http://lyrics.wikia.com/wiki/Paul_Simon:Bridge_Over_Troubled_Water)\n",
    "    1. API Metadata e.g. [Joe Bonamassa's \"So Many Roads\"](http://lyrics.wikia.com/api.php?action=lyrics&artist=Joe%20Bonamassa&song=So%20Many%20Roads&fmt=json)  \n",
    "1. maintain the following from initial [lyrics from 1970 - 2014](../data/provided/all%20billboard%20top%20100%20songs%20from%201970-2014.csv) (which was provided): `postion`, `year`, `title`, `artist`, `title.href` (wikipedia)\n",
    "1. Add the derived columns `decade` and `song_key`\n",
    "\n",
    "Pipeline Notebooks:\n",
    "* [Lyrics-Metadata-Processing Notebook](mj/Lyrics-Metadata-Processing Notebook): resulted in a master dataframe exported to [master-lyricsdf.csv](../data/condititioned/archive/master-lyricsdf.csv) populated with automated `lyrics_url` and `lyrics_abstract` from lyrics.wikia api (prior to full lyric harvesting).\n",
    "* [Lyrics-Raw-Harvesting Notebook](mj/Lyrics-Raw-Harvesting.ipynb): full lyrics harvesting from `lyrics_url` using a caching strategy to support interrupted and ad-hoc processing.\n",
    "* [Lyrics-Extraction Notebook](mj/Lyrics-Extraction.ipynb): generating and integrating the final lyric corpus and additional cleanup and consolidation, resulting in [use-this-master-lyricsdf-extracted.csv](../data/conditioned/use-this-master-lyricsdf-extracted.csv)\n",
    "\n",
    "Here are the rules followed to obtain the final lyric \"master\" corpus to maximize available data:\n",
    "* if a cached lyric extraction is available (i.e. from lyrics.wikia), it goes into df['lyrics']\n",
    "* else if existing df['lyrics'] is valid (i.e. from provided lyrics), it is the keeper\n",
    "* else if df['lyric_abstract'] is valid (i.e. the first 280 chars from lyrics.wikia api), it goes into df ['lyrics']\n",
    "\n",
    "Additional notes:\n",
    "* 20 songs are instrumentals and have no lyrics.\n",
    "* 36 songs have licensing restrictions identified by lyrics.wikia API, which we respected, of course.\n",
    "* 103 songs ended up with no available lyrics on lyrics.wikia or from our provided data.\n",
    "* Similar rules as used in conditioning to best full lyrics were applied to have the best lyric abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-2: Artists\n",
    "\n",
    "### Notebook(s)\n",
    "* [Metadata](kb/metadata.ipynb)\n",
    "* [Wordclouds Notebook](ss/Word_Clouds.ipynb)\n",
    "\n",
    "### Details\n",
    "\n",
    "####Metadata\n",
    "\n",
    "Metadata notebook is used to calculate a variety of descriptive statistics and facts about the corpus. Some insights include songs that span multiple years, covers, most popular song names, top performing artists overall, and top performing artists of each year.\n",
    "\n",
    "####Wordclouds\n",
    "\n",
    "Wordclouds are used to obtain an admittedly superficial overview of the data and in particular its differences across time and genre. There is, of course, considerable controversy over the utility of word clouds, because they leave behind so much information and risk the presentation of false equivalencies. For that reason we would [not expect to see wordclouds in the New York Times](http://www.niemanlab.org/2011/10/word-clouds-considered-harmful/) which argues they are actually \"harmful,\" but others have argued that when properly used, wordclouds can offer some useful insight. In particular, Elijah Meeks of Netflix argues that wordclouds are [naturally suited to interpretation of topic modeling processes](https://dhs.stanford.edu/algorithmic-literacy/using-word-clouds-for-topic-modeling-results/). We use wordclouds to establish a heuristic baseline for inquiry into semantic content: will our more advanced analytical methods reveal more insight than just assessing which words are used most often?  First, we partition the data by decade and then by genre, displaying unadorned word clouds using the library graciously published by Andreas Mueller at https://github.com/amueller/word_cloud. Since we are only interested in exploratory use at this point, there is no need to use the visually richer d3-based visualizations based on the work of [Jason Davies](https://www.jasondavies.com/) at https://github.com/jasondavies/d3-cloud. \n",
    "\n",
    "After running the LDA analyses on uses   the sample according to decade and genre, we will return to wordcloud to explore the Meeks hypothesis that wordclouds are useful for topic interpretation, comparing their value to the more straightforward ocular inspection technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-3: Word Use\n",
    "\n",
    "### Notebook(s)\n",
    "* [Lexical-Diversity Notebook](ss/LexicalDiversity.ipynb)\n",
    "\n",
    "### Details\n",
    "This notebook compiles some basic descriptive statistics to use as a backdrop for the sentiment analysis: \n",
    "* word counts as a proxy for song length\n",
    "* word repetition as the inverse of lexical diversity\n",
    "\n",
    "It starts with the standard library loads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-4: NLP and Vocab Conditioning \n",
    "\n",
    "### Notebook(s)\n",
    "* [Vocab-Consolidation Notebook](mj/Vocab-Consolidation.ipynb)\n",
    "* [Vocab-Shrunk Notebook](mj/Vocab-Shrunk.ipynb)\n",
    "\n",
    "### Details\n",
    "\n",
    "**Adapted concepts from [HW1](https://github.com/cs109-students/michaeljohns-2015hw/blob/hw1/hw1.ipynb) and [HW5 Part1](https://github.com/cs109-students/michaeljohns-2015hw/blob/hw5/hw5part1.ipynb)**\n",
    "\n",
    "* Vocab-Consolidation-Notebook -- The following artifacts will be established by manipulating the output of the processing pipeline for harvesting data, file [use-this-master-lyricsdf-extracted.csv](../../data/conditioned/use-this-master-lyricsdf-extracted.csv):\n",
    "  * vocabs for noun and adj\n",
    "  * n-gram for noun and adj\n",
    "  * synonyms for noun and adj\n",
    "  * hypernyms for noun and adj\n",
    "\n",
    "**Note: Vocab-Consolidation requires Spark and is run under Vagrant.**\n",
    "\n",
    "* Vocab-Shrunk -- This notebook will go through a series of shrinking efforts beginning with the noun and adjective reduced vocabs. It will first consider synonyms and the shrinkage effects. It will then work from the initial shrunken result to consider hypernyms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-5: Offensive Word Use\n",
    "\n",
    "### Notebook(s)\n",
    "* [Profanity-Extraction Notebook](mj/Profanity-Extraction.ipynb)\n",
    "\n",
    "### Details\n",
    "\n",
    "Extract counts of profanity per decade and first mentions of offensive words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-6: Topic Modeling\n",
    "\n",
    "### Notebook(s)\n",
    "* [LDA-LSI Notebook](ss/LDA-LSI.ipynb)\n",
    "* [Get-Genres](ss/GetGenres.ipynb)\n",
    "* [Genre-LDA-LSI Notebook](ss/Genre-LSI-LDA.ipynb)\n",
    "\n",
    "### Details\n",
    "In this part, the LSI and LDA methods of gensim are applied to subsets of the database. Because the sample sizes are necessarily smaller, some reduction in both the number of topics and the number of genres is necessary. By requiring the minimum number of document per genre to be at least 240 and by estimating 200 rather than 300 topics for the LSI, the overfitting potential is decreased. For LDA the number of topics extracted remains at 80. \n",
    "\n",
    "As usual, the programming starts with including ibraries. \n",
    "\n",
    "**Note: this book requires Spark and is run under Vagrant.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part-7: Prediction\n",
    "\n",
    "###Top 50 / Bottom 50 Prediction\n",
    "\n",
    "####Notebook(s)\n",
    "* [Vector-Ensemble Notebook](mj/Vector-Ensemble.ipynb)\n",
    "\n",
    "####Details\n",
    "This notebook leverages the consolidated vector CSV which includes normal, synonym, and hypernym vectors, see [master-lyricsdf-word_syn_hype_vectors.csv](../data/conditioned/master-lyricsdf-word_syn_hype_vectors.csv)\n",
    "\n",
    "While we understand that a song’s lyrics are not generally causal to where a given song might land on the charts, we had a hunch that there might at least be a correlation between a song’s position and its lyric content that we could model, train, and ultimately do some prediction. Having already explored Topic Modeling with Latent Factors as shown in the previous section, we wanted to separately focus on supervised learning techniques that would be more readily interpretable. Ultimately, we landed on predicting the ‘Top 50 versus Bottom 50’ positions on the 2014 charts, a balanced set of positives and negatives, also offering a binary prediction, where positives values indicate ‘In the Top 50’ and negative values indicate ‘In the Bottom 50’. We also wanted to again leverage the cluster computing framework Spark as we had used previously in establishing the Vocabularies. For prediction, we were interested in its Machine Learning APIs. After some trial, error, and tuning, we used Spark’s Pipeline API to apply Logistic Regression learning algorithm, or estimator, which turned out to be a solid choice for this exploration as it favors binary, balanced data. More in-depth information for our approach and results can be found at Vector Ensemble Notebook in addition to more cursory information in the project Master Process Notebook.\n",
    "\n",
    "First, we tuned and fit models against noun vectors derived from all 3 Vocabularies — Initial, Shrunken-1, and Shrunken-2 — training on all data from 1970-2013 using the tuned hyperparameters. Then we predicted ‘Top 50 versus Bottom 50’ exclusively for 2014 using the same models derived from the 3 vocabularies.\n",
    "\n",
    "At least to the degree that lyrics and position are correlated, the results of predicting the top / bottom splits are consistent with our intuitions. Initial vocabulary (vectorized to allow only each unique noun 1x max per song) was the least performant, slightly improved upon by model fit to Shrunken-1 (nouns with synonym replacement, also vectorized using same reduction rules as Initial), then a significant performance gain realized by Shrunken-2 noun vocabulary (synonyms with hypernym replacement, vectorized using same rules). Shrunken-2 correctly predicted 58 of 95 non-empty lyrics in 2014.\n",
    "\n",
    "**Note: this book requires Spark and is run under Vagrant.**\n",
    "\n",
    "###Phrase to Genre Prediction\n",
    "####Notebook(s)\n",
    "* [Positive-Naive-Bayes-Classifier Notebook](ss/PositiveNaiveBayesClassifier.ipynb)\n",
    "\n",
    "####Details\n",
    "##### Positive Naive Bayes Classification \n",
    "\n",
    "A song can fit in more than one genre, and our conditioning of the data has been attentive to preserving the one-to-potentially-many relationship. In this part, a classifier develops a probability that a given body of text will fit within each of the top ten selected genres. It uses the nltk positive naive Bayes classifier to train a set of lyrics for each of the top 15 genres, using 80% of the data. It assigns uniform priors at various levels, then priors based on the relative frequency of songs. \n",
    "\n",
    "This process builds 15 distinct, independent classifiers, and then chooses a randome sentence from each song in the testing set, submitting it to each classifier, which returns True if the classifier predicts that the sentence is a member of the associated genre, and False otherwise. Thus, any body of text submitted to it could result in a prediction of zero, one, or up to 15 genre memberships.\n",
    "\n",
    "The numbers of true and false positives and negatives are accumulated, and the results are expressed as (true positives plus true negatives) / total observations.  To test whether the classifiers comport with our subjective understanding of what sentences are likey to be in which genres of music, at the end of the notebook the classifers are exposed to entry of arbitrary text which returns the predicted genre(s).\n",
    "\n",
    "The process does not use cross-validation because the nltk PositiveNaiveBayesClassifier does not expose any regularization parameters; the only parameter it accepts is a prior. The theoretically most appropriate prior to use for each genre is the genre's relative frequency in  the training set; the classifier is run against the testing set using other values for the prior only to gauge whether the theoretically chosen prior is at least as good as arbitrarily chosen values. The series of procedures suggest that it is.   \n",
    "\n",
    "### The real value of this classfier battery, however, is in how it performs in action, assessed subjectively.  To enter arbitrary text and see what (if any) genres it matches, run this notebook (Cell->Run All) and then go to the last cell.  The classifier battery takes about ten minutes to train, but then each text input is processed very quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
