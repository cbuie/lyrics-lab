{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Profanity Extraction Notebook\n",
    "Extract counts of profanity per decade. The output of this notebook will be used for Tableau Vizualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Profanity Words\n",
    "**These are words with more direct offensive meaning used 5 or more times throughout the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the offensive dataframe pulled from the master\n",
    "offensivedf = pd.read_csv(\"../../data/conditioned/noun_n-gram_offensive.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensivedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>niggas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>ho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>booty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "      <td>pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>bone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>hoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>pimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>motherfucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>niggaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>butt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>pimpin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>bullshit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>titty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>whore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count          word\n",
       "0     143          shit\n",
       "1     134         bitch\n",
       "2     128           ass\n",
       "3     127         nigga\n",
       "4      50        niggas\n",
       "5      40          dick\n",
       "6      35            ho\n",
       "7      30         booty\n",
       "8      28         pussy\n",
       "9      24          bone\n",
       "10     23           hoe\n",
       "11     22          pimp\n",
       "12     20  motherfucker\n",
       "13     19        niggaz\n",
       "14     16          butt\n",
       "15     13        pimpin\n",
       "16      9      bullshit\n",
       "17      7          cock\n",
       "18      6         titty\n",
       "19      5         whore"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensivedf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensives = offensivedf['word'].values\n",
    "len(offensives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print \"{}\".format(('butt' in offensives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a structure for computing profanity\n",
    "ncomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for x in offensives:    \n",
    "    ncomp[x]=[0,0,0,0,0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each word\n",
    "\n",
    "def populateDecadeWords(comp,decade,json_name):\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # change root in for decade\n",
    "    drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "    \n",
    "    # read to json\n",
    "    with open(drootin + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    #set decade value for each in j\n",
    "    for x in j:\n",
    "        if x[0] in comp:\n",
    "            comp[x[0]][didx] = x[1]\n",
    "    \n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ncomp for nouns\n",
    "for d in decades:\n",
    "    ncomp = populateDecadeWords(ncomp,d,'noun_n-gram_reduced.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass\n",
      "[0, 1, 32, 68, 27]\n"
     ]
    }
   ],
   "source": [
    "#verify ncomp\n",
    "print ncomp.keys()[0]\n",
    "print ncomp[ncomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate a column full of a given decades values from a comp\n",
    "def compCol(comp,decade):\n",
    "    didx = decades.index(decade)\n",
    "    vs = []\n",
    "    for k,v in comp.iteritems():\n",
    "        vs.append(v[didx])\n",
    "        \n",
    "    return vs\n",
    "\n",
    "# function to convert comp to dataframe and save\n",
    "def compToDataframe(comp):\n",
    "    d = {'word': listAsAscii(comp.keys())}\n",
    "    \n",
    "    for decade in decades:\n",
    "        d[str(decade)] = compCol(comp,decade)\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncompdf = compToDataframe(ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>booty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>pimpin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>pimp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010    word\n",
       "0     0     1    32    68    27     ass\n",
       "1     0     0    37    58    32   nigga\n",
       "2     1     0    10    15     4   booty\n",
       "3     0     0     1    11     1  pimpin\n",
       "4     0     0     6    14     2    pimp"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncompdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Profanity Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ncompdf\n",
    "dataframeToCsv(ncompdf,'noun_decade_offensives_reduced.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
