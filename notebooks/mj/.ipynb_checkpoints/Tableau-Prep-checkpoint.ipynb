{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tableau Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to sort dataframe decsending is the default\n",
    "def sortDataframe(df,sort_col,ascending=False):\n",
    "    return df.sort(columns=sort_col, ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading list of list pairs json to columnar dataframe\n",
    "def jsonListOfPairListsToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    keys = []\n",
    "    values = []\n",
    "    for x in j:\n",
    "        keys.append(x[0])\n",
    "        values.append(x[1])\n",
    "        \n",
    "    d = {key_col_label: listAsAscii(keys), val_col_label: listAsAscii(values)}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json dict to csv\n",
    "def jsonDictToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonDictToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                             root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for json list of lists containing 2 entries to csv\n",
    "def jsonListOfPairListsToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonListOfPairListsToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                                        root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##N-Gram (Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=None #this will get set for each conversion\n",
    "key_col_label = \"word\" #this will not change for n-gram\n",
    "val_col_label = \"count\" #this will not change for n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name=\"noun-n-gram\"\n",
    "nngramdf = jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noun n-gram](../../viz/noun_n-gram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=\"adj-n-gram\"\n",
    "angramdf = jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![adjective n-gram](../../viz/adj_n-gram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##N-Gram (Reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name=\"noun_n-gram_reduced\"\n",
    "nngramreducedf = jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noun n-gram reduced](../../viz/noun_n-gram_reduced.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name=\"adj_n-gram_reduced\"\n",
    "angramreducedf = jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![adjective n-gram reduced](../../viz/noun_n-gram_reduced.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combine n-gram with n-gram reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramreducedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nngramjoindf = nngramdf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nngramjoindf['rcount'] = nngramreducedf['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>rcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>2390</td>\n",
       "      <td>love</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1665</td>\n",
       "      <td>baby</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1583</td>\n",
       "      <td>girl</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1544</td>\n",
       "      <td>time</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1097</td>\n",
       "      <td>thing</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   word  rcount\n",
       "1389   2390   love     788\n",
       "4006   1665   baby     731\n",
       "1649   1583   girl     629\n",
       "1218   1544   time     567\n",
       "1709   1097  thing     533"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramjoindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(nngramjoindf,'noun_n-grams_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3379, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angramdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3379, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angramreducedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angramjoindf = angramdf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angramjoindf['rcount'] = angramreducedf['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>rcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>2390</td>\n",
       "      <td>love</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1665</td>\n",
       "      <td>baby</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1583</td>\n",
       "      <td>girl</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1544</td>\n",
       "      <td>time</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1097</td>\n",
       "      <td>thing</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   word  rcount\n",
       "1389   2390   love     788\n",
       "4006   1665   baby     731\n",
       "1649   1583   girl     629\n",
       "1218   1544   time     567\n",
       "1709   1097  thing     533"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramjoindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(angramjoindf,'adj_n-grams_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decades (CSV Generation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]\n",
    "\n",
    "def makeDecadeCsvs(decade):\n",
    "    # change root in for decade\n",
    "    drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "    drootout = root_out+\"decades/\"+str(decade)+\"/\"\n",
    "    \n",
    "    assureDirExists(drootout)\n",
    "    \n",
    "    for name in [\"noun-n-gram\",\"adj-n-gram\"]:\n",
    "        jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, \n",
    "                      sort_col=val_col_label, root_in=drootin, root_out=drootout)\n",
    "    \n",
    "    for name in [\"noun_n-gram_reduced\",\"adj_n-gram_reduced\"]:\n",
    "        jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                      sort_col=val_col_label, root_in=drootin, root_out=drootout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in decades:\n",
    "    makeDecadeCsvs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Comparison across Decades\n",
    "Compare n-grams over decades by counting appearance of words over each decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load master noun and adj dict\n",
    "with open(root_in + 'noun_n-gram_reduced.json', 'r') as fp:\n",
    "    noun_ngram_reduced = json.load(fp)\n",
    "    \n",
    "with open(root_in + 'adj_n-gram_reduced.json', 'r') as fp:\n",
    "    adj_ngram_reduced = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5144"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_ngram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'jockin', 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_ngram_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3379"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_ngram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'suicidal', 2]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_ngram_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up a structure for each \n",
    "\n",
    "ncomp = {}\n",
    "acomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for x in noun_ngram_reduced:    \n",
    "    ncomp[x[0]]=[0,0,0,0,0]\n",
    "\n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for x in adj_ngram_reduced:\n",
    "    acomp[x[0]]=[0,0,0,0,0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each word\n",
    "\n",
    "def populateDecadeWords(comp,decade,json_name):\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # change root in for decade\n",
    "    drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "    \n",
    "    # read to json\n",
    "    with open(drootin + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    #set decade value for each in j\n",
    "    for x in j:\n",
    "        comp[x[0]][didx] = x[1]\n",
    "    \n",
    "    return comp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ncomp for nouns\n",
    "for d in decades:\n",
    "    ncomp = populateDecadeWords(ncomp,d,'noun_n-gram_reduced.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jockin\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify ncomp\n",
    "print ncomp.keys()[0]\n",
    "print ncomp[ncomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# acomp for adjs\n",
    "for d in decades:\n",
    "    acomp = populateDecadeWords(acomp,d,'adj_n-gram_reduced.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limited\n",
      "[0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#verify acomp\n",
    "print acomp.keys()[0]\n",
    "print acomp[acomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate a column full of a given decades values from a comp\n",
    "def compCol(comp,decade):\n",
    "    didx = decades.index(decade)\n",
    "    vs = []\n",
    "    for k,v in comp.iteritems():\n",
    "        vs.append(v[didx])\n",
    "        \n",
    "    return vs\n",
    "\n",
    "# function to convert comp to dataframe and save\n",
    "def compToDataframe(comp):\n",
    "    d = {'word': listAsAscii(comp.keys())}\n",
    "    \n",
    "    for decade in decades:\n",
    "        d[str(decade)] = compCol(comp,decade)\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncompdf = compToDataframe(ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jockin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>girl(oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sleet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010     word\n",
       "0     0     0     1     0     0   jockin\n",
       "1     0     0     0     1     0   inning\n",
       "2     0     0     1     0     0  girl(oh\n",
       "3     1     1     1     2     1   yellow\n",
       "4     1     0     0     0     0    sleet"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncompdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acompdf = compToDataframe(acomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>our-our-our-ou-ou-ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ri-dic-dic-dic-ulous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010                    word\n",
       "0     0     0     0     1     1                 limited\n",
       "1     0     0     0     0     1  our-our-our-ou-ou-ours\n",
       "2     0     0     1     1     0                suicidal\n",
       "3     0     0     0     1     0    ri-dic-dic-dic-ulous\n",
       "4     0     0     1     2     0                 dynamic"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acompdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Comp to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ncompdf\n",
    "dataframeToCsv(ncompdf,'noun_decade_comp_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# acompdf\n",
    "dataframeToCsv(acompdf,'adj_decade_comp_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word-Counts for Appearances in 1 or more decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countAppearances(comp):\n",
    "    \n",
    "    spanning_dict = {}\n",
    "    spanning_count_dict = {}\n",
    "    \n",
    "    #init\n",
    "    for x in range(0,6):\n",
    "        spanning_dict['spanning-'+str(x)] = []\n",
    "        spanning_count_dict['spanning-'+str(x)] = {}\n",
    "    \n",
    "    print \"len spanning and spanning count dicts --> \", len(spanning_dict)    \n",
    "    \n",
    "    word_count_dict = {} # hold raw word counts\n",
    "    \n",
    "    # build up decade spanning words (1-5)\n",
    "    # keept track of counts\n",
    "    for word,decades in comp.iteritems():\n",
    "        c = 0\n",
    "        for dc in decades:\n",
    "            if dc: #meaning, if the value is > 0\n",
    "                c += 1\n",
    "                # keep track of actual total use of word\n",
    "                if word in word_count_dict:\n",
    "                    word_count_dict[word] += dc\n",
    "                else:\n",
    "                    word_count_dict[word] = dc\n",
    "                    \n",
    "        spanning_dict['spanning-'+str(c)].append(word)\n",
    "            \n",
    "    # get the 5 decade counts right for sorting\n",
    "    for sk,sv in spanning_dict.iteritems():\n",
    "        for v in sv:\n",
    "            spanning_count_dict[sk][v] = word_count_dict[v]\n",
    "        \n",
    "    return spanning_dict, spanning_count_dict, word_count_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len spanning and spanning count dicts -->  6\n"
     ]
    }
   ],
   "source": [
    "ncs = countAppearances(ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'air': 55,\n",
       " u'angel': 25,\n",
       " u'answer': 18,\n",
       " u'anybody': 18,\n",
       " u'arm': 90,\n",
       " u'babe': 54,\n",
       " u'baby': 629,\n",
       " u'ball': 27,\n",
       " u'band': 22,\n",
       " u'bar': 44,\n",
       " u'beach': 16,\n",
       " u'beat': 52,\n",
       " u'beating': 13,\n",
       " u'beauty': 18,\n",
       " u'bed': 47,\n",
       " u'beer': 18,\n",
       " u'bird': 25,\n",
       " u'bit': 124,\n",
       " u'blast': 10,\n",
       " u'block': 30,\n",
       " u'blood': 26,\n",
       " u'blow': 33,\n",
       " u'blue': 41,\n",
       " u'board': 9,\n",
       " u'body': 145,\n",
       " u'bone': 24,\n",
       " u'book': 18,\n",
       " u'boot': 16,\n",
       " u'bottle': 35,\n",
       " u'bout': 93,\n",
       " u'boy': 283,\n",
       " u'brain': 29,\n",
       " u'brand': 80,\n",
       " u'bread': 13,\n",
       " u'break': 27,\n",
       " u'breath': 26,\n",
       " u'breeze': 19,\n",
       " u'brother': 47,\n",
       " u'bunch': 10,\n",
       " u'burning': 10,\n",
       " u'bus': 10,\n",
       " u'business': 15,\n",
       " u'cab': 5,\n",
       " u'candle': 9,\n",
       " u'car': 104,\n",
       " u'card': 11,\n",
       " u'care': 16,\n",
       " u'case': 31,\n",
       " u'cat': 41,\n",
       " u'cause': 285,\n",
       " u'chance': 66,\n",
       " u'change': 46,\n",
       " u'chick': 65,\n",
       " u'child': 73,\n",
       " u'circle': 10,\n",
       " u'city': 54,\n",
       " u'clock': 11,\n",
       " u'clothe': 40,\n",
       " u'cloud': 20,\n",
       " u'clown': 7,\n",
       " u'coffee': 8,\n",
       " u'cold': 32,\n",
       " u'color': 23,\n",
       " u'come': 15,\n",
       " u'control': 33,\n",
       " u'conversation': 21,\n",
       " u'cool': 25,\n",
       " u'corner': 25,\n",
       " u'country': 17,\n",
       " u'cousin': 6,\n",
       " u'crowd': 20,\n",
       " u'cup': 31,\n",
       " u'da': 26,\n",
       " u'daddy': 42,\n",
       " u'damn': 25,\n",
       " u'dance': 82,\n",
       " u'dancing': 30,\n",
       " u'darlin': 19,\n",
       " u'dawn': 12,\n",
       " u'day': 396,\n",
       " u'deal': 22,\n",
       " u'diamond': 43,\n",
       " u'difference': 7,\n",
       " u'dime': 20,\n",
       " u'dip': 16,\n",
       " u'distance': 10,\n",
       " u'dog': 34,\n",
       " u'doll': 5,\n",
       " u'dollar': 26,\n",
       " u'door': 107,\n",
       " u'doubt': 21,\n",
       " u'dream': 239,\n",
       " u'dress': 30,\n",
       " u'drink': 33,\n",
       " u'drive': 20,\n",
       " u'drop': 47,\n",
       " u'dude': 27,\n",
       " u'emotion': 29,\n",
       " u'end': 52,\n",
       " u'everybody': 116,\n",
       " u'eye': 291,\n",
       " u'face': 123,\n",
       " u'fact': 32,\n",
       " u'faith': 18,\n",
       " u'fall': 19,\n",
       " u'fallin': 8,\n",
       " u'family': 25,\n",
       " u'fantasy': 23,\n",
       " u'fast': 9,\n",
       " u'father': 16,\n",
       " u'fear': 30,\n",
       " u'feel': 32,\n",
       " u'feelin': 53,\n",
       " u'feeling': 96,\n",
       " u'fella': 12,\n",
       " u'field': 15,\n",
       " u'fight': 39,\n",
       " u'finger': 37,\n",
       " u'flame': 19,\n",
       " u'flash': 11,\n",
       " u'floor': 59,\n",
       " u'flow': 32,\n",
       " u'flower': 22,\n",
       " u'fool': 61,\n",
       " u'foot': 72,\n",
       " u'freedom': 10,\n",
       " u'friend': 196,\n",
       " u'fun': 47,\n",
       " u'future': 19,\n",
       " u'game': 136,\n",
       " u'gate': 10,\n",
       " u'girl': 567,\n",
       " u'girlfriend': 17,\n",
       " u'glass': 36,\n",
       " u'glow': 9,\n",
       " u'god': 17,\n",
       " u'gold': 36,\n",
       " u'goodbye': 37,\n",
       " u'grass': 24,\n",
       " u'groove': 27,\n",
       " u'ground': 41,\n",
       " u'gun': 44,\n",
       " u'guy': 67,\n",
       " u'hair': 86,\n",
       " u'half': 32,\n",
       " u'hand': 175,\n",
       " u'hard': 12,\n",
       " u'hat': 15,\n",
       " u'head': 120,\n",
       " u'heart': 373,\n",
       " u'heaven': 49,\n",
       " u'heel': 23,\n",
       " u'hell': 49,\n",
       " u'help': 16,\n",
       " u'highway': 14,\n",
       " u'home': 156,\n",
       " u'honey': 39,\n",
       " u'hoo': 9,\n",
       " u'hop': 12,\n",
       " u'hope': 22,\n",
       " u'horse': 17,\n",
       " u'hour': 34,\n",
       " u'house': 57,\n",
       " u'ice': 35,\n",
       " u'inside': 87,\n",
       " u'jean': 57,\n",
       " u'jet': 15,\n",
       " u'job': 28,\n",
       " u'jump': 12,\n",
       " u'key': 27,\n",
       " u'kick': 21,\n",
       " u'kid': 61,\n",
       " u'kind': 97,\n",
       " u'kiss': 112,\n",
       " u'knee': 30,\n",
       " u'lady': 115,\n",
       " u'land': 35,\n",
       " u'leaf': 14,\n",
       " u'leg': 23,\n",
       " u'let': 62,\n",
       " u'letter': 21,\n",
       " u'lie': 15,\n",
       " u'life': 378,\n",
       " u'light': 154,\n",
       " u'line': 85,\n",
       " u'lip': 54,\n",
       " u'livin': 49,\n",
       " u'lock': 14,\n",
       " u'look': 43,\n",
       " u'loser': 9,\n",
       " u'lot': 64,\n",
       " u'loud': 6,\n",
       " u'love': 788,\n",
       " u'lover': 79,\n",
       " u'luck': 26,\n",
       " u'lyin': 11,\n",
       " u'make': 44,\n",
       " u'mama': 68,\n",
       " u'man': 449,\n",
       " u'matter': 24,\n",
       " u'memory': 52,\n",
       " u'mess': 24,\n",
       " u'middle': 18,\n",
       " u'mile': 24,\n",
       " u'mind': 171,\n",
       " u'minute': 37,\n",
       " u'mistake': 23,\n",
       " u'mom': 13,\n",
       " u'moment': 53,\n",
       " u'money': 112,\n",
       " u'mood': 19,\n",
       " u'moon': 33,\n",
       " u'morning': 48,\n",
       " u'mother': 22,\n",
       " u'motion': 20,\n",
       " u'mountain': 25,\n",
       " u'mouse': 5,\n",
       " u'mouth': 40,\n",
       " u'movie': 18,\n",
       " u'music': 68,\n",
       " u'nail': 11,\n",
       " u'nature': 8,\n",
       " u'need': 36,\n",
       " u'neon': 8,\n",
       " u'news': 13,\n",
       " u'night': 456,\n",
       " u'note': 14,\n",
       " u'nothin': 62,\n",
       " u'number': 26,\n",
       " u'ooh': 39,\n",
       " u'outside': 15,\n",
       " u'oven': 8,\n",
       " u'page': 15,\n",
       " u'pain': 61,\n",
       " u'pair': 16,\n",
       " u'pant': 27,\n",
       " u'paper': 13,\n",
       " u'paradise': 7,\n",
       " u'park': 16,\n",
       " u'party': 64,\n",
       " u'passion': 24,\n",
       " u'past': 11,\n",
       " u'pay': 11,\n",
       " u'perfume': 12,\n",
       " u'person': 154,\n",
       " u'phone': 43,\n",
       " u'picture': 47,\n",
       " u'pie': 15,\n",
       " u'piece': 44,\n",
       " u'place': 152,\n",
       " u'plan': 24,\n",
       " u'play': 28,\n",
       " u'pocket': 20,\n",
       " u'point': 19,\n",
       " u'power': 24,\n",
       " u'pride': 25,\n",
       " u'problem': 32,\n",
       " u'promise': 12,\n",
       " u'queen': 18,\n",
       " u'question': 28,\n",
       " u'race': 15,\n",
       " u'radio': 23,\n",
       " u'rain': 59,\n",
       " u'rap': 28,\n",
       " u'reason': 49,\n",
       " u'red': 15,\n",
       " u'rest': 30,\n",
       " u'rhythm': 23,\n",
       " u'ride': 73,\n",
       " u'ridin': 9,\n",
       " u'right': 100,\n",
       " u'ring': 34,\n",
       " u'rise': 7,\n",
       " u'river': 28,\n",
       " u'road': 73,\n",
       " u'rock': 89,\n",
       " u'roll': 38,\n",
       " u'rollin': 12,\n",
       " u'romance': 29,\n",
       " u'roof': 14,\n",
       " u'room': 71,\n",
       " u'round': 70,\n",
       " u'rule': 22,\n",
       " u'run': 18,\n",
       " u'rush': 15,\n",
       " u'sand': 19,\n",
       " u'sayin': 36,\n",
       " u'scene': 22,\n",
       " u'school': 61,\n",
       " u'sea': 42,\n",
       " u'seat': 26,\n",
       " u'self': 12,\n",
       " u'sense': 25,\n",
       " u'set': 17,\n",
       " u'shade': 16,\n",
       " u'share': 41,\n",
       " u'sheet': 13,\n",
       " u'shine': 21,\n",
       " u'ship': 8,\n",
       " u'shoe': 41,\n",
       " u'shot': 44,\n",
       " u'shoulder': 19,\n",
       " u'shower': 10,\n",
       " u'showin': 10,\n",
       " u'sight': 33,\n",
       " u'sign': 30,\n",
       " u'silence': 9,\n",
       " u'silver': 14,\n",
       " u'sin': 17,\n",
       " u'sing': 10,\n",
       " u'sister': 18,\n",
       " u'sittin': 14,\n",
       " u'situation': 22,\n",
       " u'skin': 41,\n",
       " u'sky': 110,\n",
       " u'slow': 21,\n",
       " u'smell': 12,\n",
       " u'smile': 70,\n",
       " u'snake': 5,\n",
       " u'snow': 21,\n",
       " u'somebody': 60,\n",
       " u'somethin': 58,\n",
       " u'song': 139,\n",
       " u'sorry': 5,\n",
       " u'soul': 91,\n",
       " u'sound': 65,\n",
       " u'space': 13,\n",
       " u'spirit': 13,\n",
       " u'spot': 36,\n",
       " u'stain': 7,\n",
       " u'stand': 12,\n",
       " u'star': 76,\n",
       " u'start': 42,\n",
       " u'state': 9,\n",
       " u'steel': 8,\n",
       " u'step': 42,\n",
       " u'stop': 15,\n",
       " u'store': 15,\n",
       " u'story': 39,\n",
       " u'stranger': 18,\n",
       " u'street': 84,\n",
       " u'string': 8,\n",
       " u'stuff': 31,\n",
       " u'style': 48,\n",
       " u'sugar': 27,\n",
       " u'suit': 21,\n",
       " u'summer': 47,\n",
       " u'summertime': 9,\n",
       " u'sun': 74,\n",
       " u'sunshine': 13,\n",
       " u'sure': 22,\n",
       " u'surprise': 19,\n",
       " u'tale': 25,\n",
       " u'talk': 59,\n",
       " u'taste': 43,\n",
       " u'tea': 8,\n",
       " u'team': 20,\n",
       " u'tear': 44,\n",
       " u'tellin': 21,\n",
       " u'thing': 533,\n",
       " u'thought': 57,\n",
       " u'tide': 8,\n",
       " u'time': 731,\n",
       " u'today': 50,\n",
       " u'toe': 16,\n",
       " u'tomorrow': 34,\n",
       " u'tonight': 130,\n",
       " u'touch': 59,\n",
       " u'town': 82,\n",
       " u'track': 34,\n",
       " u'train': 24,\n",
       " u'tree': 33,\n",
       " u'trip': 23,\n",
       " u'trouble': 14,\n",
       " u'truck': 19,\n",
       " u'trust': 12,\n",
       " u'truth': 36,\n",
       " u'try': 22,\n",
       " u'tryin': 63,\n",
       " u'tune': 17,\n",
       " u'turn': 15,\n",
       " u'tv': 25,\n",
       " u'type': 46,\n",
       " u'vision': 20,\n",
       " u'voice': 41,\n",
       " u'wake': 29,\n",
       " u'walk': 19,\n",
       " u'walking': 8,\n",
       " u'wall': 33,\n",
       " u'war': 20,\n",
       " u'waste': 9,\n",
       " u'water': 41,\n",
       " u'wave': 18,\n",
       " u'way': 483,\n",
       " u'weather': 19,\n",
       " u'week': 19,\n",
       " u'wheel': 26,\n",
       " u'whisper': 21,\n",
       " u'wind': 47,\n",
       " u'window': 29,\n",
       " u'wine': 37,\n",
       " u'wing': 20,\n",
       " u'winner': 7,\n",
       " u'winter': 19,\n",
       " u'wire': 11,\n",
       " u'wish': 14,\n",
       " u'woman': 129,\n",
       " u'wonder': 14,\n",
       " u'wood': 15,\n",
       " u'word': 148,\n",
       " u'work': 34,\n",
       " u'world': 270,\n",
       " u'ya': 253,\n",
       " u'yea': 16,\n",
       " u'year': 103,\n",
       " u'yellow': 6,\n",
       " u'yes': 12,\n",
       " u'yesterday': 14,\n",
       " u'youre': 14}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncs[1]['spanning-5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len spanning and spanning count dicts -->  6\n"
     ]
    }
   ],
   "source": [
    "acs = countAppearances(acomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'able': 14,\n",
       " u'afraid': 62,\n",
       " u'alive': 107,\n",
       " u'answer': 12,\n",
       " u'ashamed': 17,\n",
       " u'average': 11,\n",
       " u'bad': 286,\n",
       " u'beat': 50,\n",
       " u'beautiful': 99,\n",
       " u'best': 228,\n",
       " u'better': 233,\n",
       " u'big': 339,\n",
       " u'bigger': 29,\n",
       " u'biggest': 14,\n",
       " u'bitter': 15,\n",
       " u'black': 135,\n",
       " u'blind': 75,\n",
       " u'blue': 136,\n",
       " u'break': 32,\n",
       " u'bright': 79,\n",
       " u'brighter': 21,\n",
       " u'broken': 85,\n",
       " u'brown': 46,\n",
       " u'busy': 31,\n",
       " u'certain': 17,\n",
       " u'cheap': 19,\n",
       " u'cherry': 14,\n",
       " u'clean': 42,\n",
       " u'clear': 73,\n",
       " u'clearer': 9,\n",
       " u'close': 29,\n",
       " u'closed': 12,\n",
       " u'closer': 47,\n",
       " u'closest': 5,\n",
       " u'cold': 167,\n",
       " u'colder': 14,\n",
       " u'come': 45,\n",
       " u'common': 17,\n",
       " u'complete': 22,\n",
       " u'confused': 16,\n",
       " u'cool': 82,\n",
       " u'corner': 11,\n",
       " u'crazy': 226,\n",
       " u'cruel': 17,\n",
       " u'cute': 35,\n",
       " u'damn': 33,\n",
       " u'damned': 9,\n",
       " u'dancin': 10,\n",
       " u'dark': 133,\n",
       " u'darkest': 17,\n",
       " u'daytime': 7,\n",
       " u'dead': 89,\n",
       " u'dear': 24,\n",
       " u'deep': 168,\n",
       " u'deeper': 23,\n",
       " u'different': 106,\n",
       " u'dirty': 76,\n",
       " u'divine': 14,\n",
       " u'double': 31,\n",
       " u'drunk': 36,\n",
       " u'dry': 25,\n",
       " u'dumb': 22,\n",
       " u'early': 17,\n",
       " u'east': 22,\n",
       " u'easy': 94,\n",
       " u'electric': 12,\n",
       " u'endless': 27,\n",
       " u'everyday': 59,\n",
       " u'extra': 22,\n",
       " u'fair': 32,\n",
       " u'familiar': 12,\n",
       " u'famous': 15,\n",
       " u'fancy': 32,\n",
       " u'fast': 58,\n",
       " u'fat': 46,\n",
       " u'favorite': 60,\n",
       " u'feel': 9,\n",
       " u'feelin': 45,\n",
       " u'feeling': 27,\n",
       " u'final': 25,\n",
       " u'fine': 80,\n",
       " u'finer': 10,\n",
       " u'flat': 20,\n",
       " u'flow': 18,\n",
       " u'fly': 48,\n",
       " u'foolish': 24,\n",
       " u'foreign': 20,\n",
       " u'freaky': 23,\n",
       " u'free': 186,\n",
       " u'french': 14,\n",
       " u'fresh': 56,\n",
       " u'funky': 42,\n",
       " u'funny': 93,\n",
       " u'glad': 52,\n",
       " u'golden': 32,\n",
       " u'good': 694,\n",
       " u'grand': 19,\n",
       " u'gray': 23,\n",
       " u'great': 66,\n",
       " u'green': 50,\n",
       " u'greener': 12,\n",
       " u'grey': 17,\n",
       " u'guilty': 21,\n",
       " u'happy': 109,\n",
       " u'hard': 199,\n",
       " u'harder': 20,\n",
       " u'heavy': 34,\n",
       " u'high': 251,\n",
       " u'higher': 43,\n",
       " u'hollow': 9,\n",
       " u'honest': 12,\n",
       " u'hot': 214,\n",
       " u'human': 24,\n",
       " u'humble': 9,\n",
       " u'hungry': 29,\n",
       " u'hurt': 23,\n",
       " u'inner': 12,\n",
       " u'innocent': 8,\n",
       " u'insane': 27,\n",
       " u'jamaican': 8,\n",
       " u'jealous': 28,\n",
       " u'key': 22,\n",
       " u'lame': 18,\n",
       " u'late': 59,\n",
       " u'laughin': 11,\n",
       " u'lead': 9,\n",
       " u'left': 33,\n",
       " u'light': 33,\n",
       " u'like': 109,\n",
       " u'little': 707,\n",
       " u'live': 51,\n",
       " u'living': 21,\n",
       " u'local': 15,\n",
       " u'lonely': 206,\n",
       " u'long': 307,\n",
       " u'loose': 14,\n",
       " u'lost': 24,\n",
       " u'loud': 73,\n",
       " u'love': 21,\n",
       " u'lovely': 28,\n",
       " u'lovin': 121,\n",
       " u'loving': 103,\n",
       " u'low': 136,\n",
       " u'lucky': 29,\n",
       " u'mad': 79,\n",
       " u'magical': 13,\n",
       " u'main': 21,\n",
       " u'make': 48,\n",
       " u'mean': 38,\n",
       " u'middle': 17,\n",
       " u'miss': 31,\n",
       " u'movin': 17,\n",
       " u'naked': 32,\n",
       " u'nasty': 28,\n",
       " u'natural': 20,\n",
       " u'nervous': 17,\n",
       " u'new': 366,\n",
       " u'nice': 114,\n",
       " u'ohh': 36,\n",
       " u'ohhh': 9,\n",
       " u'okay': 46,\n",
       " u'ol': 34,\n",
       " u'old': 319,\n",
       " u'older': 29,\n",
       " u'oo': 8,\n",
       " u'ooh': 237,\n",
       " u'ooo': 17,\n",
       " u'oooh': 34,\n",
       " u'open': 108,\n",
       " u'outside': 55,\n",
       " u'past': 58,\n",
       " u'perfect': 97,\n",
       " u'physical': 11,\n",
       " u'pink': 15,\n",
       " u'precious': 42,\n",
       " u'pretty': 110,\n",
       " u'private': 30,\n",
       " u'proud': 31,\n",
       " u'pure': 30,\n",
       " u'purple': 16,\n",
       " u'quick': 57,\n",
       " u'quiet': 33,\n",
       " u'rare': 10,\n",
       " u'ready': 135,\n",
       " u'real': 454,\n",
       " u'red': 100,\n",
       " u'restless': 14,\n",
       " u'rich': 47,\n",
       " u'right': 250,\n",
       " u'rockin': 67,\n",
       " u'rough': 46,\n",
       " u'sacred': 9,\n",
       " u'sad': 94,\n",
       " u'safe': 47,\n",
       " u'scared': 42,\n",
       " u'second': 93,\n",
       " u'secret': 26,\n",
       " u'separate': 19,\n",
       " u'sexy': 80,\n",
       " u'shady': 13,\n",
       " u'shiny': 16,\n",
       " u'short': 49,\n",
       " u'shy': 25,\n",
       " u'sick': 66,\n",
       " u'silly': 25,\n",
       " u'simple': 56,\n",
       " u'single': 87,\n",
       " u'sleeping': 16,\n",
       " u'sleepless': 12,\n",
       " u'slow': 69,\n",
       " u'small': 48,\n",
       " u'smart': 21,\n",
       " u'soft': 49,\n",
       " u'sorry': 34,\n",
       " u'southern': 19,\n",
       " u'special': 83,\n",
       " u'steady': 33,\n",
       " u'stormy': 15,\n",
       " u'straight': 34,\n",
       " u'strange': 51,\n",
       " u'strong': 159,\n",
       " u'stronger': 32,\n",
       " u'sunny': 18,\n",
       " u'super': 22,\n",
       " u'sure': 140,\n",
       " u'surprised': 6,\n",
       " u'sweet': 262,\n",
       " u'sweeter': 16,\n",
       " u'sweetest': 27,\n",
       " u'tall': 32,\n",
       " u'tan': 19,\n",
       " u'tight': 44,\n",
       " u'tiny': 8,\n",
       " u'tired': 73,\n",
       " u'tough': 47,\n",
       " u'true': 339,\n",
       " u'ugly': 10,\n",
       " u'undercover': 16,\n",
       " u'vain': 18,\n",
       " u'vicious': 9,\n",
       " u'virgin': 10,\n",
       " u'warm': 70,\n",
       " u'weak': 42,\n",
       " u'wee': 12,\n",
       " u'welcome': 20,\n",
       " u'west': 10,\n",
       " u'wet': 61,\n",
       " u'white': 112,\n",
       " u'wide': 56,\n",
       " u'wild': 119,\n",
       " u'willing': 13,\n",
       " u'wise': 12,\n",
       " u'wonderful': 24,\n",
       " u'wont': 24,\n",
       " u'worst': 26,\n",
       " u'worth': 27,\n",
       " u'wrong': 216,\n",
       " u'yellow': 37,\n",
       " u'young': 184,\n",
       " u'younger': 25}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs[1]['spanning-5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save a histogram of  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appearanceCountsToHistogram(ctuple):\n",
    "    d = {}\n",
    "    idx = 0 #want to effectively start with 1\n",
    "    for c in ctuple:\n",
    "        idx += 1\n",
    "        d['{}-decade'.format(idx)] = [len(c)]\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-decade</th>\n",
       "      <th>2-decade</th>\n",
       "      <th>3-decade</th>\n",
       "      <th>4-decade</th>\n",
       "      <th>5-decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2994</td>\n",
       "      <td>913</td>\n",
       "      <td>490</td>\n",
       "      <td>328</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-decade  2-decade  3-decade  4-decade  5-decade\n",
       "0      2994       913       490       328       419"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncshistdf = appearanceCountsToHistogram(ncs)\n",
    "ncshistdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(ncshistdf,'noun_decade_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-decade</th>\n",
       "      <th>2-decade</th>\n",
       "      <th>3-decade</th>\n",
       "      <th>4-decade</th>\n",
       "      <th>5-decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2127</td>\n",
       "      <td>547</td>\n",
       "      <td>273</td>\n",
       "      <td>172</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-decade  2-decade  3-decade  4-decade  5-decade\n",
       "0      2127       547       273       172       260"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acshistdf = appearanceCountsToHistogram(acs)\n",
    "acshistdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(acshistdf,'adj_decade_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dump the 5-decade words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns5s = ncs[1]['spanning-5']\n",
    "dataframeToCsv(pd.DataFrame(data={'5-decade':ns5s.keys(), 'count':ns5s.values()}),'nouns_5-decade_spanners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "as5s = acs[1]['spanning-5']\n",
    "dataframeToCsv(pd.DataFrame(data={'5-decade':as5s.keys(), 'count':as5s.values()}),'adjs_5-decade_spanners.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Offensive Word-Counts for Appearances in 1 or more decade\n",
    "**These were prepped in [Profanity-Extraction Notebook](Profanity-Extraction.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Hypernym and Synonym Prep\n",
    "**These were prepped in [Vocab-Shrunk Notebook](Vocab-Shrunk.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Vector Ensemble Prep\n",
    "**These were prepped in [Vector-Ensemble Notebook](Vector-Ensemble.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
