{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tableau Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to sort dataframe decsending is the default\n",
    "def sortDataframe(df,sort_col,ascending=False):\n",
    "    return df.sort(columns=sort_col, ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading list of list pairs json to columnar dataframe\n",
    "def jsonListOfPairListsToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    keys = []\n",
    "    values = []\n",
    "    for x in j:\n",
    "        keys.append(x[0])\n",
    "        values.append(x[1])\n",
    "        \n",
    "    d = {key_col_label: listAsAscii(keys), val_col_label: listAsAscii(values)}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json dict to csv\n",
    "def jsonDictToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonDictToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                             root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for json list of lists containing 2 entries to csv\n",
    "def jsonListOfPairListsToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonListOfPairListsToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                                        root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##N-Gram (Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=None #this will get set for each conversion\n",
    "key_col_label = \"word\" #this will not change for n-gram\n",
    "val_col_label = \"count\" #this will not change for n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name=\"noun-n-gram\"\n",
    "nngramdf = jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noun n-gram](../../viz/noun_n-gram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=\"adj-n-gram\"\n",
    "angramdf = jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![adjective n-gram](../../viz/adj_n-gram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##N-Gram (Reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name=\"noun_n-gram_reduced\"\n",
    "nngramreducedf = jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noun n-gram reduced](../../viz/noun_n-gram_reduced.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name=\"adj_n-gram_reduced\"\n",
    "angramreducedf = jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, sort_col=val_col_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![adjective n-gram reduced](../../viz/noun_n-gram_reduced.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combine n-gram with n-gram reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramreducedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nngramjoindf = nngramdf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nngramjoindf['rcount'] = nngramreducedf['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>rcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>2390</td>\n",
       "      <td>love</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1665</td>\n",
       "      <td>baby</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1583</td>\n",
       "      <td>girl</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1544</td>\n",
       "      <td>time</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1097</td>\n",
       "      <td>thing</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   word  rcount\n",
       "1389   2390   love     788\n",
       "4006   1665   baby     731\n",
       "1649   1583   girl     629\n",
       "1218   1544   time     567\n",
       "1709   1097  thing     533"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramjoindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(nngramjoindf,'noun_n-grams_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3379, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angramdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3379, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angramreducedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angramjoindf = angramdf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angramjoindf['rcount'] = angramreducedf['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>rcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>2390</td>\n",
       "      <td>love</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1665</td>\n",
       "      <td>baby</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1583</td>\n",
       "      <td>girl</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1544</td>\n",
       "      <td>time</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1097</td>\n",
       "      <td>thing</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   word  rcount\n",
       "1389   2390   love     788\n",
       "4006   1665   baby     731\n",
       "1649   1583   girl     629\n",
       "1218   1544   time     567\n",
       "1709   1097  thing     533"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nngramjoindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(angramjoindf,'adj_n-grams_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decades (CSV Generation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]\n",
    "\n",
    "def makeDecadeCsvs(decade):\n",
    "    # change root in for decade\n",
    "    drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "    drootout = root_out+\"decades/\"+str(decade)+\"/\"\n",
    "    \n",
    "    assureDirExists(drootout)\n",
    "    \n",
    "    for name in [\"noun-n-gram\",\"adj-n-gram\"]:\n",
    "        jsonDictToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label, \n",
    "                      sort_col=val_col_label, root_in=drootin, root_out=drootout)\n",
    "    \n",
    "    for name in [\"noun_n-gram_reduced\",\"adj_n-gram_reduced\"]:\n",
    "        jsonListOfPairListsToCsv(name+\".json\",name+\".csv\", key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                      sort_col=val_col_label, root_in=drootin, root_out=drootout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in decades:\n",
    "    makeDecadeCsvs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Comparison across Decades\n",
    "Compare n-grams over decades by counting appearance of words over each decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load master noun and adj dict\n",
    "with open(root_in + 'noun_n-gram_reduced.json', 'r') as fp:\n",
    "    noun_ngram_reduced = json.load(fp)\n",
    "    \n",
    "with open(root_in + 'adj_n-gram_reduced.json', 'r') as fp:\n",
    "    adj_ngram_reduced = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5144"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_ngram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'jockin', 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_ngram_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3379"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_ngram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'suicidal', 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_ngram_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up a structure for each \n",
    "\n",
    "ncomp = {}\n",
    "acomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for x in noun_ngram_reduced:    \n",
    "    ncomp[x[0]]=[0,0,0,0,0]\n",
    "\n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for x in adj_ngram_reduced:\n",
    "    acomp[x[0]]=[0,0,0,0,0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each word\n",
    "\n",
    "def populateDecadeWords(comp,decade,json_name):\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # change root in for decade\n",
    "    drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "    \n",
    "    # read to json\n",
    "    with open(drootin + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    \n",
    "    #set decade value for each in j\n",
    "    for x in j:\n",
    "        comp[x[0]][didx] = x[1]\n",
    "    \n",
    "    return comp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ncomp for nouns\n",
    "for d in decades:\n",
    "    ncomp = populateDecadeWords(ncomp,d,'noun_n-gram_reduced.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jockin\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify ncomp\n",
    "print ncomp.keys()[0]\n",
    "print ncomp[ncomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# acomp for adjs\n",
    "for d in decades:\n",
    "    acomp = populateDecadeWords(acomp,d,'adj_n-gram_reduced.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limited\n",
      "[0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#verify acomp\n",
    "print acomp.keys()[0]\n",
    "print acomp[acomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate a column full of a given decades values from a comp\n",
    "def compCol(comp,decade):\n",
    "    didx = decades.index(decade)\n",
    "    vs = []\n",
    "    for k,v in comp.iteritems():\n",
    "        vs.append(v[didx])\n",
    "        \n",
    "    return vs\n",
    "\n",
    "# function to convert comp to dataframe and save\n",
    "def compToDataframe(comp):\n",
    "    d = {'word': listAsAscii(comp.keys())}\n",
    "    \n",
    "    for decade in decades:\n",
    "        d[str(decade)] = compCol(comp,decade)\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncompdf = compToDataframe(ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jockin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>girl(oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sleet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010     word\n",
       "0     0     0     1     0     0   jockin\n",
       "1     0     0     0     1     0   inning\n",
       "2     0     0     1     0     0  girl(oh\n",
       "3     1     1     1     2     1   yellow\n",
       "4     1     0     0     0     0    sleet"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncompdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acompdf = compToDataframe(acomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>our-our-our-ou-ou-ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ri-dic-dic-dic-ulous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010                    word\n",
       "0     0     0     0     1     1                 limited\n",
       "1     0     0     0     0     1  our-our-our-ou-ou-ours\n",
       "2     0     0     1     1     0                suicidal\n",
       "3     0     0     0     1     0    ri-dic-dic-dic-ulous\n",
       "4     0     0     1     2     0                 dynamic"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acompdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Comp to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ncompdf\n",
    "dataframeToCsv(ncompdf,'noun_decade_comp_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# acompdf\n",
    "dataframeToCsv(acompdf,'adj_decade_comp_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word-Counts for Appearances in 1 or more decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countAppearances(comp):\n",
    "    c1 = []\n",
    "    c2 = []\n",
    "    c3 = []\n",
    "    c4 = []\n",
    "    c5 = []\n",
    "    \n",
    "    for k,v in comp.iteritems():\n",
    "        c = 0\n",
    "        for x in v:\n",
    "            if x:\n",
    "                c += 1\n",
    "        if x == 5:\n",
    "            c5.append(k)\n",
    "        elif x == 4:\n",
    "            c4.append(k)\n",
    "        elif x == 3:\n",
    "            c3.append(k)\n",
    "        elif x == 2:\n",
    "            c2.append(k)\n",
    "        elif x == 1:\n",
    "            c1.append(k)\n",
    "    return c1,c2,c3,c4,c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncs = countAppearances(ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'half',\n",
       " u'end',\n",
       " u'beauty',\n",
       " u'wine',\n",
       " u'ball',\n",
       " u'gon',\n",
       " u'sippin',\n",
       " u'mouth',\n",
       " u'flow',\n",
       " u'team',\n",
       " u'ice',\n",
       " u'trouble',\n",
       " u'water',\n",
       " u'memory',\n",
       " u'ooh',\n",
       " u'feelin',\n",
       " u'work',\n",
       " u'suit',\n",
       " u'college',\n",
       " u'morning',\n",
       " u'sound',\n",
       " u'pop',\n",
       " u'start',\n",
       " u'building',\n",
       " u'trippin',\n",
       " u'kick',\n",
       " u'dress',\n",
       " u'beer',\n",
       " u'plan',\n",
       " u'buzz',\n",
       " u'pound',\n",
       " u'livin',\n",
       " u'hater',\n",
       " u'phone',\n",
       " u'jump',\n",
       " u'cloud',\n",
       " u'high',\n",
       " u'skirt',\n",
       " u'animal',\n",
       " u'bag',\n",
       " u'type',\n",
       " u'drunk',\n",
       " u'brain',\n",
       " u'record',\n",
       " u'tattoo',\n",
       " u'crack',\n",
       " u'wish']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acs = countAppearances(acomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'worth',\n",
       " u'dry',\n",
       " u'golden',\n",
       " u'fresher',\n",
       " u'break',\n",
       " u'twisted',\n",
       " u'rich',\n",
       " u'hotter',\n",
       " u'welcome',\n",
       " u'baddest',\n",
       " u'american',\n",
       " u'clean',\n",
       " u'nervous',\n",
       " u'movin',\n",
       " u'wait',\n",
       " u'fake',\n",
       " u'animal',\n",
       " u'light',\n",
       " u'wet',\n",
       " u'lean']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save a histogram of  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appearanceCountsToHistogram(ctuple):\n",
    "    d = {}\n",
    "    idx = 0 #want to effectively start with 1\n",
    "    for c in ctuple:\n",
    "        idx += 1\n",
    "        d['{}-decade'.format(idx)] = [len(c)]\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-decade</th>\n",
       "      <th>2-decade</th>\n",
       "      <th>3-decade</th>\n",
       "      <th>4-decade</th>\n",
       "      <th>5-decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>944</td>\n",
       "      <td>264</td>\n",
       "      <td>121</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-decade  2-decade  3-decade  4-decade  5-decade\n",
       "0       944       264       121        68        47"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncshistdf = appearanceCountsToHistogram(ncs)\n",
    "ncshistdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(ncshistdf,'noun_decade_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-decade</th>\n",
       "      <th>2-decade</th>\n",
       "      <th>3-decade</th>\n",
       "      <th>4-decade</th>\n",
       "      <th>5-decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>557</td>\n",
       "      <td>136</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-decade  2-decade  3-decade  4-decade  5-decade\n",
       "0       557       136        58        36        20"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acshistdf = appearanceCountsToHistogram(acs)\n",
    "acshistdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(acshistdf,'adj_decade_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dump the 5-decade words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(pd.DataFrame(data={'5-decade':ncs[4]}),'nouns_5-decade_spanners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(pd.DataFrame(data={'5-decade':acs[4]}),'adjs_5-decade_spanners.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Offensive Word-Counts for Appearances in 1 or more decade\n",
    "**These were prepped in [Profanity-Extraction Notebook](Profanity-Extraction.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
