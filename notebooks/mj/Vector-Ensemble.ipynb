{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vector Ensemble\n",
    "Ensemble approach using Spark. This notebook leverages the consolidated vector CSV which includes normal, synonym, and hypernym vectors, see [master-lyricsdf-word_syn_hype_vectors.csv](../../data/conditioned/master-lyricsdf-word_syn_hype_vectors.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "# Depending on your setup you might have to change this line of code\n",
    "#findspark makes sure I dont need the below on homebrew.\n",
    "#os.environ['SPARK_HOME']=\"/usr/local/Cellar/apache-spark/1.5.1/libexec/\"\n",
    "#the below actually broke my spark, so I removed it. \n",
    "#Depending on how you started the notebook, you might need it.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS']=\"--master local pyspark --executor-memory 4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local[4]')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.executor.memory', u'2g'),\n",
       " (u'spark.master', u'local[4]'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.driver.memory', u'8g'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.name', u'pyspark')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(2),2)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup Data For Pipeline\n",
    "###Load Dataframe into Pandas for initial manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the lyrics from the approved \"master\" dataframe\n",
    "lyrics_pd_df = pd.read_csv(\"../../data/conditioned/master-lyricsdf-word_syn_hype_vectors.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "      <th>noun_syn_hype_vector</th>\n",
       "      <th>adj_syn_hype_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>troubled rough</td>\n",
       "      <td>bridge time water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector  adj_syn_vector noun_syn_hype_vector adj_syn_hype_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water  troubled rough    bridge time water      rough troubled"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Add Labels for Data based on position\n",
    "This will change based upon the current run. A straight-forward usage is to see how well top and bottom 50 can be predicted.\n",
    "**Note: Spark ML seems picky about `label` being the column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use positions for labeling\n",
    "pcols = ['bin_10_percent','bin_25_percent','is_top_10_percent','is_top_25_percent','is_top_50_percent']\n",
    "\n",
    "# linear regression only supports binary topics\n",
    "pbinarycols = ['is_top_10_percent','is_top_25_percent','is_top_50_percent'] \n",
    "\n",
    "pos_dict = {\n",
    "    'bin_10_percent': {\n",
    "      10.0:range(1,11),\n",
    "      20.0:range(11,21),\n",
    "      30.0:range(21,31),\n",
    "      40.0:range(31,41),\n",
    "      50.0:range(41,51),\n",
    "      60.0:range(51,61), \n",
    "      70.0:range(61,71),\n",
    "      80.0:range(71,81),\n",
    "      90.0:range(81,91),\n",
    "      100.0:range(91,101)  \n",
    "    }, 'bin_25_percent': {\n",
    "      25.0:range(1,26),\n",
    "      50.0:range(26,51),\n",
    "      75.0:range(51,76),\n",
    "      100.0:range(76,101)\n",
    "    }, 'is_top_10_percent': {\n",
    "      1.0:range(1,11),\n",
    "      0.0:range(11,101)            \n",
    "    }, 'is_top_25_percent': {\n",
    "      1.0:range(1,26),\n",
    "      0.0:range(26,101)\n",
    "    }, 'is_top_50_percent': {\n",
    "      1.0:range(1,51),\n",
    "      0.0:range(51,101)\n",
    "    }\n",
    "}\n",
    "\n",
    "pos_dict_descrips = {\n",
    "    'bin_10_percent': \"10 Percent Splits (10 Topics)\",\n",
    "    'bin_25_percent': \"25 Percent Splits (4 Topics)\",\n",
    "    'is_top_10_percent': \"Top 10 versus Bottom 90 (2 Topics)\",\n",
    "    'is_top_25_percent': \"Top 25 versus Bottom 75 (2 Topics)\",      \n",
    "    'is_top_50_percent': \"Top 50 versus Bottom 50 (2 Topics)\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "      <th>noun_syn_hype_vector</th>\n",
       "      <th>adj_syn_hype_vector</th>\n",
       "      <th>bin_10_percent</th>\n",
       "      <th>is_top_50_percent</th>\n",
       "      <th>is_top_25_percent</th>\n",
       "      <th>bin_25_percent</th>\n",
       "      <th>is_top_10_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1367</td>\n",
       "      <td>68</td>\n",
       "      <td>1983</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Wanna_Be_Startin...</td>\n",
       "      <td>Wanna Be Startin' Somethin'</td>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>I said you wanna be startin' somethin'. You go...</td>\n",
       "      <td>1980</td>\n",
       "      <td>1983-68</td>\n",
       "      <td>http://lyrics.wikia.com/Michael_Jackson:Wanna_...</td>\n",
       "      <td>I said you wanna be startin' somethin'. You go...</td>\n",
       "      <td>cunnin declinin head coo sa</td>\n",
       "      <td>treacherous high loud</td>\n",
       "      <td>head sa coo</td>\n",
       "      <td>high loud treacherous</td>\n",
       "      <td>coo head sa</td>\n",
       "      <td>high loud treacherous</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>3080</td>\n",
       "      <td>81</td>\n",
       "      <td>2000</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Where_I_Wanna_Be...</td>\n",
       "      <td>Where I Wanna Be</td>\n",
       "      <td>Donell Jones</td>\n",
       "      <td>(verse one). I just left my baby girl a messag...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-81</td>\n",
       "      <td>http://lyrics.wikia.com/Donell_Jones:Where_I_W...</td>\n",
       "      <td>(verse one). I just left my baby girl a messag...</td>\n",
       "      <td>year love share</td>\n",
       "      <td>teenage real</td>\n",
       "      <td>love share year</td>\n",
       "      <td>adolescent real</td>\n",
       "      <td>love share year</td>\n",
       "      <td>adolescent real</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>4020</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Empire_State_of_...</td>\n",
       "      <td>Empire State of Mind</td>\n",
       "      <td>Jay-Z</td>\n",
       "      <td>Yeah. Yeah, I'm up at Brooklyn, now I'm down i...</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-21</td>\n",
       "      <td>http://lyrics.wikia.com/Jay-Z:Empire_State_Of_...</td>\n",
       "      <td>Yeah. Yeah, I'm up at Brooklyn, now I'm down i...</td>\n",
       "      <td>courtside fife street brand light nigga shit y...</td>\n",
       "      <td>high new big hot famous welcome yellow fair na...</td>\n",
       "      <td>yankee school foreigner king light winter life...</td>\n",
       "      <td>long particular high fair bad bright hot virgi...</td>\n",
       "      <td>air bellow boundary cab city corner crap dolla...</td>\n",
       "      <td>bad bare blazing bright celebrated cold fair g...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  position  year                                         title.href                        title           artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract                                        noun_vector                                         adj_vector                                    noun_syn_vector  \\\n",
       "1367   1367        68  1983  https://en.wikipedia.org/wiki/Wanna_Be_Startin...  Wanna Be Startin' Somethin'  Michael Jackson  I said you wanna be startin' somethin'. You go...    1980  1983-68  http://lyrics.wikia.com/Michael_Jackson:Wanna_...  I said you wanna be startin' somethin'. You go...                        cunnin declinin head coo sa                              treacherous high loud                                        head sa coo   \n",
       "3080   3080        81  2000  https://en.wikipedia.org/wiki/Where_I_Wanna_Be...             Where I Wanna Be     Donell Jones  (verse one). I just left my baby girl a messag...    2000  2000-81  http://lyrics.wikia.com/Donell_Jones:Where_I_W...  (verse one). I just left my baby girl a messag...                                    year love share                                       teenage real                                    love share year   \n",
       "4020   4020        21  2010  https://en.wikipedia.org/wiki/Empire_State_of_...         Empire State of Mind            Jay-Z  Yeah. Yeah, I'm up at Brooklyn, now I'm down i...    2010  2010-21  http://lyrics.wikia.com/Jay-Z:Empire_State_Of_...  Yeah. Yeah, I'm up at Brooklyn, now I'm down i...  courtside fife street brand light nigga shit y...  high new big hot famous welcome yellow fair na...  yankee school foreigner king light winter life...   \n",
       "\n",
       "                                         adj_syn_vector                               noun_syn_hype_vector                                adj_syn_hype_vector  bin_10_percent  is_top_50_percent  is_top_25_percent  bin_25_percent  is_top_10_percent  \n",
       "1367                              high loud treacherous                                        coo head sa                              high loud treacherous              70                  0                  0              75                  0  \n",
       "3080                                    adolescent real                                    love share year                                    adolescent real              90                  0                  0             100                  0  \n",
       "4020  long particular high fair bad bright hot virgi...  air bellow boundary cab city corner crap dolla...  bad bare blazing bright celebrated cold fair g...              30                  1                  1              25                  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def labelForPosition(pos,pos_dict_key):\n",
    "    for k,p in pos_dict[pos_dict_key].iteritems():\n",
    "        if pos in p:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "#label is position\n",
    "for pos_dict_key in pos_dict.keys():\n",
    "    lyrics_pd_df[pos_dict_key] = lyrics_pd_df.position.apply(lambda p : labelForPosition(p,pos_dict_key))\n",
    "\n",
    "#sanity check\n",
    "lyrics_pd_df.sample(3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Filter out Non-Lyric Records\n",
    "**Non-Lyrics due to:**\n",
    "* Instrumentals\n",
    "* Licensing restrictions on lyrics.wikia\n",
    "* No lyrics added to lyrics.wikia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the noun cols\n",
    "ncols = ['noun_vector','noun_syn_vector','noun_syn_hype_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many empty lyrics are there? 159\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls (which may include instrumentals or otherwise unavailable )\n",
    "print \"How many empty lyrics are there? {}\".format(len(np.where(pd.isnull(lyrics_pd_df[['lyrics']]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out null lyrics\n",
    "lyrics_pd_df = lyrics_pd_df.dropna(axis=0, how='any', thresh=None, subset=['lyrics'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4341, 22)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after removing noun_vector empties --> (4121, 22)\n",
      "shape after removing noun_syn_vector empties --> (4105, 22)\n",
      "shape after removing noun_syn_hype_vector empties --> (4105, 22)\n"
     ]
    }
   ],
   "source": [
    "# ALSO NEED TO REMOVE EMPTY NCOL ROWS RESULTING FROM VOCAB SHRINKAGE OPERATIONS\n",
    "for col in ncols:\n",
    "    lyrics_pd_df = lyrics_pd_df.dropna(axis=0, how='any', thresh=None, subset=[col], inplace=False)\n",
    "    print \"shape after removing {} empties --> {}\".format(col,lyrics_pd_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ROWS after removing empties --> 4105\n"
     ]
    }
   ],
   "source": [
    "print \"Final ROWS after removing empties -->\", lyrics_pd_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Set up Master Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhype = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUniqueWordsSorted(df,word_col):\n",
    "    u = []\n",
    "    for r in df.iterrows():\n",
    "        ws = r[1][word_col]\n",
    "        if not isinstance(ws,float):\n",
    "            vs = ws.split()          \n",
    "            for v in vs:\n",
    "                if not v in u:\n",
    "                    u.append(v)\n",
    "        \n",
    "    return sorted(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- noun_vector ---\n",
      "\n",
      "\tHow long is dict? 5138\n",
      "\tWhat are the first 5 entries? [['60', '8-bit', '>jeep', '>mayback', '\\\\n|officialsite']]\n",
      "\n",
      "--- noun_syn_vector ---\n",
      "\n",
      "\tHow long is dict? 3230\n",
      "\tWhat are the first 5 entries? [['abdomen', 'ability', 'abnormality', 'abortion', 'abrasion']]\n",
      "\n",
      "--- noun_syn_hype_vector ---\n",
      "\n",
      "\tHow long is dict? 3230\n",
      "\tWhat are the first 5 entries? [['abdomen', 'ability', 'abnormality', 'abortion', 'abrasion']]\n"
     ]
    }
   ],
   "source": [
    "all_words_dict = {}\n",
    "\n",
    "for col in ncols:\n",
    "    print \"\\n--- {} ---\\n\".format(col)\n",
    "    all_words_dict[col] = getUniqueWordsSorted(lyrics_pd_df, col)\n",
    "    print \"\\tHow long is dict? {}\".format(len(all_words_dict[col]))\n",
    "    print \"\\tWhat are the first 5 entries? [{}]\".format(all_words_dict[col][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compareWordLists(alist,blist):\n",
    "    same = []\n",
    "    ina = []\n",
    "    inb = []\n",
    "    \n",
    "    for a in alist:\n",
    "        if a in blist:\n",
    "            same.append(a)\n",
    "        else:\n",
    "            ina.append(a)\n",
    "    \n",
    "    for b in blist:\n",
    "        if b not in same:\n",
    "            inb.append(b)\n",
    "    return sorted(same), sorted(ina), sorted(inb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For syn versus syn-hype words...\n",
      "How many are same?  3230\n",
      "How many are only in syn?  0\n",
      "How many are only in hype?  0\n"
     ]
    }
   ],
   "source": [
    "tcomp = compareWordLists(all_words_dict[ncols[1]],all_words_dict[ncols[2]])\n",
    "print \"For syn versus syn-hype words...\"\n",
    "print \"How many are same? \", len(tcomp[0])\n",
    "print \"How many are only in syn? \", len(tcomp[1])\n",
    "print \"How many are only in hype? \", len(tcomp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Set up dictionaries for string and vectorized data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert array of strings to array of arrays\n",
    "def stringsToUniqueVectors(strings):\n",
    "    vectors = []\n",
    "    for s in strings:\n",
    "        # test for NaN\n",
    "        if not isinstance(s,float):\n",
    "            tmp = s.split()\n",
    "            cs = []\n",
    "            for t in tmp:\n",
    "                if not t in cs:\n",
    "                    cs.append(t)\n",
    "            vectors.append(sorted(cs))\n",
    "        # just in case, handle empty    \n",
    "        else:\n",
    "            vectors.append([])\n",
    "            \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict for k=col, v=array of strings\n",
    "nstrings = {}\n",
    "\n",
    "# dict for k=col, v=array of arrays\n",
    "nvectors = {}\n",
    "\n",
    "# initialize\n",
    "for col in ncols:\n",
    "    nstrings[col] = []\n",
    "    nvectors[col] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# populate\n",
    "for col in ncols:\n",
    "    nstrings[col] = lyrics_pd_df[col].values\n",
    "    nvectors[col] = stringsToUniqueVectors(nstrings[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verification\n",
    "for col in ncols:\n",
    "    idx = 6\n",
    "    print \"`{}`[{}]: {} -->\\n\\t{}\".format(col,idx,nstrings[col][idx],nvectors[col][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert and manipulate with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert from pandas to spark dataframe\n",
    "lyricsdf = sqlsc.createDataFrame(lyrics_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline Using Spark\n",
    "Reference [combine all features into a single feature vector](https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html)\n",
    "![Ensemble Pipeline Overview](https://databricks.com/wp-content/uploads/2015/07/simple-pipeline.png)\n",
    "* Tokenizer\n",
    "* HashingTF\n",
    "* Word2Vec\n",
    "* OneHotEncoder\n",
    "* Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline adapted from:\n",
    "# http://spark.apache.org/docs/latest/ml-guide.html\n",
    "# https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used in common for printing predictions\n",
    "def printPredicts(predictsdf,pred_hits,ncol,pcol,pipeline_name=\"Pipeline\",reg_param=None, max_iter=None, verbose=False):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    print \"For reg_param: {} & max_iter: {}, how did pipeline '{}' do predicting pcol '{}' for label '{}'?\".format(\n",
    "        (reg_param if reg_param else \"<unspecified>\"),\n",
    "        (max_iter if max_iter else \"<unspecified>\"),\n",
    "        pipeline_name,pos_dict_descrips[pcol],ncol)\n",
    "    \n",
    "    for r in predictsdf.iterrows():\n",
    "        song_key = r[1].song_key\n",
    "        pred = pred_hits[song_key]  \n",
    "        result = labelForPosition(r[1].position, pcol)\n",
    "        correct = result == pred\n",
    "        if correct:\n",
    "            hits +=1\n",
    "            if verbose:\n",
    "                print \"Correct ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "        else:\n",
    "            misses +=1\n",
    "            if verbose:\n",
    "                print \"Incorrect ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "    print \"{} hits: {}, misses: {}\".format(pipeline_name,hits,misses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Fit Linear Regression Models to songs prior to 2013 and predict on 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## establish training and test Spark Dataframes (to be filtered further as needed)\n",
    "## e.g. traindf.select(['song_key',ncol,pcol])\n",
    "\n",
    "# training on songs to 2013 (uses nstrings)\n",
    "traindf = lyricsdf.filter(lyricsdf['year'] != 2014)\n",
    "# test year 2014 (uses nstrings)\n",
    "testdf = lyricsdf.filter(lyricsdf['year'] == 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pipeline  :  Linear Regression\n",
    "**Here is the output of** \n",
    "```python\n",
    "LogisticRegression().explainParams()\n",
    "```\n",
    "* __elasticNetParam__: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
    "* __featuresCol__: features column name (default: features)\n",
    "* __fitIntercept__: whether to fit an intercept term. (default: True)\n",
    "* __labelCol__: label column name (default: label)\n",
    "* __maxIter__: max number of iterations (>= 0) (default: 100)\n",
    "* __predictionCol__: prediction column name (default: prediction)\n",
    "* __probabilityCol__: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
    "* __rawPredictionCol__: raw prediction (a.k.a. confidence) column name (default: rawPrediction)\n",
    "* __regParam__: regularization parameter (>= 0) (default: 0.1)\n",
    "* __threshold__: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match. (default: 0.5)\n",
    "* __thresholds__: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold. (undefined)\n",
    "* __tol__: the convergence tolerance for iterative algorithms (default: 1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLinearRegressionPipelineModel(ncol, pcol, max_iter=10, reg_param=0.01):  \n",
    "    tok = Tokenizer(inputCol=ncol, outputCol=\"words\")\n",
    "    htf = HashingTF(inputCol=tok.getOutputCol(), outputCol=\"features\", numFeatures=200)\n",
    "    lr = LogisticRegression(labelCol=pcol, maxIter=max_iter, regParam=reg_param)\n",
    "    return Pipeline(stages=[tok, htf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up models for each of the ncols considering all binary labels (i.e. topics such as `is_top_10_percent`)\n",
    "modelbinary_dict = {}\n",
    "\n",
    "# initialize\n",
    "for col in ncols:\n",
    "    modelbinary_dict[col] = {}\n",
    "\n",
    "# populate with binary labels\n",
    "for ncol in ncols:\n",
    "    for pcol in pbinarycols:\n",
    "        modelbinary_dict[ncol][pcol] = buildLinearRegressionPipelineModel(ncol,pcol)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quick test \n",
    "tncol = ncols[2]\n",
    "tpcol = pbinarycols[2]\n",
    "tdf = lyrics_pd_df[lyrics_pd_df['year'] == 2014]\n",
    "treg_params = [.001, .01, .1, 1., 10., 100., 200., 300., 400., 500., 1000.]\n",
    "tmax_iters = [10,20,30,40,50]\n",
    "\n",
    "print \"testing with\\n\\tncol: {}\\n\\tpcol: {}\\n\\treg_params: {}\\n\\ttmax_iters: {}\".format(tncol,tpcol,treg_params,tmax_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for reg_param in treg_params:\n",
    "    print \"\\n--- reg_param: {} ---\".format(reg_param)\n",
    "    for max_iter in tmax_iters:\n",
    "        model1 = buildLinearRegressionPipelineModel(\n",
    "            tncol, tpcol, max_iter=max_iter, reg_param=reg_param).fit(traindf.select(['song_key',tncol,tpcol]))\n",
    "    \n",
    "        # Make predictions on test documents and print columns of interest.\n",
    "        prediction1 = model1.transform(testdf.select(['song_key',tncol,tpcol]))\n",
    "        selected1 = prediction1.select(\"song_key\", tncol, \"prediction\")\n",
    "    \n",
    "        # build up predictions\n",
    "        pred_hits1 = {}\n",
    "        for row in selected1.collect():\n",
    "            pred_hits1[row[0]] = row[2]\n",
    "    \n",
    "        # print predictions\n",
    "        printPredicts(tdf,pred_hits1, tncol, tpcol, reg_param=reg_param, max_iter=max_iter, \n",
    "                      pipeline_name=\"LRPipeline Predict 2014\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
