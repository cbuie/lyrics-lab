{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vector Ensemble\n",
    "Ensemble approach using Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SET DECADE (OR NOT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if decade is set, then filter results accordingly.\n",
    "decade = None\n",
    "# decade = 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "# Depending on your setup you might have to change this line of code\n",
    "#findspark makes sure I dont need the below on homebrew.\n",
    "#os.environ['SPARK_HOME']=\"/usr/local/Cellar/apache-spark/1.5.1/libexec/\"\n",
    "#the below actually broke my spark, so I removed it. \n",
    "#Depending on how you started the notebook, you might need it.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS']=\"--master local pyspark --executor-memory 4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local[4]')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.executor.memory', u'2g'),\n",
       " (u'spark.master', u'local[4]'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.driver.memory', u'8g'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.name', u'pyspark')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(2),2)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup Data For Pipeline\n",
    "###Load and manipulate with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the lyrics from the approved \"master\" dataframe\n",
    "lyrics_pd_df = pd.read_csv(\"../../data/conditioned/use-this-master-lyricsdf-extracted.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if decade:\n",
    "    lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['decade'] == decade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Labels for Data based on position\n",
    "**Note: Spark ML seems picky about `label` being the column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use positions for labeling\n",
    "positions_10_percent = {\n",
    "  10.0:range(1,11),\n",
    "  20.0:range(11,21),\n",
    "  30.0:range(21,31),\n",
    "  40.0:range(31,41),\n",
    "  50.0:range(41,51),\n",
    "  60.0:range(51,61), \n",
    "  70.0:range(61,71),\n",
    "  80.0:range(71,81),\n",
    "  90.0:range(81,91),\n",
    "  100.0:range(91,101)  \n",
    "}\n",
    "\n",
    "positions_25_percent = {\n",
    "  25.0:range(1,26),\n",
    "  50.0:range(26,51),\n",
    "  75.0:range(51,76),\n",
    "  100.0:range(76,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 25\n",
    "positions_top_25 = {\n",
    "  0.0:range(1,26),\n",
    "  1.0:range(26,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 50\n",
    "positions_top_50 = {\n",
    "  0.0:range(1,51),\n",
    "  1.0:range(51,101)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is the dictionary for this run. This is how the classification is being done.\n",
    "positions_description = \"Top 50 versus Bottom 50\"\n",
    "positions_dict = positions_top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelForPosition(pos):\n",
    "    for k,p in positions_dict.iteritems():\n",
    "        if pos in p:\n",
    "            return k\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test label lookup\n",
    "labelForPosition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#label is position, e.g. 1-10, in this use\n",
    "lyrics_pd_df['label'] = lyrics_pd_df.position.apply(labelForPosition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>4320</td>\n",
       "      <td>21</td>\n",
       "      <td>2013</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cups_(song)</td>\n",
       "      <td>Cups</td>\n",
       "      <td>Anna Kendrick</td>\n",
       "      <td>I've got my ticket for the long way 'round. Tw...</td>\n",
       "      <td>2010</td>\n",
       "      <td>2013-21</td>\n",
       "      <td>http://lyrics.wikia.com/Anna_Kendrick:Cups</td>\n",
       "      <td>I've got my ticket for the long way 'round. Tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2134</td>\n",
       "      <td>35</td>\n",
       "      <td>1991</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Here_We_Go_(Let%...</td>\n",
       "      <td>Here We Go</td>\n",
       "      <td>C+C Music Factory</td>\n",
       "      <td>Y'all want this party started, right? Y'all wa...</td>\n",
       "      <td>1990</td>\n",
       "      <td>1991-35</td>\n",
       "      <td>http://lyrics.wikia.com/C%2BC_Music_Factory:He...</td>\n",
       "      <td>Y'all want this party started, right? Y'all wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>4027</td>\n",
       "      <td>28</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Breakeven_(song)</td>\n",
       "      <td>Breakeven</td>\n",
       "      <td>The Script</td>\n",
       "      <td>I'm still alive but I'm barely breathing. Just...</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-28</td>\n",
       "      <td>http://lyrics.wikia.com/The_Script:Breakeven</td>\n",
       "      <td>I'm still alive but I'm barely breathing. Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>90</td>\n",
       "      <td>1978</td>\n",
       "      <td>https://en.wikipedia.org/wiki/It%27s_So_Easy!_...</td>\n",
       "      <td>It's So Easy</td>\n",
       "      <td>Linda Ronstadt</td>\n",
       "      <td>It's so easy to fall in love. It's so easy to ...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1978-90</td>\n",
       "      <td>http://lyrics.wikia.com/Linda_Ronstadt:It%27s_...</td>\n",
       "      <td>It's so easy to fall in love. It's so easy to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>4179</td>\n",
       "      <td>80</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Knee_Deep</td>\n",
       "      <td>Knee Deep</td>\n",
       "      <td>Zac Brown Band</td>\n",
       "      <td>Gonna put the the world away for a minute. Pre...</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011-80</td>\n",
       "      <td>http://lyrics.wikia.com/Zac_Brown_Band:Knee_Deep</td>\n",
       "      <td>Gonna put the the world away for a minute. Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  position  year                                         title.href         title             artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract  label\n",
       "4320   4320        21  2013          https://en.wikipedia.org/wiki/Cups_(song)          Cups      Anna Kendrick  I've got my ticket for the long way 'round. Tw...    2010  2013-21         http://lyrics.wikia.com/Anna_Kendrick:Cups  I've got my ticket for the long way 'round. Tw...      0\n",
       "2134   2134        35  1991  https://en.wikipedia.org/wiki/Here_We_Go_(Let%...    Here We Go  C+C Music Factory  Y'all want this party started, right? Y'all wa...    1990  1991-35  http://lyrics.wikia.com/C%2BC_Music_Factory:He...  Y'all want this party started, right? Y'all wa...      0\n",
       "4027   4027        28  2010     https://en.wikipedia.org/wiki/Breakeven_(song)     Breakeven         The Script  I'm still alive but I'm barely breathing. Just...    2010  2010-28       http://lyrics.wikia.com/The_Script:Breakeven  I'm still alive but I'm barely breathing. Just...      0\n",
       "889     889        90  1978  https://en.wikipedia.org/wiki/It%27s_So_Easy!_...  It's So Easy     Linda Ronstadt  It's so easy to fall in love. It's so easy to ...    1970  1978-90  http://lyrics.wikia.com/Linda_Ronstadt:It%27s_...  It's so easy to fall in love. It's so easy to ...      1\n",
       "4179   4179        80  2011            https://en.wikipedia.org/wiki/Knee_Deep     Knee Deep     Zac Brown Band  Gonna put the the world away for a minute. Pre...    2010  2011-80   http://lyrics.wikia.com/Zac_Brown_Band:Knee_Deep  Gonna put the the world away for a minute. Pre...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.sample(5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Reduced Word and ID Vectors\n",
    "Add columns:\n",
    "* `noun_vector` for reduced words (as string separated by spaces)\n",
    "* `noun_id_vector` id vector (again as string separated by vector)\n",
    "* `ad_vector` for reduced words (as string separated by spaces)\n",
    "* `adj_id_vector` id vector (again as string separated by vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files needed (expects dir `corpus_vocabs` to be present)\n",
    "\n",
    "# load ncollect from file\n",
    "with open('../../data/conditioned/corpus_vocabs/noun-word-reduction.json', 'r') as fp:\n",
    "    nreduction = json.load(fp)\n",
    "    \n",
    "# load acollect from file\n",
    "with open('../../data/conditioned/corpus_vocabs/adj-word-reduction.json', 'r') as fp:\n",
    "    areduction = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'time', u'bridge', u'water']]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nreduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reductionAsWordStr(reduction):\n",
    "    words = []\n",
    "    for r in reduction:\n",
    "        v = ' '.join([x.encode('ascii','ignore') for x in r])\n",
    "        words.append(v)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn_reduction = reductionAsWordStr(nreduction)\n",
    "wa_reduction = reductionAsWordStr(areduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'time bridge water']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_reduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'rough troubled']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_reduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvdf = pd.DataFrame({'noun_vector': wn_reduction})  \n",
    "lyrics_pd_df1 = lyrics_pd_df.join(nvdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avdf = pd.DataFrame({'adj_vector': wa_reduction})  \n",
    "lyrics_pd_df = lyrics_pd_df1.join(avdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/(They_Long_to_Be...</td>\n",
       "      <td>(They Long to Be) Close to You</td>\n",
       "      <td>The Carpenters</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-2</td>\n",
       "      <td>http://lyrics.wikia.com/Carpenters:%28They_Lon...</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "      <td>dream starlight eye</td>\n",
       "      <td>true blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/American_Woman_(...</td>\n",
       "      <td>American Woman</td>\n",
       "      <td>The Guess Who</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-3</td>\n",
       "      <td>http://lyrics.wikia.com/The_Guess_Who:American...</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "      <td>woman mess mind mama thing time growin light y...</td>\n",
       "      <td>american important old coloured leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Raindrops_Keep_F...</td>\n",
       "      <td>Raindrops Keep Fallin' on My Head</td>\n",
       "      <td>B.J. Thomas</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-4</td>\n",
       "      <td>http://lyrics.wikia.com/B.J._Thomas:Raindrops_...</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "      <td>guy foot bed happiness step eye</td>\n",
       "      <td>big long red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/War_(Edwin_Starr...</td>\n",
       "      <td>War</td>\n",
       "      <td>Edwin Starr</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-5</td>\n",
       "      <td>http://lyrics.wikia.com/Edwin_Starr:War</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "      <td>god destruction life war unrest generation man...</td>\n",
       "      <td>good innocent younger young short precious fig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                              title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract                                        noun_vector                                         adj_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...         Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...                                  time bridge water                                     rough troubled\n",
       "1      1         2  1970  https://en.wikipedia.org/wiki/(They_Long_to_Be...     (They Long to Be) Close to You       The Carpenters  Why do birds suddenly appear. Everytime you ar...    1970   1970-2  http://lyrics.wikia.com/Carpenters:%28They_Lon...  Why do birds suddenly appear. Everytime you ar...                                dream starlight eye                                          true blue\n",
       "2      2         3  1970  https://en.wikipedia.org/wiki/American_Woman_(...                     American Woman        The Guess Who  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...    1970   1970-3  http://lyrics.wikia.com/The_Guess_Who:American...  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...  woman mess mind mama thing time growin light y...              american important old coloured leave\n",
       "3      3         4  1970  https://en.wikipedia.org/wiki/Raindrops_Keep_F...  Raindrops Keep Fallin' on My Head          B.J. Thomas  Raindrops are falling on my head. And just lik...    1970   1970-4  http://lyrics.wikia.com/B.J._Thomas:Raindrops_...  Raindrops are falling on my head. And just lik...                    guy foot bed happiness step eye                                       big long red\n",
       "4      4         5  1970  https://en.wikipedia.org/wiki/War_(Edwin_Starr...                                War          Edwin Starr  War, huh, yeah. What is it good for? Absolutel...    1970   1970-5            http://lyrics.wikia.com/Edwin_Starr:War  War, huh, yeah. What is it good for? Absolutel...  god destruction life war unrest generation man...  good innocent younger young short precious fig..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save Augmented DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics_pd_df.to_csv(\"../../data/conditioned/master-lyricsdf-word_vectors.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Filter out Non-Lyric Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many empties are there? 103\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls\n",
    "empties = np.where(pd.isnull(lyrics_pd_df[['lyrics']]))\n",
    "print \"How many empties are there? {}\".format(len(empties[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instrumentals are there? 20\n"
     ]
    }
   ],
   "source": [
    "# Check for instrumental mustic\n",
    "instrumentals = np.where(lyrics_pd_df[['lyrics']].applymap(lambda x: x == 'Instrumental'))\n",
    "print \"How many instrumentals are there? {}\".format(len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many total non-lyrics are there? 123\n"
     ]
    }
   ],
   "source": [
    "# total non-lyrics\n",
    "print \"How many total non-lyrics are there? {}\".format(len(empties[0]) + len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out null lyrics\n",
    "lyrics_pd_df = lyrics_pd_df.dropna(axis=0, how='any', thresh=None, subset=['lyrics'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4397, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out instrumentals\n",
    "lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['lyrics'] != 'Instrumental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4377, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Filtered Lyrics With Reduced Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load Corpus and Vocab(s) As Needed\n",
    "**\n",
    "NOTES:\n",
    "* These files need to be locally unzipped, e.g. the `corpus_vocabs.7z` under `data` folder\n",
    "* The unzipped files should not be added back to GitHub, they are excluded in .gitignore\n",
    "* It is assumed that the .7z are unzipped into their own folder\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildFilename = (lambda name, decade, ext : name + str(decade) + \".\" + ext if decade else name + \".\" + ext) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using base_path -->  ../../data/conditioned/corpus_vocabs/\n"
     ]
    }
   ],
   "source": [
    "# base_path will get manipulated based on decade or not\n",
    "base_path = \"../../data/conditioned/\"\n",
    "if decade:\n",
    "    base_path = base_path + \"decades/\" + str(decade) + \"/\"\n",
    "else:\n",
    "    base_path = base_path + \"corpus_vocabs/\"\n",
    "\n",
    "print \"Will be using base_path --> \",base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## with base path set, load up needed resources\n",
    "\n",
    "corpus = None # this is a pickle file\n",
    "adjid2word = None\n",
    "nounid2word = None\n",
    "\n",
    "# corpus\n",
    "try:   \n",
    "    corpus = pickle.load( open(base_path + buildFilename(\"corpus\",decade,\"p\") , \"rb\" ) ) \n",
    "except Exception as e:\n",
    "    print \"unable to find corpus{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# adjid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"adjid2word\",decade,\"json\"), 'r') as fp:\n",
    "        adjid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find adjid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# nounid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"nounid2word\",decade,\"json\"), 'r') as fp:\n",
    "        nounid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find nounid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is corpus?  35472\n",
      "How big is adjid2word?  3379\n",
      "How big is nounid2word?  5144\n"
     ]
    }
   ],
   "source": [
    "print \"How big is corpus? \", len(corpus)\n",
    "print \"How big is adjid2word? \", len(adjid2word)\n",
    "print \"How big is nounid2word? \", len(nounid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(5139, 1)], [(135, 1), (1887, 1)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'suicidal'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'jockin'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Manipulate `Corpus` into list of index ids per row\n",
    "**This list removes duplication of token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35472"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)\n",
    "corpus[:10]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for r in corpus:\n",
    "    cs = []\n",
    "    for c in r:\n",
    "        cs.append(str(c[0]))\n",
    "    corpus_list.append(\" \".join(cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5139', '135 1887', '135 1887', '135 1887', '135 1887', '135 1887', '135 1887', '327', '192 1621', '327']\n"
     ]
    }
   ],
   "source": [
    "print corpus_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35472"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert and manipulate with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert from pandas to spark dataframe\n",
    "lyricsdf = sqlsc.createDataFrame(lyrics_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "|index|position|year|          title.href|               title|             artist|              lyrics|decade|song_key|          lyrics_url|     lyrics_abstract|label|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "|    0|       1|1970|https://en.wikipe...|Bridge over Troub...|Simon and Garfunkel|When you're weary...|  1970|  1970-1|http://lyrics.wik...|When you're weary...|  0.0|\n",
      "|    1|       2|1970|https://en.wikipe...|(They Long to Be)...|     The Carpenters|Why do birds sudd...|  1970|  1970-2|http://lyrics.wik...|Why do birds sudd...|  0.0|\n",
      "|    2|       3|1970|https://en.wikipe...|      American Woman|      The Guess Who|Mmm, da da da. Mm...|  1970|  1970-3|http://lyrics.wik...|Mmm, da da da. Mm...|  0.0|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline Using Spark\n",
    "Reference [combine all features into a single feature vector](https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html)\n",
    "![Ensemble Pipeline Overview](https://databricks.com/wp-content/uploads/2015/07/simple-pipeline.png)\n",
    "* Tokenizer\n",
    "* HashingTF\n",
    "* Word2Vec\n",
    "* OneHotEncoder\n",
    "* Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline adapted from:\n",
    "# http://spark.apache.org/docs/latest/ml-guide.html\n",
    "# https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used in common for printing predictions\n",
    "def printPredicts(predictsdf,pred_hits,pipeline_name=\"Pipeline\"):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    print \"How did {} do predicting {}?\".format(pipeline_name,positions_description)\n",
    "    for r in predictsdf.iterrows():\n",
    "        song_key = r[1].song_key\n",
    "        pred = pred_hits[song_key]  \n",
    "        result = labelForPosition(r[1].position)\n",
    "        correct = result == pred\n",
    "        if correct:\n",
    "            hits +=1\n",
    "            print \"Correct ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "        else:\n",
    "            misses +=1\n",
    "            print \"Incorrect ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "    print \"{} hits: {}, misses: {}\".format(pipeline_name,hits,misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO (HERE OR TABLEAU) -- VIZ Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Whole Corpus Approach: Fit a model to songs prior to 2013 and predict on 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment lyricsdf with corpus\n",
    "lyricsdf_corpus = lyricsdf.withColumn(\"lyrics_tokenized\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training on songs to 2013\n",
    "training = lyricsdf.filter(lyricsdf['year'] != 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "# training_corpus on songs to 2013\n",
    "training_corpus = lyricsdf_corpus.filter(lyricsdf['year'] != 2014).select(['song_key','lyrics','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test year 2014\n",
    "test = lyricsdf.filter(lyricsdf['year'] == 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "# test_corpus year 2014\n",
    "test_corpus = lyricsdf_corpus.filter(lyricsdf['year'] == 2014).select(['song_key','lyrics','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pipeline 1 : Whole Document as Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Fri, 27 Nov 2015 14:18:36\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 17.7 ms, total: 17.7 ms\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "LabeledDocument = Row(\"song_key\", \"lyrics\", \"label\")\n",
    "\n",
    "## ML Pipeline \n",
    "tok1 = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
    "htf1 = HashingTF(inputCol=tok1.getOutputCol(), outputCol=\"features\", numFeatures=200)\n",
    "lr1 = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline1 = Pipeline(stages=[tok1, htf1, lr1])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model1 = pipeline1.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction1 = model1.transform(test)\n",
    "selected1 = prediction1.select(\"song_key\", \"lyrics\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print type(selected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up predictions\n",
    "pred_hits1 = {}\n",
    "for row in selected1.collect():\n",
    "    pred_hits1[row[0]] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check, predicted 2010-1 in top 25 correctly.\n",
    "pred_hits1['2014-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How did pipeline1 do at predicting top 50 hits for 2014 in light of hits prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Pipeline1 do predicting Top 50 versus Bottom 50?\n",
      "Correct ::: song_key --> 2014-1, predicted 0.0\n",
      "Correct ::: song_key --> 2014-2, predicted 0.0\n",
      "Correct ::: song_key --> 2014-3, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-4, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-5, predicted 1.0\n",
      "Correct ::: song_key --> 2014-6, predicted 0.0\n",
      "Correct ::: song_key --> 2014-7, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-8, predicted 1.0\n",
      "Correct ::: song_key --> 2014-9, predicted 0.0\n",
      "Correct ::: song_key --> 2014-10, predicted 0.0\n",
      "Correct ::: song_key --> 2014-11, predicted 0.0\n",
      "Correct ::: song_key --> 2014-12, predicted 0.0\n",
      "Correct ::: song_key --> 2014-13, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-14, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-15, predicted 1.0\n",
      "Correct ::: song_key --> 2014-16, predicted 0.0\n",
      "Correct ::: song_key --> 2014-17, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-18, predicted 1.0\n",
      "Correct ::: song_key --> 2014-19, predicted 0.0\n",
      "Correct ::: song_key --> 2014-20, predicted 0.0\n",
      "Correct ::: song_key --> 2014-21, predicted 0.0\n",
      "Correct ::: song_key --> 2014-22, predicted 0.0\n",
      "Correct ::: song_key --> 2014-23, predicted 0.0\n",
      "Correct ::: song_key --> 2014-24, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-25, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-26, predicted 1.0\n",
      "Correct ::: song_key --> 2014-27, predicted 0.0\n",
      "Correct ::: song_key --> 2014-28, predicted 0.0\n",
      "Correct ::: song_key --> 2014-29, predicted 0.0\n",
      "Correct ::: song_key --> 2014-30, predicted 0.0\n",
      "Correct ::: song_key --> 2014-31, predicted 0.0\n",
      "Correct ::: song_key --> 2014-32, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-33, predicted 1.0\n",
      "Correct ::: song_key --> 2014-34, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-35, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-36, predicted 1.0\n",
      "Correct ::: song_key --> 2014-37, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-38, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-39, predicted 1.0\n",
      "Correct ::: song_key --> 2014-40, predicted 0.0\n",
      "Correct ::: song_key --> 2014-41, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-42, predicted 1.0\n",
      "Correct ::: song_key --> 2014-43, predicted 0.0\n",
      "Correct ::: song_key --> 2014-44, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-45, predicted 1.0\n",
      "Correct ::: song_key --> 2014-46, predicted 0.0\n",
      "Correct ::: song_key --> 2014-47, predicted 0.0\n",
      "Correct ::: song_key --> 2014-48, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-49, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-50, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-51, predicted 0.0\n",
      "Correct ::: song_key --> 2014-52, predicted 1.0\n",
      "Correct ::: song_key --> 2014-53, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-54, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-55, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-56, predicted 0.0\n",
      "Correct ::: song_key --> 2014-57, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-58, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-59, predicted 0.0\n",
      "Correct ::: song_key --> 2014-60, predicted 1.0\n",
      "Correct ::: song_key --> 2014-61, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-62, predicted 0.0\n",
      "Correct ::: song_key --> 2014-63, predicted 1.0\n",
      "Correct ::: song_key --> 2014-64, predicted 1.0\n",
      "Correct ::: song_key --> 2014-65, predicted 1.0\n",
      "Correct ::: song_key --> 2014-66, predicted 1.0\n",
      "Correct ::: song_key --> 2014-67, predicted 1.0\n",
      "Correct ::: song_key --> 2014-68, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-69, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-70, predicted 0.0\n",
      "Correct ::: song_key --> 2014-71, predicted 1.0\n",
      "Correct ::: song_key --> 2014-72, predicted 1.0\n",
      "Correct ::: song_key --> 2014-73, predicted 1.0\n",
      "Correct ::: song_key --> 2014-74, predicted 1.0\n",
      "Correct ::: song_key --> 2014-75, predicted 1.0\n",
      "Correct ::: song_key --> 2014-76, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-77, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-78, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-79, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-80, predicted 0.0\n",
      "Correct ::: song_key --> 2014-81, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-82, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-83, predicted 0.0\n",
      "Incorrect ::: song_key --> 2014-84, predicted 0.0\n",
      "Correct ::: song_key --> 2014-85, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-86, predicted 0.0\n",
      "Correct ::: song_key --> 2014-87, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-88, predicted 0.0\n",
      "Correct ::: song_key --> 2014-89, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-90, predicted 0.0\n",
      "Correct ::: song_key --> 2014-91, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-93, predicted 0.0\n",
      "Correct ::: song_key --> 2014-94, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-95, predicted 0.0\n",
      "Correct ::: song_key --> 2014-96, predicted 1.0\n",
      "Correct ::: song_key --> 2014-97, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-98, predicted 0.0\n",
      "Correct ::: song_key --> 2014-99, predicted 1.0\n",
      "Incorrect ::: song_key --> 2014-100, predicted 0.0\n",
      "Pipeline1 hits: 59, misses: 40\n"
     ]
    }
   ],
   "source": [
    "printPredicts(lyrics_pd_df[lyrics_pd_df['year'] == 2014],pred_hits1,pipeline_name=\"Pipeline1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : VIZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pipeline2\n",
    "**Word Vector approach**\n",
    "\n",
    "####TODO: IMPLEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column lyrics must be of type ArrayType(StringType,true) but was actually StringType.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-bc16e33abb5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Fit the pipeline to training documents.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vagrant/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m--> 538\u001b[1;33m                 self.target_id, self.name)\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column lyrics must be of type ArrayType(StringType,true) but was actually StringType."
     ]
    }
   ],
   "source": [
    "## \n",
    "tok2 = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
    "htf2 = HashingTF(inputCol=tok2.getOutputCol(), outputCol=\"tf\", numFeatures=200)\n",
    "w2v = Word2Vec(inputCol=\"lyrics\", outputCol=\"w2v\")\n",
    "ohe = OneHotEncoder(inputCol=\"label\", outputCol=\"lbl\")\n",
    "va = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"lbl\"], outputCol=\"features\")\n",
    "pipeline2 = Pipeline(stages=[tok,htf,w2v,ohe,va])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline2.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Try per decade predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
