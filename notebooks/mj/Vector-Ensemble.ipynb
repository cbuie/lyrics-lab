{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vector Ensemble\n",
    "Ensemble approach using Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SET DECADE (OR NOT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if decade is set, then filter results accordingly.\n",
    "decade = None\n",
    "# decade = 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "# Depending on your setup you might have to change this line of code\n",
    "#findspark makes sure I dont need the below on homebrew.\n",
    "#os.environ['SPARK_HOME']=\"/usr/local/Cellar/apache-spark/1.5.1/libexec/\"\n",
    "#the below actually broke my spark, so I removed it. \n",
    "#Depending on how you started the notebook, you might need it.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS']=\"--master local pyspark --executor-memory 4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local[4]')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.executor.memory', u'2g'),\n",
       " (u'spark.master', u'local[4]'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.driver.memory', u'8g'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.name', u'pyspark')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(2),2)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup Data For Pipeline\n",
    "###Load and manipulate with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the lyrics from the approved \"master\" dataframe\n",
    "lyrics_pd_df = pd.read_csv(\"../../data/conditioned/use-this-master-lyricsdf-extracted.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if decade:\n",
    "    lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['decade'] == decade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Labels for Data based on position\n",
    "**Note: Spark ML seems picky about `label` being the column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use positions for labeling\n",
    "positions_10_percent = {\n",
    "  10.0:range(1,11),\n",
    "  20.0:range(11,21),\n",
    "  30.0:range(21,31),\n",
    "  40.0:range(31,41),\n",
    "  50.0:range(41,51),\n",
    "  60.0:range(51,61), \n",
    "  70.0:range(61,71),\n",
    "  80.0:range(71,81),\n",
    "  90.0:range(81,91),\n",
    "  100.0:range(91,101)  \n",
    "}\n",
    "\n",
    "positions_25_percent = {\n",
    "  25.0:range(1,26),\n",
    "  50.0:range(26,51),\n",
    "  75.0:range(51,76),\n",
    "  100.0:range(76,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 25\n",
    "positions_top_25 = {\n",
    "  0.0:range(1,26),\n",
    "  1.0:range(26,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 50\n",
    "positions_top_50 = {\n",
    "  0.0:range(1,51),\n",
    "  1.0:range(51,101)\n",
    "}\n",
    "\n",
    "def labelForPosition(pos, positions=positions_top_50):\n",
    "    for k,p in positions.iteritems():\n",
    "        if pos in p:\n",
    "            return k\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test label lookup\n",
    "labelForPosition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label is position, e.g. 1-10, in this use\n",
    "lyrics_pd_df['label'] = lyrics_pd_df.position.apply(labelForPosition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>767</td>\n",
       "      <td>68</td>\n",
       "      <td>1977</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cold_as_Ice_(For...</td>\n",
       "      <td>Cold as Ice</td>\n",
       "      <td>Foreigner</td>\n",
       "      <td>You're as cold as ice. You're willing to sacri...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1977-68</td>\n",
       "      <td>http://lyrics.wikia.com/Foreigner:Cold_As_Ice</td>\n",
       "      <td>You're as cold as ice. You're willing to sacri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>3906</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I%27m_Yours_(Jas...</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>Well, you dawned on me and you bet I felt it. ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2009-7</td>\n",
       "      <td>http://lyrics.wikia.com/Jason_Mraz:I%27m_Yours</td>\n",
       "      <td>Well, you dawned on me and you bet I felt it. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>3596</td>\n",
       "      <td>97</td>\n",
       "      <td>2005</td>\n",
       "      <td>https://en.wikipedia.org/wiki/U_Already_Know</td>\n",
       "      <td>U Already Know</td>\n",
       "      <td>112</td>\n",
       "      <td>uhh,112.uhh. Papa coming home, to give you som...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2005-97</td>\n",
       "      <td>http://lyrics.wikia.com/112:U_Already_Know</td>\n",
       "      <td>uhh,112.uhh. Papa coming home, to give you som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>4382</td>\n",
       "      <td>83</td>\n",
       "      <td>2013</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Body_Party</td>\n",
       "      <td>Body Party</td>\n",
       "      <td>Ciara</td>\n",
       "      <td>My body is your party, baby. Nobody's invited ...</td>\n",
       "      <td>2010</td>\n",
       "      <td>2013-83</td>\n",
       "      <td>http://lyrics.wikia.com/Ciara:Body_Party</td>\n",
       "      <td>My body is your party, baby. Nobody's invited ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>74</td>\n",
       "      <td>1971</td>\n",
       "      <td>https://en.wikipedia.org/wiki/When_You%27re_Ho...</td>\n",
       "      <td>When You're Hot, You're Hot</td>\n",
       "      <td>Jerry Reed</td>\n",
       "      <td>Well me and Homer Jones and Big John Talley. H...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1971-74</td>\n",
       "      <td>http://lyrics.wikia.com/Jerry_Reed:When_You%27...</td>\n",
       "      <td>Well me and Homer Jones and Big John Talley. H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  position  year                                         title.href                        title      artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract  label\n",
       "767     767        68  1977  https://en.wikipedia.org/wiki/Cold_as_Ice_(For...                  Cold as Ice   Foreigner  You're as cold as ice. You're willing to sacri...    1970  1977-68      http://lyrics.wikia.com/Foreigner:Cold_As_Ice  You're as cold as ice. You're willing to sacri...      1\n",
       "3906   3906         7  2009  https://en.wikipedia.org/wiki/I%27m_Yours_(Jas...                    I'm Yours  Jason Mraz  Well, you dawned on me and you bet I felt it. ...    2000   2009-7     http://lyrics.wikia.com/Jason_Mraz:I%27m_Yours  Well, you dawned on me and you bet I felt it. ...      0\n",
       "3596   3596        97  2005       https://en.wikipedia.org/wiki/U_Already_Know               U Already Know         112  uhh,112.uhh. Papa coming home, to give you som...    2000  2005-97         http://lyrics.wikia.com/112:U_Already_Know  uhh,112.uhh. Papa coming home, to give you som...      1\n",
       "4382   4382        83  2013           https://en.wikipedia.org/wiki/Body_Party                   Body Party       Ciara  My body is your party, baby. Nobody's invited ...    2010  2013-83           http://lyrics.wikia.com/Ciara:Body_Party  My body is your party, baby. Nobody's invited ...      1\n",
       "173     173        74  1971  https://en.wikipedia.org/wiki/When_You%27re_Ho...  When You're Hot, You're Hot  Jerry Reed  Well me and Homer Jones and Big John Talley. H...    1970  1971-74  http://lyrics.wikia.com/Jerry_Reed:When_You%27...  Well me and Homer Jones and Big John Talley. H...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.sample(5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Filter out Non-Lyric Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many empties are there? 103\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls\n",
    "empties = np.where(pd.isnull(lyrics_pd_df[['lyrics']]))\n",
    "print \"How many empties are there? {}\".format(len(empties[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instrumentals are there? 20\n"
     ]
    }
   ],
   "source": [
    "# Check for instrumental mustic\n",
    "instrumentals = np.where(lyrics_pd_df[['lyrics']].applymap(lambda x: x == 'Instrumental'))\n",
    "print \"How many instrumentals are there? {}\".format(len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many total non-lyrics are there? 123\n"
     ]
    }
   ],
   "source": [
    "# total non-lyrics\n",
    "print \"How many total non-lyrics are there? {}\".format(len(empties[0]) + len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out null lyrics\n",
    "lyrics_pd_df = lyrics_pd_df.dropna(axis=0, how='any', thresh=None, subset=['lyrics'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4397, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out instrumentals\n",
    "lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['lyrics'] != 'Instrumental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4377, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load Corpus and Vocab(s) As Needed\n",
    "**\n",
    "NOTES:\n",
    "* These files need to be locally unzipped, e.g. the `corpus_vocabs.7z` under `data` folder\n",
    "* The unzipped files should not be added back to GitHub, they are excluded in .gitignore\n",
    "* It is assumed that the .7z are unzipped into their own folder\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildFilename = (lambda name, decade, ext : name + str(decade) + \".\" + ext if decade else name + \".\" + ext) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using base_path -->  ../../data/conditioned/corpus_vocabs/\n"
     ]
    }
   ],
   "source": [
    "# base_path will get manipulated based on decade or not\n",
    "base_path = \"../../data/conditioned/\"\n",
    "if decade:\n",
    "    base_path = base_path + \"decades/\" + str(decade) + \"/\"\n",
    "else:\n",
    "    base_path = base_path + \"corpus_vocabs/\"\n",
    "\n",
    "print \"Will be using base_path --> \",base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## with base path set, load up needed resources\n",
    "\n",
    "corpus = None # this is a pickle file\n",
    "adjid2word = None\n",
    "nounid2word = None\n",
    "\n",
    "# corpus\n",
    "try:   \n",
    "    corpus = pickle.load( open(base_path + buildFilename(\"corpus\",decade,\"p\") , \"rb\" ) ) \n",
    "except Exception as e:\n",
    "    print \"unable to find corpus{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# adjid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"adjid2word\",decade,\"json\"), 'r') as fp:\n",
    "        adjid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find adjid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# nounid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"nounid2word\",decade,\"json\"), 'r') as fp:\n",
    "        nounid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find nounid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is corpus?  35472\n",
      "How big is adjid2word?  3379\n",
      "How big is nounid2word?  5144\n"
     ]
    }
   ],
   "source": [
    "print \"How big is corpus? \", len(corpus)\n",
    "print \"How big is adjid2word? \", len(adjid2word)\n",
    "print \"How big is nounid2word? \", len(nounid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(5139, 1)], [(135, 1), (1887, 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'suicidal'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'jockin'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration: Alter `corpus` to use column `position` as a label\n",
    "Idea: take a percentile of data base on position range (1-10, 11-20, etc) to label where songs fall in the charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert and manipulate with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert from pandas to spark dataframe\n",
    "lyricsdf = sqlsc.createDataFrame(lyrics_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "|index|position|year|          title.href|               title|             artist|              lyrics|decade|song_key|          lyrics_url|     lyrics_abstract|label|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "|    0|       1|1970|https://en.wikipe...|Bridge over Troub...|Simon and Garfunkel|When you're weary...|  1970|  1970-1|http://lyrics.wik...|When you're weary...|  0.0|\n",
      "|    1|       2|1970|https://en.wikipe...|(They Long to Be)...|     The Carpenters|Why do birds sudd...|  1970|  1970-2|http://lyrics.wik...|Why do birds sudd...|  0.0|\n",
      "|    2|       3|1970|https://en.wikipe...|      American Woman|      The Guess Who|Mmm, da da da. Mm...|  1970|  1970-3|http://lyrics.wik...|Mmm, da da da. Mm...|  0.0|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline Using Spark\n",
    "Reference [combine all features into a single feature vector](https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html)\n",
    "![Ensemble Pipeline Overview](https://databricks.com/wp-content/uploads/2015/07/simple-pipeline.png)\n",
    "* Tokenizer\n",
    "* HashingTF\n",
    "* Word2Vec\n",
    "* OneHotEncoder\n",
    "* Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Fri, 27 Nov 2015 04:48:37\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 33.9 ms, total: 50.6 ms\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Pipeline adapted from:\n",
    "# http://spark.apache.org/docs/latest/ml-guide.html\n",
    "# https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "LabeledDocument = Row(\"song_key\", \"lyrics\", \"label\")\n",
    "\n",
    "# training on songs to 2013\n",
    "training = lyricsdf.filter(lyricsdf['year'] != 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "## ML Pipeline \n",
    "tok = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
    "htf = HashingTF(inputCol=tok.getOutputCol(), outputCol=\"features\", numFeatures=200)\n",
    "\n",
    "## path1 (need to work on input using corpus)\n",
    "# w2v = Word2Vec(inputCol=\"lyrics\", outputCol=\"w2v\")\n",
    "# ohe = OneHotEncoder(inputCol=\"label\", outputCol=\"lbl\")\n",
    "# va = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"lbl\"], outputCol=\"features\")\n",
    "# pipeline = Pipeline(stages=[tok,htf,w2v,ohe,va])\n",
    "\n",
    "## path2: three stages: tokenizer, hashingTF, and lr.\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tok, htf, lr])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test year 2014\n",
    "test = lyricsdf.filter(lyricsdf['year'] == 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"song_key\", \"lyrics\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print type(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up predictions\n",
    "pred_hits = {}\n",
    "for row in selected.collect():\n",
    "    pred_hits[row[0]] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check, predicted 2010-1 in top 25 correctly.\n",
    "pred_hits['2014-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How did we do at predicting top 50 hits for 2014 in light of hits prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct   ::: song_key --> 2014-1, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-2, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-3, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-4, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-5, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-6, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-7, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-8, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-9, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-10, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-11, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-12, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-13, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-14, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-15, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-16, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-17, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-18, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-19, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-20, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-21, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-22, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-23, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-24, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-25, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-26, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-27, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-28, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-29, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-30, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-31, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-32, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-33, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-34, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-35, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-36, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-37, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-38, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-39, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-40, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-41, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-42, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-43, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-44, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-45, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-46, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-47, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-48, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-49, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-50, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-51, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-52, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-53, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-54, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-55, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-56, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-57, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-58, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-59, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-60, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-61, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-62, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-63, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-64, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-65, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-66, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-67, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-68, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-69, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-70, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-71, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-72, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-73, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-74, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-75, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-76, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-77, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-78, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-79, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-80, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-81, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-82, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-83, predicted top 25? 0.0\n",
      "Incorrect ::: song_key --> 2014-84, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-85, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-86, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-87, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-88, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-89, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-90, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-91, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-93, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-94, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-95, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-96, predicted top 25? 1.0\n",
      "Correct   ::: song_key --> 2014-97, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-98, predicted top 25? 0.0\n",
      "Correct   ::: song_key --> 2014-99, predicted top 25? 1.0\n",
      "Incorrect ::: song_key --> 2014-100, predicted top 25? 0.0\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "for r in lyrics_pd_df[lyrics_pd_df['year'] == 2014].iterrows():\n",
    "    song_key = r[1].song_key\n",
    "    pred = pred_hits[song_key]  \n",
    "    result = labelForPosition(r[1].position)\n",
    "    correct = result == pred\n",
    "    if correct:\n",
    "        hits +=1\n",
    "        print \"Correct   ::: song_key --> {}, predicted top 25? {}\".format(song_key, pred)\n",
    "    else:\n",
    "        misses +=1\n",
    "        print \"Incorrect ::: song_key --> {}, predicted top 25? {}\".format(song_key, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits: 59, misses: 40\n"
     ]
    }
   ],
   "source": [
    "print \"hits: {}, misses: {}\".format(hits,misses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
