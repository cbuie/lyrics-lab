{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vector Ensemble\n",
    "Ensemble approach using Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SET DECADE (OR NOT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if decade is set, then filter results accordingly.\n",
    "decade = None\n",
    "# decade = 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "# Depending on your setup you might have to change this line of code\n",
    "#findspark makes sure I dont need the below on homebrew.\n",
    "#os.environ['SPARK_HOME']=\"/usr/local/Cellar/apache-spark/1.5.1/libexec/\"\n",
    "#the below actually broke my spark, so I removed it. \n",
    "#Depending on how you started the notebook, you might need it.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS']=\"--master local pyspark --executor-memory 4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local[4]')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.executor.memory', u'2g'),\n",
       " (u'spark.master', u'local[4]'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.driver.memory', u'8g'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.name', u'pyspark')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(2),2)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup Data For Pipeline\n",
    "###Load and manipulate with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the lyrics from the approved \"master\" dataframe\n",
    "lyrics_pd_df = pd.read_csv(\"../../data/conditioned/use-this-master-lyricsdf-extracted.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if decade:\n",
    "    lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['decade'] == decade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Reduced Word and ID Vectors\n",
    "Add columns:\n",
    "* `noun_vector` for reduced words (as string separated by spaces)\n",
    "* `noun_id_vector` id vector (again as string separated by vector)\n",
    "* `ad_vector` for reduced words (as string separated by spaces)\n",
    "* `adj_id_vector` id vector (again as string separated by vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files needed (expects dir `corpus_vocabs` to be present)\n",
    "\n",
    "# load ncollect from file\n",
    "with open('../../data/conditioned/corpus_vocabs/noun-word-reduction.json', 'r') as fp:\n",
    "    nreduction = json.load(fp)\n",
    "    \n",
    "# load acollect from file\n",
    "with open('../../data/conditioned/corpus_vocabs/adj-word-reduction.json', 'r') as fp:\n",
    "    areduction = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'time', u'bridge', u'water']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nreduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reductionAsWordStr(reduction):\n",
    "    words = []\n",
    "    for r in reduction:\n",
    "        v = ' '.join([x.encode('ascii','ignore') for x in r])\n",
    "        words.append(v)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn_reduction = reductionAsWordStr(nreduction)\n",
    "wa_reduction = reductionAsWordStr(areduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time bridge water']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_reduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rough troubled']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_reduction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvdf = pd.DataFrame({'noun_vector': wn_reduction})  \n",
    "lyrics_pd_df1 = lyrics_pd_df.join(nvdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avdf = pd.DataFrame({'adj_vector': wa_reduction})  \n",
    "lyrics_pd_df = lyrics_pd_df1.join(avdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/(They_Long_to_Be...</td>\n",
       "      <td>(They Long to Be) Close to You</td>\n",
       "      <td>The Carpenters</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-2</td>\n",
       "      <td>http://lyrics.wikia.com/Carpenters:%28They_Lon...</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "      <td>dream starlight eye</td>\n",
       "      <td>true blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/American_Woman_(...</td>\n",
       "      <td>American Woman</td>\n",
       "      <td>The Guess Who</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-3</td>\n",
       "      <td>http://lyrics.wikia.com/The_Guess_Who:American...</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "      <td>woman mess mind mama thing time growin light y...</td>\n",
       "      <td>american important old coloured leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Raindrops_Keep_F...</td>\n",
       "      <td>Raindrops Keep Fallin' on My Head</td>\n",
       "      <td>B.J. Thomas</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-4</td>\n",
       "      <td>http://lyrics.wikia.com/B.J._Thomas:Raindrops_...</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "      <td>guy foot bed happiness step eye</td>\n",
       "      <td>big long red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/War_(Edwin_Starr...</td>\n",
       "      <td>War</td>\n",
       "      <td>Edwin Starr</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-5</td>\n",
       "      <td>http://lyrics.wikia.com/Edwin_Starr:War</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "      <td>god destruction life war unrest generation man...</td>\n",
       "      <td>good innocent younger young short precious fig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                              title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract                                        noun_vector                                         adj_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...         Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...                                  time bridge water                                     rough troubled\n",
       "1      1         2  1970  https://en.wikipedia.org/wiki/(They_Long_to_Be...     (They Long to Be) Close to You       The Carpenters  Why do birds suddenly appear. Everytime you ar...    1970   1970-2  http://lyrics.wikia.com/Carpenters:%28They_Lon...  Why do birds suddenly appear. Everytime you ar...                                dream starlight eye                                          true blue\n",
       "2      2         3  1970  https://en.wikipedia.org/wiki/American_Woman_(...                     American Woman        The Guess Who  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...    1970   1970-3  http://lyrics.wikia.com/The_Guess_Who:American...  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...  woman mess mind mama thing time growin light y...              american important old coloured leave\n",
       "3      3         4  1970  https://en.wikipedia.org/wiki/Raindrops_Keep_F...  Raindrops Keep Fallin' on My Head          B.J. Thomas  Raindrops are falling on my head. And just lik...    1970   1970-4  http://lyrics.wikia.com/B.J._Thomas:Raindrops_...  Raindrops are falling on my head. And just lik...                    guy foot bed happiness step eye                                       big long red\n",
       "4      4         5  1970  https://en.wikipedia.org/wiki/War_(Edwin_Starr...                                War          Edwin Starr  War, huh, yeah. What is it good for? Absolutel...    1970   1970-5            http://lyrics.wikia.com/Edwin_Starr:War  War, huh, yeah. What is it good for? Absolutel...  god destruction life war unrest generation man...  good innocent younger young short precious fig..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save Augmented DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics_pd_df.to_csv(\"../../data/conditioned/master-lyricsdf-word_vectors.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Labels for Data based on position\n",
    "**Note: Spark ML seems picky about `label` being the column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>3888</td>\n",
       "      <td>89</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://en.wikipedia.org/wiki/I_Remember_(Keys...</td>\n",
       "      <td>I Remember</td>\n",
       "      <td>Keyshia Cole</td>\n",
       "      <td>Ohhh. Remember. Ohhh, I remember. I wanna know...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008-89</td>\n",
       "      <td>http://lyrics.wikia.com/Keyshia_Cole:I_Remember</td>\n",
       "      <td>Ohhh. Remember. Ohhh, I remember. I wanna know...</td>\n",
       "      <td>love heart</td>\n",
       "      <td>deep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>3161</td>\n",
       "      <td>62</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stranger_in_My_H...</td>\n",
       "      <td>Stranger in My House</td>\n",
       "      <td>Tamia</td>\n",
       "      <td>I don't understand. You look just like the man...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001-62</td>\n",
       "      <td>http://lyrics.wikia.com/Tamia:Stranger_In_My_H...</td>\n",
       "      <td>I don't understand. You look just like the man...</td>\n",
       "      <td>stranger house</td>\n",
       "      <td>convinced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>3365</td>\n",
       "      <td>66</td>\n",
       "      <td>2003</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Like_Glue</td>\n",
       "      <td>Like Glue</td>\n",
       "      <td>Sean Paul</td>\n",
       "      <td>Yeah yeah, yeah yeah, feel dat trend now, yeah...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2003-66</td>\n",
       "      <td>http://lyrics.wikia.com/Sean_Paul:Like_Glue</td>\n",
       "      <td>Yeah yeah, yeah yeah, feel dat trend now, yeah...</td>\n",
       "      <td>girl road man haffi shooby seh dem mi promise ...</td>\n",
       "      <td>nuff little cutie hot cool di nuh wet mi big d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>2860</td>\n",
       "      <td>61</td>\n",
       "      <td>1998</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lately_(Divine_s...</td>\n",
       "      <td>Lately</td>\n",
       "      <td>Divine</td>\n",
       "      <td>Lately. Been thinkin bout you baby. Just sitti...</td>\n",
       "      <td>1990</td>\n",
       "      <td>1998-61</td>\n",
       "      <td>http://lyrics.wikia.com/Divine:Lately</td>\n",
       "      <td>Lately. Been thinkin bout you baby. Just sitti...</td>\n",
       "      <td>saddest day singin love song</td>\n",
       "      <td>sweet sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "      <td>1971</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Night_They_D...</td>\n",
       "      <td>The Night They Drove Old Dixie Down</td>\n",
       "      <td>Joan Baez</td>\n",
       "      <td>Virgil Caine is my name and I drove on the Dan...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1971-20</td>\n",
       "      <td>http://lyrics.wikia.com/Joan_Baez:The_Night_Th...</td>\n",
       "      <td>Virgil Caine is my name and I drove on the Dan...</td>\n",
       "      <td>winter night day come money father man brave</td>\n",
       "      <td>hungry alive old quick good working proud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  position  year                                         title.href                                title        artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract                                        noun_vector                                         adj_vector  label\n",
       "3888   3888        89  2008  https://en.wikipedia.org/wiki/I_Remember_(Keys...                           I Remember  Keyshia Cole  Ohhh. Remember. Ohhh, I remember. I wanna know...    2000  2008-89    http://lyrics.wikia.com/Keyshia_Cole:I_Remember  Ohhh. Remember. Ohhh, I remember. I wanna know...                                         love heart                                               deep      1\n",
       "3161   3161        62  2001  https://en.wikipedia.org/wiki/Stranger_in_My_H...                 Stranger in My House         Tamia  I don't understand. You look just like the man...    2000  2001-62  http://lyrics.wikia.com/Tamia:Stranger_In_My_H...  I don't understand. You look just like the man...                                     stranger house                                          convinced      1\n",
       "3365   3365        66  2003            https://en.wikipedia.org/wiki/Like_Glue                            Like Glue     Sean Paul  Yeah yeah, yeah yeah, feel dat trend now, yeah...    2000  2003-66        http://lyrics.wikia.com/Sean_Paul:Like_Glue  Yeah yeah, yeah yeah, feel dat trend now, yeah...  girl road man haffi shooby seh dem mi promise ...  nuff little cutie hot cool di nuh wet mi big d...      1\n",
       "2860   2860        61  1998  https://en.wikipedia.org/wiki/Lately_(Divine_s...                               Lately        Divine  Lately. Been thinkin bout you baby. Just sitti...    1990  1998-61              http://lyrics.wikia.com/Divine:Lately  Lately. Been thinkin bout you baby. Just sitti...                       saddest day singin love song                                          sweet sad      1\n",
       "119     119        20  1971  https://en.wikipedia.org/wiki/The_Night_They_D...  The Night They Drove Old Dixie Down     Joan Baez  Virgil Caine is my name and I drove on the Dan...    1970  1971-20  http://lyrics.wikia.com/Joan_Baez:The_Night_Th...  Virgil Caine is my name and I drove on the Dan...       winter night day come money father man brave          hungry alive old quick good working proud      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use positions for labeling\n",
    "positions_10_percent = {\n",
    "  10.0:range(1,11),\n",
    "  20.0:range(11,21),\n",
    "  30.0:range(21,31),\n",
    "  40.0:range(31,41),\n",
    "  50.0:range(41,51),\n",
    "  60.0:range(51,61), \n",
    "  70.0:range(61,71),\n",
    "  80.0:range(71,81),\n",
    "  90.0:range(81,91),\n",
    "  100.0:range(91,101)  \n",
    "}\n",
    "\n",
    "positions_25_percent = {\n",
    "  25.0:range(1,26),\n",
    "  50.0:range(26,51),\n",
    "  75.0:range(51,76),\n",
    "  100.0:range(76,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 25\n",
    "positions_top_25 = {\n",
    "  0.0:range(1,26),\n",
    "  1.0:range(26,101)\n",
    "}\n",
    "\n",
    "# binary classification for top 50\n",
    "positions_top_50 = {\n",
    "  0.0:range(1,51),\n",
    "  1.0:range(51,101)\n",
    "}\n",
    "\n",
    "# Here is the dictionary for this run. This is how the classification is being done.\n",
    "positions_description = \"Top 50 versus Bottom 50\"\n",
    "positions_dict = positions_top_50\n",
    "\n",
    "def labelForPosition(pos):\n",
    "    for k,p in positions_dict.iteritems():\n",
    "        if pos in p:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "#label is position, e.g. 1-10, in this use\n",
    "lyrics_pd_df['label'] = lyrics_pd_df.position.apply(labelForPosition)\n",
    "lyrics_pd_df.sample(5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Filter out Non-Lyric Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many empties are there? 159\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls\n",
    "empties = np.where(pd.isnull(lyrics_pd_df[['lyrics']]))\n",
    "print \"How many empties are there? {}\".format(len(empties[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instrumentals are there? 0\n"
     ]
    }
   ],
   "source": [
    "# Check for instrumental mustic\n",
    "instrumentals = np.where(lyrics_pd_df[['lyrics']].applymap(lambda x: x == 'Instrumental'))\n",
    "print \"How many instrumentals are there? {}\".format(len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many total non-lyrics are there? 159\n"
     ]
    }
   ],
   "source": [
    "# total non-lyrics\n",
    "print \"How many total non-lyrics are there? {}\".format(len(empties[0]) + len(instrumentals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out null lyrics\n",
    "lyrics_pd_df = lyrics_pd_df.dropna(axis=0, how='any', thresh=None, subset=['lyrics'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4341, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out instrumentals\n",
    "lyrics_pd_df = lyrics_pd_df[lyrics_pd_df['lyrics'] != 'Instrumental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4341, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Filtered Lyrics With Reduced Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load Corpus and Vocab(s) As Needed\n",
    "**\n",
    "NOTES:\n",
    "* These files need to be locally unzipped, e.g. the `corpus_vocabs.7z` under `data` folder\n",
    "* The unzipped files should not be added back to GitHub, they are excluded in .gitignore\n",
    "* It is assumed that the .7z are unzipped into their own folder\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildFilename = (lambda name, decade, ext : name + str(decade) + \".\" + ext if decade else name + \".\" + ext) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using base_path -->  ../../data/conditioned/corpus_vocabs/\n"
     ]
    }
   ],
   "source": [
    "# base_path will get manipulated based on decade or not\n",
    "base_path = \"../../data/conditioned/\"\n",
    "if decade:\n",
    "    base_path = base_path + \"decades/\" + str(decade) + \"/\"\n",
    "else:\n",
    "    base_path = base_path + \"corpus_vocabs/\"\n",
    "\n",
    "print \"Will be using base_path --> \",base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## with base path set, load up needed resources\n",
    "\n",
    "corpus = None # this is a pickle file\n",
    "adjid2word = None\n",
    "nounid2word = None\n",
    "\n",
    "# corpus\n",
    "try:   \n",
    "    corpus = pickle.load( open(base_path + buildFilename(\"corpus\",decade,\"p\") , \"rb\" ) ) \n",
    "except Exception as e:\n",
    "    print \"unable to find corpus{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# adjid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"adjid2word\",decade,\"json\"), 'r') as fp:\n",
    "        adjid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find adjid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)\n",
    "\n",
    "# nounid2word\n",
    "try:\n",
    "    with open(base_path + buildFilename(\"nounid2word\",decade,\"json\"), 'r') as fp:\n",
    "        nounid2word = json.load(fp)\n",
    "except Exception as e:\n",
    "    print \"unable to find nounid2word{} in directory '{}' (have you unzipped vocabs to a directory?), msg --> {}\".format((str(decade) if decade else \"\"),base_path,e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is corpus?  35472\n",
      "How big is adjid2word?  3379\n",
      "How big is nounid2word?  5144\n"
     ]
    }
   ],
   "source": [
    "print \"How big is corpus? \", len(corpus)\n",
    "print \"How big is adjid2word? \", len(adjid2word)\n",
    "print \"How big is nounid2word? \", len(nounid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(5139, 1)], [(135, 1), (1887, 1)]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'suicidal'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'jockin'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounid2word['0'] # keys are index over size of vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Manipulate `Corpus` into list of index ids per row\n",
    "**This list removes duplication of token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35472"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)\n",
    "corpus[:10]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for r in corpus:\n",
    "    cs = []\n",
    "    for c in r:\n",
    "        cs.append(str(c[0]))\n",
    "    corpus_list.append(\" \".join(cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5139', '135 1887', '135 1887', '135 1887', '135 1887', '135 1887', '135 1887', '327', '192 1621', '327']\n"
     ]
    }
   ],
   "source": [
    "print corpus_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35472"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert and manipulate with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert from pandas to spark dataframe\n",
    "lyricsdf = sqlsc.createDataFrame(lyrics_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|index|position|year|          title.href|               title|             artist|              lyrics|decade|song_key|          lyrics_url|     lyrics_abstract|         noun_vector|          adj_vector|label|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|    0|       1|1970|https://en.wikipe...|Bridge over Troub...|Simon and Garfunkel|When you're weary...|  1970|  1970-1|http://lyrics.wik...|When you're weary...|   time bridge water|      rough troubled|  0.0|\n",
      "|    1|       2|1970|https://en.wikipe...|(They Long to Be)...|     The Carpenters|Why do birds sudd...|  1970|  1970-2|http://lyrics.wik...|Why do birds sudd...| dream starlight eye|           true blue|  0.0|\n",
      "|    2|       3|1970|https://en.wikipe...|      American Woman|      The Guess Who|Mmm, da da da. Mm...|  1970|  1970-3|http://lyrics.wik...|Mmm, da da da. Mm...|woman mess mind m...|american importan...|  0.0|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline Using Spark\n",
    "Reference [combine all features into a single feature vector](https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html)\n",
    "![Ensemble Pipeline Overview](https://databricks.com/wp-content/uploads/2015/07/simple-pipeline.png)\n",
    "* Tokenizer\n",
    "* HashingTF\n",
    "* Word2Vec\n",
    "* OneHotEncoder\n",
    "* Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline adapted from:\n",
    "# http://spark.apache.org/docs/latest/ml-guide.html\n",
    "# https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used in common for printing predictions\n",
    "def printPredicts(predictsdf,pred_hits,pipeline_name=\"Pipeline\"):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    print \"How did {} do predicting {}?\".format(pipeline_name,positions_description)\n",
    "    for r in predictsdf.iterrows():\n",
    "        song_key = r[1].song_key\n",
    "        pred = pred_hits[song_key]  \n",
    "        result = labelForPosition(r[1].position)\n",
    "        correct = result == pred\n",
    "        if correct:\n",
    "            hits +=1\n",
    "            print \"Correct ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "        else:\n",
    "            misses +=1\n",
    "            print \"Incorrect ::: song_key --> {}, predicted {}\".format(song_key, pred)\n",
    "    print \"{} hits: {}, misses: {}\".format(pipeline_name,hits,misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO (HERE OR TABLEAU) -- VIZ Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Whole Corpus Approach: Fit a model to songs prior to 2013 and predict on 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-30d9b2b12c00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# augment lyricsdf with corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlyricsdf_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlyricsdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lyrics_tokenized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vagrant/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Alice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Bob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \"\"\"\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col should be Column\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "# augment lyricsdf with corpus\n",
    "lyricsdf_corpus = lyricsdf.withColumn(\"lyrics_tokenized\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training on songs to 2013\n",
    "training = lyricsdf.filter(lyricsdf['year'] != 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "# training_corpus on songs to 2013\n",
    "training_corpus = lyricsdf_corpus.filter(lyricsdf['year'] != 2014).select(['song_key','lyrics','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test year 2014\n",
    "test = lyricsdf.filter(lyricsdf['year'] == 2014).select(['song_key','lyrics','label'])\n",
    "\n",
    "# test_corpus year 2014\n",
    "test_corpus = lyricsdf_corpus.filter(lyricsdf['year'] == 2014).select(['song_key','lyrics','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pipeline 1 : Whole Document as Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "LabeledDocument = Row(\"song_key\", \"lyrics\", \"label\")\n",
    "\n",
    "## ML Pipeline \n",
    "tok1 = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
    "htf1 = HashingTF(inputCol=tok1.getOutputCol(), outputCol=\"features\", numFeatures=200)\n",
    "lr1 = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline1 = Pipeline(stages=[tok1, htf1, lr1])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model1 = pipeline1.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction1 = model1.transform(test)\n",
    "selected1 = prediction1.select(\"song_key\", \"lyrics\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(selected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up predictions\n",
    "pred_hits1 = {}\n",
    "for row in selected1.collect():\n",
    "    pred_hits1[row[0]] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quick check, predicted 2010-1 in top 25 correctly.\n",
    "pred_hits1['2014-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How did pipeline1 do at predicting top 50 hits for 2014 in light of hits prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printPredicts(lyrics_pd_df[lyrics_pd_df['year'] == 2014],pred_hits1,pipeline_name=\"Pipeline1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : VIZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pipeline2\n",
    "**Word Vector approach**\n",
    "\n",
    "####TODO: IMPLEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## \n",
    "tok2 = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
    "htf2 = HashingTF(inputCol=tok2.getOutputCol(), outputCol=\"tf\", numFeatures=200)\n",
    "w2v = Word2Vec(inputCol=\"lyrics\", outputCol=\"w2v\")\n",
    "ohe = OneHotEncoder(inputCol=\"label\", outputCol=\"lbl\")\n",
    "va = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"lbl\"], outputCol=\"features\")\n",
    "pipeline2 = Pipeline(stages=[tok,htf,w2v,ohe,va])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline2.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Try per decade predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
