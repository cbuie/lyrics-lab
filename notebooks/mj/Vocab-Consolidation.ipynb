{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vocab Consolidation\n",
    "### Adapted concepts from [HW1](https://github.com/cs109-students/michaeljohns-2015hw/blob/hw1/hw1.ipynb) and [HW5 Part1](https://github.com/cs109-students/michaeljohns-2015hw/blob/hw5/hw5part1.ipynb)\n",
    "\n",
    "**This notebook should be locally run by issuing `vagrant up` from project root, then locating the notebook at \"http:\\\\localhost:4545\". You may also need to issue `vagrant provision` to update any required resources.**\n",
    "\n",
    "The following artifacts will be established by manipulating the output of the processing pipeline for harvesting data, file [use-this-master-lyricsdf-extracted.csv](../../data/conditioned/use-this-master-lyricsdf-extracted.csv):\n",
    "* vocabs for noun and adj\n",
    "* n-gram for noun and adj\n",
    "* synonyms for noun and adj\n",
    "* hypernyms for noun and adj\n",
    "\n",
    "Other notes:\n",
    "* this notebook leverages and finalizes exploratory work in [Data-Exploration Notebook](Data-Exploration.ipynb).\n",
    "* outputs are anticipated to be combined in follow-on work for better latent factors, prediction, and recommendation processing (not reflected here)\n",
    "* in other notebooks that use the exact same contents as here, we will establish n-gram and vocab per decade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "# Depending on your setup you might have to change this line of code\n",
    "#findspark makes sure I dont need the below on homebrew.\n",
    "#os.environ['SPARK_HOME']=\"/usr/local/Cellar/apache-spark/1.5.1/libexec/\"\n",
    "#the below actually broke my spark, so I removed it. \n",
    "#Depending on how you started the notebook, you might need it.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS']=\"--master local pyspark --executor-memory 4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local[4]')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.executor.memory', u'2g'),\n",
       " (u'spark.master', u'local[4]'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.driver.memory', u'8g'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.name', u'pyspark')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Finalized Conditioned Data Into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the lyrics from the approved \"master\" dataframe\n",
    "lyrics_pd_df = pd.read_csv(\"../../data/conditioned/use-this-master-lyricsdf-extracted.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/(They_Long_to_Be...</td>\n",
       "      <td>(They Long to Be) Close to You</td>\n",
       "      <td>The Carpenters</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-2</td>\n",
       "      <td>http://lyrics.wikia.com/Carpenters:%28They_Lon...</td>\n",
       "      <td>Why do birds suddenly appear. Everytime you ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/American_Woman_(...</td>\n",
       "      <td>American Woman</td>\n",
       "      <td>The Guess Who</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-3</td>\n",
       "      <td>http://lyrics.wikia.com/The_Guess_Who:American...</td>\n",
       "      <td>Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Raindrops_Keep_F...</td>\n",
       "      <td>Raindrops Keep Fallin' on My Head</td>\n",
       "      <td>B.J. Thomas</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-4</td>\n",
       "      <td>http://lyrics.wikia.com/B.J._Thomas:Raindrops_...</td>\n",
       "      <td>Raindrops are falling on my head. And just lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/War_(Edwin_Starr...</td>\n",
       "      <td>War</td>\n",
       "      <td>Edwin Starr</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-5</td>\n",
       "      <td>http://lyrics.wikia.com/Edwin_Starr:War</td>\n",
       "      <td>War, huh, yeah. What is it good for? Absolutel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                              title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...         Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...\n",
       "1      1         2  1970  https://en.wikipedia.org/wiki/(They_Long_to_Be...     (They Long to Be) Close to You       The Carpenters  Why do birds suddenly appear. Everytime you ar...    1970   1970-2  http://lyrics.wikia.com/Carpenters:%28They_Lon...  Why do birds suddenly appear. Everytime you ar...\n",
       "2      2         3  1970  https://en.wikipedia.org/wiki/American_Woman_(...                     American Woman        The Guess Who  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...    1970   1970-3  http://lyrics.wikia.com/The_Guess_Who:American...  Mmm, da da da. Mmm, mmm, da da da. Mmm, mmm, d...\n",
       "3      3         4  1970  https://en.wikipedia.org/wiki/Raindrops_Keep_F...  Raindrops Keep Fallin' on My Head          B.J. Thomas  Raindrops are falling on my head. And just lik...    1970   1970-4  http://lyrics.wikia.com/B.J._Thomas:Raindrops_...  Raindrops are falling on my head. And just lik...\n",
       "4      4         5  1970  https://en.wikipedia.org/wiki/War_(Edwin_Starr...                                War          Edwin Starr  War, huh, yeah. What is it good for? Absolutel...    1970   1970-5            http://lyrics.wikia.com/Edwin_Starr:War  War, huh, yeah. What is it good for? Absolutel..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Manipulate With Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert from pandas to spark dataframe\n",
    "lyricsdf = sqlsc.createDataFrame(lyrics_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "|index|position|year|          title.href|               title|             artist|              lyrics|decade|song_key|          lyrics_url|     lyrics_abstract|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "|    0|       1|1970|https://en.wikipe...|Bridge over Troub...|Simon and Garfunkel|When you're weary...|  1970|  1970-1|http://lyrics.wik...|When you're weary...|\n",
      "|    1|       2|1970|https://en.wikipe...|(They Long to Be)...|     The Carpenters|Why do birds sudd...|  1970|  1970-2|http://lyrics.wik...|Why do birds sudd...|\n",
      "|    2|       3|1970|https://en.wikipe...|      American Woman|      The Guess Who|Mmm, da da da. Mm...|  1970|  1970-3|http://lyrics.wik...|Mmm, da da da. Mm...|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view output\n",
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "|index|position|year|          title.href|               title|             artist|              lyrics|decade|song_key|          lyrics_url|     lyrics_abstract|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "|    0|       1|1970|https://en.wikipe...|Bridge over Troub...|Simon and Garfunkel|When you're weary...|  1970|  1970-1|http://lyrics.wik...|When you're weary...|\n",
      "|    1|       2|1970|https://en.wikipe...|(They Long to Be)...|     The Carpenters|Why do birds sudd...|  1970|  1970-2|http://lyrics.wik...|Why do birds sudd...|\n",
      "|    2|       3|1970|https://en.wikipe...|      American Woman|      The Guess Who|Mmm, da da da. Mm...|  1970|  1970-3|http://lyrics.wik...|Mmm, da da da. Mm...|\n",
      "+-----+--------+----+--------------------+--------------------+-------------------+--------------------+------+--------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view output\n",
    "lyricsdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many songs do we have? 4500\n"
     ]
    }
   ],
   "source": [
    "#We cache the data to make sure it is only read once from disk\n",
    "lyricsdf.cache()\n",
    "print \"How many songs do we have?\", lyricsdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the schema? root\n",
      " |-- index: long (nullable = true)\n",
      " |-- position: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- title.href: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- lyrics: string (nullable = true)\n",
      " |-- decade: long (nullable = true)\n",
      " |-- song_key: string (nullable = true)\n",
      " |-- lyrics_url: string (nullable = true)\n",
      " |-- lyrics_abstract: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"What is the schema?\", lyricsdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Sample Lyrics (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initial sampling to take from each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether or not to sample lyrics, and how many to sample per year\n",
    "sample_lyrics = False\n",
    "PER_YEAR_SAMPLES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(your code here)\n",
    "def randomSubSampleLyrics(sparkdf,take=PER_YEAR_SAMPLES):    \n",
    "    # generate spark pairs as a tuple\n",
    "    br_pairs = sparkdf.map(lambda r: (r.year, r.song_key))\n",
    "    \n",
    "    # group by key for a list of reviews per business and collect\n",
    "    br_grouped = br_pairs.groupByKey().mapValues(lambda x: list(x)).collect()\n",
    "        \n",
    "    #sample after collect\n",
    "    br_sample = [np.random.choice(v, size=take, replace=False) for k,v in br_grouped]    \n",
    "    \n",
    "    #flatten into a list\n",
    "    return list(itertools.chain.from_iterable(br_sample))\n",
    "    \n",
    "small_song_keys = randomSubSampleLyrics(lyricsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No lyric sampling, full processing (change `sample_lyrics` value to `True` to sample)\n"
     ]
    }
   ],
   "source": [
    "if sample_lyrics:\n",
    "    print \"How many small_song_keys? \", len(small_song_keys)\n",
    "    small_song_keys[:5]\n",
    "else:\n",
    "    print \"No lyric sampling, full processing (change `sample_lyrics` value to `True` to sample)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Tue, 24 Nov 2015 04:11:01\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 4 µs, total: 15 µs\n",
      "Wall time: 32.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#(your code here)\n",
    "if sample_lyrics:\n",
    "    ldf=lyricsdf[lyricsdf.song_key.isin(small_song_keys)]#creates new dataframe\n",
    "else:\n",
    "    ldf=lyricsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[index: bigint, position: bigint, year: bigint, title.href: string, title: string, artist: string, lyrics: string, decade: bigint, song_key: string, lyrics_url: string, lyrics_abstract: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "ldf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many lyrics are in ldf?  4500\n"
     ]
    }
   ],
   "source": [
    "print \"How many lyrics are in ldf? \", ldf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick Test of parse...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'The/DT/B-NP/O/the world/NN/I-NP/O/world is/VBZ/B-VP/O/be the/DT/B-NP/O/the craziest/JJ/I-NP/O/craziest place/NN/I-NP/O/place ././O/O/.\\nI/PRP/B-NP/O/i am/VBP/B-VP/O/be working/VBG/I-VP/O/work hard/RB/B-ADVP/O/hard ././O/O/.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Quick Test of parse...\"\n",
    "parse(\"The world is the craziest place. I am working hard.\", tokenize=True, lemmata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check of get_parts ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[u'patio', u'job'], [u'lunch', u'egg']], [[u'perfect'], [u'good', u'great']])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Quick check of get_parts ...\"\n",
    "get_parts(\"Have had many other items and just love the food. The patio...job was and...perfect. Lunch is good, and the only egg is great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Run Get Parts on Provided Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(your code here)\n",
    "lyric_parts = ldf.map(lambda r : get_parts(r.lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[u'time'],\n",
       "   [u'bridge', u'water'],\n",
       "   [u'bridge', u'water'],\n",
       "   [u'bridge', u'water'],\n",
       "   [u'bridge', u'water'],\n",
       "   [u'bridge', u'water'],\n",
       "   [u'bridge', u'water']],\n",
       "  [[u'rough'],\n",
       "   [u'troubled'],\n",
       "   [u'troubled'],\n",
       "   [u'troubled'],\n",
       "   [u'troubled'],\n",
       "   [u'troubled'],\n",
       "   [u'troubled']]),\n",
       " ([[u'dream'], [u'starlight', u'eye'], [u'dream'], [u'starlight', u'eye']],\n",
       "  [[u'true'], [u'blue'], [u'true'], [u'blue']])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "lyric_parts.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Tue, 24 Nov 2015 04:11:55\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 21.8 ms, total: 161 ms\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parseout=lyric_parts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Vocab\n",
    "###Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many parseout entries?  4500\n"
     ]
    }
   ],
   "source": [
    "print \"How many parseout entries? \", len(parseout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten parseout to create initial noun rdd\n",
    "nounrdd=sc.parallelize([ele[0] for ele in parseout]).flatMap(lambda l: l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'time']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "nounrdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[34] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "nounrdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# straight reduce for overall word counts\n",
    "nwordsrdd = (nounrdd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'jockin', 1),\n",
       " (u'slope', 1),\n",
       " (u'girl(oh', 1),\n",
       " (u'dance', 216),\n",
       " (u'pigeon', 3)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "nwordsrdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'love', 2390),\n",
       " (u'baby', 1665),\n",
       " (u'girl', 1583),\n",
       " (u'time', 1544),\n",
       " (u'thing', 1097),\n",
       " (u'night', 1003),\n",
       " (u'man', 918),\n",
       " (u'way', 881),\n",
       " (u'day', 830),\n",
       " (u'heart', 802)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top n, based on values, sorted descending\n",
    "nwordsrdd.takeOrdered(10, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[41] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwordsrdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect all the words and cache\n",
    "nounvocabtups = (nwordsrdd\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'jockin', 0), (u'slope', 1), (u'girl(oh', 2)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "nounvocabtups.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[44] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "nounvocabtups.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect results\n",
    "nounvocab=nounvocabtups.collectAsMap()\n",
    "nounid2word=nounvocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'jockin', u'catch', 728)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since sampling may be used, avoiding more common usage, e.g. `nounvocab['dance']`\n",
    "nounid2word[0], nounvocab.keys()[5], nounvocab[nounvocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is the noun vocabulary?  5144\n"
     ]
    }
   ],
   "source": [
    "print \"How big is the noun vocabulary? \", len(nounvocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create initial adj rdd from parseout\n",
    "adjrdd=sc.parallelize([ele[1] for ele in parseout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'rough'],\n",
       "  [u'troubled'],\n",
       "  [u'troubled'],\n",
       "  [u'troubled'],\n",
       "  [u'troubled'],\n",
       "  [u'troubled'],\n",
       "  [u'troubled']],\n",
       " [[u'true'], [u'blue'], [u'true'], [u'blue']],\n",
       " [[u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'important'],\n",
       "  [u'old'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'coloured'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'american'],\n",
       "  [u'coloured'],\n",
       "  [u'american'],\n",
       "  [u'leave'],\n",
       "  [u'american'],\n",
       "  [u'american']]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "adjrdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[46] at parallelize at PythonRDD.scala:423"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "adjrdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# straight reduce for overall word counts\n",
    "awordsrdd = (adjrdd\n",
    "             .flatMap(lambda l: l)\n",
    "             .flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'suicidal', 2),\n",
       " (u'hooked', 21),\n",
       " (u'resist', 1),\n",
       " (u'dynamic', 3),\n",
       " (u'cocky', 2)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "awordsrdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'little', 1838),\n",
       " (u'good', 1727),\n",
       " (u'real', 946),\n",
       " (u'bad', 770),\n",
       " (u'new', 764),\n",
       " (u'big', 678),\n",
       " (u'true', 649),\n",
       " (u'sweet', 635),\n",
       " (u'ooh', 607),\n",
       " (u'long', 579)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top n, based on values, sorted descending\n",
    "awordsrdd.takeOrdered(10, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[54] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "awordsrdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(your code here)\n",
    "adjvocabtups = (awordsrdd\n",
    "              .map(lambda (x,y): x)\n",
    "              .zipWithIndex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'suicidal', 0), (u'hooked', 1), (u'resist', 2)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "adjvocabtups.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[57] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache results\n",
    "adjvocabtups.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect results\n",
    "adjvocab=adjvocabtups.collectAsMap()\n",
    "adjid2word=adjvocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'suicidal', u'suspenseful', 1696)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since sampling may be used, avoiding more common usage, e.g. `adjvocab['exotic']`\n",
    "adjid2word[0], adjvocab.keys()[5], adjvocab[adjvocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is the adjective vocabulary?  3379\n"
     ]
    }
   ],
   "source": [
    "print \"How big is the adjective vocabulary? \", len(adjvocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Document Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# CITATION - Use of counter for reduce within each word list from:\n",
    "# http://stackoverflow.com/questions/2600191/how-can-i-count-the-occurrences-of-a-list-item-in-python\n",
    "##################################################################################################\n",
    "from collections import Counter\n",
    "\n",
    "# for each sentence, reduct into a list of tuple k,v where k=vocab index and v=count, \n",
    "# each word list is sorted by occurence\n",
    "documents = nounrdd.map(lambda words: Counter([nounvocab[word] for word in words]).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(5139, 1)]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify output\n",
    "documents.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather spark results\n",
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save Spark Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save noun n-gram\n",
    "with open('../../data/conditioned/noun-n-gram.json', 'w') as fp:\n",
    "    json.dump(dict(nwordsrdd.collect()), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save adjective n-gram\n",
    "with open('../../data/conditioned/adj-n-gram.json', 'w') as fp:\n",
    "    json.dump(dict(awordsrdd.collect()), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save noun vocab and id2word\n",
    "with open('../../data/conditioned/nounvocab.json', 'w') as fp:\n",
    "    json.dump(nounvocab, fp)\n",
    "    \n",
    "with open('../../data/conditioned/nounid2word.json', 'w') as fp:\n",
    "    json.dump(nounid2word, fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save adj vocab and id2word\n",
    "with open('../../data/conditioned/adjvocab.json', 'w') as fp:\n",
    "    json.dump(adjvocab, fp)\n",
    "    \n",
    "with open('../../data/conditioned/adjid2word.json', 'w') as fp:\n",
    "    json.dump(adjid2word, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save corpus\n",
    "pickle.dump( corpus, open( \"../../data/conditioned/corpus.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Synonym Lookups\n",
    "Focus on WordNet python package within [nltk](http://www.nltk.org) via [textblob](https://textblob.readthedocs.org/en/dev/)\n",
    "The main idea is to lookup all words in the noun and adj vocab dictionaries and attempt to collapse down -- where possible -- to synonyms. The synonyms can be used for common_support also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob.wordnet import Synset\n",
    "from textblob.wordnet import NOUN\n",
    "from textblob.wordnet import ADJ\n",
    "\n",
    "SIM_THRESHOLD = 1.0 # Only act on values at/above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## COMMON METHODS FOR SYNSETS\n",
    "def synsetStr(syn):\n",
    "    \"\"\"\n",
    "    attempt to parse the string from a Synset, e.g. Synset('dog.n.01') would return 'dog'\n",
    "    return String or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return syn.name().split('.')[0]\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "def flattenSynsetValues(syn_dict, skip_invalid=True, replace_invalid=None):\n",
    "    \"\"\"\n",
    "    flatten synset values in dictionary using params\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for k,v in syn_dict.iteritems():\n",
    "        if v:\n",
    "            d[k] = synsetStr(v)\n",
    "        elif not skip_invalid:\n",
    "            d[k] = replace_invalid\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CORE FUNCTIONS FOR BUILDING SIMILARITY MATRIX\n",
    "\n",
    "def posToSingle(pos):\n",
    "    \"\"\"\n",
    "    Keep up with which pos values are implemented.\n",
    "    \"\"\"\n",
    "    if pos == NOUN:\n",
    "        return \"n\"\n",
    "    elif pos == ADJ:\n",
    "        return \"a\"\n",
    "    return None # essentially, else clause\n",
    "\n",
    "\n",
    "def cachedSynsetOrBuild(idx, syns, p, id_lookup):\n",
    "    \"\"\"\n",
    "    Build Synset for given `idx`, using the `id_lookup`.\n",
    "    Facilitate O(n) computational complexity by caching results.\n",
    "    \n",
    "    --- Input ---\n",
    "    idx: id to build and cache\n",
    "    syns: existing dictionary of synsets, with k: id, v: Synset or None\n",
    "    p: String pos value in the form needed for Synset generation, see `posToSingle`\n",
    "    id_lookup: dictionary for noun / adj to build n x n matrix of similarity.\n",
    "    \n",
    "    --- Return ---\n",
    "    Synset or None\n",
    "    \"\"\"\n",
    "    if idx in syns:\n",
    "        return syns[idx] \n",
    "        \n",
    "    # focus on `.01` only\n",
    "    try:                      \n",
    "        syn = Synset(\"{}.{}.01\".format(id_lookup[idx],p))\n",
    "        syns[idx] = syn\n",
    "        return syn\n",
    "    except Exception:\n",
    "        syns[idx] = None\n",
    "        return None\n",
    "\n",
    "def similarityMatrix(id2word, pos, take_n=None):\n",
    "    \"\"\"\n",
    "    ##############################################################\n",
    "    Build matrix of synsets for given id2word dictionary.    \n",
    "    Optionally, only build a similarity matrix for the first n values.\n",
    "    \n",
    "    --- Input ---    \n",
    "    id2word: dictionary for noun / adj to build n x n matrix of similarity.\n",
    "    pos: WordNet position, `NOUN` or `ADJ` imported based on needs\n",
    "    take_n: whether take the first n values for testing, default=None\n",
    "    \n",
    "    --- Return ---\n",
    "    return a tuple, t where\n",
    "    t[0]: n x n matrix with raw similarity score or zero\n",
    "    t[1]: dictionary of synsets with k: id, v: Synset or None\n",
    "    ##############################################################    \n",
    "    \"\"\"    \n",
    "    syns = {} # obtain O(n)\n",
    "    p = posToSingle(pos)\n",
    "    \n",
    "    # determine n\n",
    "    n = len(id2word)\n",
    "    if take_n:\n",
    "        n = take_n\n",
    "    \n",
    "    # n x n matrix, initialized with zeros \n",
    "    matrix = np.zeros((n,n))\n",
    "    \n",
    "    # populate\n",
    "    ns = range(n)\n",
    "    for i in ns:  \n",
    "        isyn = cachedSynsetOrBuild(i,syns,p,id2word)       \n",
    "        for j in ns:\n",
    "            # find j in synset\n",
    "            jsyn = None\n",
    "            if isyn:\n",
    "                jsyn = cachedSynsetOrBuild(j,syns,p,id2word) # no reason unless isyn is ok\n",
    "        \n",
    "            # update matrix with path_similarity between i and j words\n",
    "            if isyn and jsyn:            \n",
    "                ps = isyn.path_similarity(jsyn)            \n",
    "                if ps:\n",
    "                    matrix[i][j] = ps\n",
    "            \n",
    "    return matrix, syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS FOR EVALUATING SIMILARITY MATRIX RESULTS\n",
    "\n",
    "def printSimilarityPairs(matrix, show_n=None, id_lookup=None, sim_threshold=SIM_THRESHOLD): \n",
    "    \"\"\"\n",
    "    print non zero similarities, ignoring diagonals.\n",
    "    Optionally, show only first n non zeros then return.\n",
    "    Optionally, lookup ids with words.\n",
    "    Optionally, only evaluate values at/above a threshold.\n",
    "    \"\"\"\n",
    "    ns = range(len(matrix))      \n",
    "    c = 0\n",
    "    for i in ns:\n",
    "        for j in ns:\n",
    "            v = matrix[i][j] \n",
    "            \n",
    "            # handle sim_threshold\n",
    "            met_threshold = True\n",
    "            if sim_threshold and v < sim_threshold:\n",
    "                met_threshold = False\n",
    "            elif not v:\n",
    "                met_threshold = False\n",
    "                    \n",
    "            if (i != j) and met_threshold:                \n",
    "                if not show_n or c < show_n:\n",
    "                    c += 1\n",
    "                    s_i = i\n",
    "                    s_j = j\n",
    "                    if id_lookup:\n",
    "                        s_i = id_lookup[i]\n",
    "                        s_j = id_lookup[j]\n",
    "                    print \"{},{} --> {}\".format(s_i,s_j,v)\n",
    "                elif show_n:\n",
    "                    return\n",
    "                \n",
    "def countSimilarityPairs(matrix, sim_threshold=SIM_THRESHOLD):\n",
    "    \"\"\"\n",
    "    count non zero similarities, ignoring diagonals.\n",
    "    Optionally, only evaluate values at/above a threshold.    \n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    ns = range(len(matrix))         \n",
    "    for i in ns:\n",
    "        for j in ns:\n",
    "            v = matrix[i][j]\n",
    "            \n",
    "            # handle sim_threshold\n",
    "            met_threshold = True\n",
    "            if sim_threshold and v < sim_threshold:\n",
    "                met_threshold = False\n",
    "            elif not v:\n",
    "                met_threshold = False\n",
    "            \n",
    "            if (i != j) and met_threshold:                \n",
    "                c += 1                    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Tue, 24 Nov 2015 04:17:05\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 0 ns, total: 27.4 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build adj similarity matrix\n",
    "asimatrix, asyns = similarityMatrix(adjid2word, ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count non-zero similarities for adjectivies at/above SIM_THRESHOLD, ignoring diagonal\n",
    "countSimilarityPairs(asimatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crimson,ruby --> 1.0\n",
      "crimson,cherry --> 1.0\n",
      "crimson,scarlet --> 1.0\n",
      "crimson,red --> 1.0\n",
      "magic,magical --> 1.0\n",
      "aflame,ablaze --> 1.0\n",
      "small,little --> 1.0\n",
      "7th,seventh --> 1.0\n",
      "blue,bluish --> 1.0\n",
      "unsure,shy --> 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check adj similarity results, are they any good?\n",
    "printSimilarityPairs(asimatrix, show_n=10, id_lookup=adjid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution start --> Tue, 24 Nov 2015 04:19:04\n"
     ]
    }
   ],
   "source": [
    "print \"execution start --> {}\".format(time.strftime('%a, %d %b %Y %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 36s, sys: 7.07 s, total: 16min 44s\n",
      "Wall time: 16min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build noun similarity matrix (can take 30+ minutes!!!)\n",
    "nsimatrix, nsyns = similarityMatrix(nounid2word, NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count non-zero similarities for nouns at/above SIM_THRESHOLD, ignoring diagonal\n",
    "countSimilarityPairs(nsimatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep,slumber --> 1.0\n",
      "prick,motherfucker --> 1.0\n",
      "prick,bastard --> 1.0\n",
      "prick,asshole --> 1.0\n",
      "chatter,yack --> 1.0\n",
      "cavity,pit --> 1.0\n",
      "topic,subject --> 1.0\n",
      "tush,ass --> 1.0\n",
      "tush,derriere --> 1.0\n",
      "tush,fanny --> 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check noun similarity results, are they any good?\n",
    "printSimilarityPairs(nsimatrix, show_n = 10, id_lookup=nounid2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Similarity Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save asimatrix\n",
    "pickle.dump( asimatrix, open( \"../../data/conditioned/asimatrix.p\", \"wb\" ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten and save asyns\n",
    "with open('../../data/conditioned/asyns.json', 'w') as fp:\n",
    "    json.dump(flattenSynsetValues(asyns), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save nsimatrix\n",
    "pickle.dump( nsimatrix, open( \"../../data/conditioned/nsimatrix.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten and save nsyns\n",
    "with open('../../data/conditioned/nsyns.json', 'w') as fp:\n",
    "    json.dump(flattenSynsetValues(nsyns), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Hypernyms\n",
    "find the lowest common [hypernym](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy) between similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('carnivore.n.01')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick Test\n",
    "Synset('dog.n.01').lowest_common_hypernyms(Synset('cat.n.01'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CORE FUNCTIONS FOR BUILDING HYPERNYM\n",
    "\n",
    "def makeOrderedTuple(idx1, idx2):\n",
    "    if idx1 > idx2:\n",
    "        return (idx2,idx1) \n",
    "    return (idx1,idx2) \n",
    "\n",
    "def cachedHypernymOrBuild(idx1, idx2, syn_lookup, hypes, hype_as_str=True):\n",
    "    \"\"\"\n",
    "    Build Hypernym for given `idxtuple`, using the `syns_lookup`.\n",
    "    Facilitate O(n) computational complexity by caching results\n",
    "    Will internally manage hypernym keys as ordered tuple.\n",
    "    \n",
    "    --- Input ---\n",
    "    idx: tuple of id to build and cache\n",
    "    syn_lookup: existing dictionary of synsets, with k: id, v: Synset or None    \n",
    "    hypes: dictionary for hypernyms with k: ordered tuple, v: hypernym.\n",
    "    hype_as_str: optional build map with string values, default = True\n",
    "    --- Return ---\n",
    "    a hypernym Synset or None\n",
    "    \"\"\"\n",
    "    ituple = makeOrderedTuple(idx1,idx2)    \n",
    "    if ituple in hypes: \n",
    "        return hypes[ituple] \n",
    "    \n",
    "    try:    \n",
    "        s1 = syn_lookup[ituple[0]]\n",
    "        s2 = syn_lookup[ituple[1]]\n",
    "        h = s1.lowest_common_hypernyms(s2)[0]\n",
    "        \n",
    "        if hype_as_str:\n",
    "            h = synsetStr(h)\n",
    "            \n",
    "        hypes[ituple] = h\n",
    "        return h\n",
    "    except Exception:\n",
    "        hypes[ituple] = None\n",
    "        return None\n",
    "\n",
    "def lowestCommonHypernyms(simatrix, syn_lookup, sim_threshold=SIM_THRESHOLD, hype_as_str=True):\n",
    "    \"\"\"\n",
    "    Build a matrix with hypernym where found.\n",
    "    Optionally, only evaluate values at/above a threshold.\n",
    "    \n",
    "    --- Input ---\n",
    "    simatrix: tuple of id to build and cache\n",
    "    syn_lookup: existing dictionary of synsets, with k: id, v: Synset or None    \n",
    "    sim_threshold: optional threshold to use for establishing hypernyms, default = SIM_THRESHOLD\n",
    "    hype_as_str: optional build map with string values, default = True\n",
    "    \n",
    "    --- Return ---\n",
    "    dictionary for hypernyms with k: ordered tuple, v: Synset.    \n",
    "    \"\"\"\n",
    "    \n",
    "    hypes = {} # dictionary to build up.\n",
    "    \n",
    "    n = len(simatrix)\n",
    "    ns = range(n)          \n",
    "    for i in ns:\n",
    "        for j in ns:\n",
    "            v = simatrix[i][j] \n",
    "            \n",
    "            # handle sim_threshold\n",
    "            met_threshold = True\n",
    "            if sim_threshold and v < sim_threshold:\n",
    "                met_threshold = False\n",
    "            elif not v:\n",
    "                met_threshold = False\n",
    "                    \n",
    "            if (i != j) and met_threshold:                                \n",
    "                cachedHypernymOrBuild(i,j, syn_lookup, hypes, hype_as_str)\n",
    "                \n",
    "    return hypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS FOR EVALUATING HYPERNYMS\n",
    "\n",
    "def countHypernyms(hypes, count_valid=True, count_invalid=True):\n",
    "    \"\"\"\n",
    "    Count  hypernyms, ignoring None\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    for k,v in hypes.iteritems():\n",
    "        if count_valid and v:\n",
    "            c += 1\n",
    "        elif count_invalid and not v:\n",
    "            c += 1        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adjective Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find adj hypernyms, defaulting to only the string value\n",
    "ahypes = lowestCommonHypernyms(asimatrix, asyns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many adj hypernyms?  167\n",
      "how many valid adj hypernyms?  167\n",
      "how many invalid adj hypernyms?  0\n",
      "example key: (1581, 1687), value: grateful\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"how many adj hypernyms? \", countHypernyms(ahypes)\n",
    "print \"how many valid adj hypernyms? \", countHypernyms(ahypes, count_valid=True, count_invalid=False)\n",
    "print \"how many invalid adj hypernyms? \", countHypernyms(ahypes, count_valid=False, count_invalid=True)\n",
    "print \"example key: {}, value: {}\".format(ahypes.keys()[0],ahypes[ahypes.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(23, 570): u'red',\n",
       " (23, 1490): u'red',\n",
       " (23, 1630): u'red',\n",
       " (23, 1727): u'red',\n",
       " (40, 1467): u'charming',\n",
       " (43, 1534): u'ablaze',\n",
       " (49, 1960): u'small',\n",
       " (63, 81): u'seventh',\n",
       " (66, 2802): u'blue',\n",
       " (80, 1308): u'diffident',\n",
       " (100, 1041): u'icky',\n",
       " (100, 1505): u'icky',\n",
       " (100, 1947): u'icky',\n",
       " (134, 530): u'ignored',\n",
       " (174, 1812): u'enormous',\n",
       " (178, 930): u'casual',\n",
       " (191, 447): u'all_right',\n",
       " (191, 655): u'all_right',\n",
       " (193, 2240): u'cheery',\n",
       " (193, 2304): u'cheery',\n",
       " (207, 2757): u'nauseating',\n",
       " (211, 408): u'ferocious',\n",
       " (211, 564): u'ferocious',\n",
       " (237, 1159): u'awful',\n",
       " (265, 2225): u'boggy',\n",
       " (289, 2803): u'dizzy',\n",
       " (289, 3127): u'dizzy',\n",
       " (300, 1132): u'hairy',\n",
       " (309, 1660): u'ageless',\n",
       " (309, 2634): u'ageless',\n",
       " (309, 3215): u'ageless',\n",
       " (330, 2788): u'alone',\n",
       " (346, 1714): u'disgusting',\n",
       " (348, 2028): u'colossal',\n",
       " (350, 1786): u'adolescent',\n",
       " (354, 2645): u'extreme',\n",
       " (376, 2027): u'cockamamie',\n",
       " (376, 2812): u'cockamamie',\n",
       " (378, 481): u'bare',\n",
       " (378, 2377): u'bare',\n",
       " (408, 564): u'ferocious',\n",
       " (431, 3173): u'bare',\n",
       " (445, 1135): u'besotted',\n",
       " (447, 655): u'all_right',\n",
       " (458, 2189): u'cardinal',\n",
       " (481, 2377): u'bare',\n",
       " (520, 1733): u'religious',\n",
       " (529, 2605): u'instantaneous',\n",
       " (544, 792): u'bang-up',\n",
       " (544, 2303): u'bang-up',\n",
       " (544, 2866): u'bang-up',\n",
       " (562, 2170): u'firm',\n",
       " (570, 1490): u'red',\n",
       " (570, 1630): u'red',\n",
       " (570, 1727): u'red',\n",
       " (600, 1445): u'large',\n",
       " (640, 1977): u'untrimmed',\n",
       " (641, 2206): u'ephemeral',\n",
       " (675, 1035): u'crisp',\n",
       " (683, 879): u'bigheaded',\n",
       " (733, 3104): u'ace',\n",
       " (739, 836): u'favorite',\n",
       " (747, 3168): u'crazed',\n",
       " (759, 1432): u'chopped',\n",
       " (766, 2168): u'devilish',\n",
       " (769, 2940): u'bally',\n",
       " (785, 3128): u'cryptic',\n",
       " (792, 2303): u'bang-up',\n",
       " (792, 2866): u'bang-up',\n",
       " (824, 1899): u'amazing',\n",
       " (860, 3072): u'bronzed',\n",
       " (872, 3038): u'cutting',\n",
       " (893, 3060): u'talented',\n",
       " (902, 3109): u'honest',\n",
       " (915, 2569): u'brassy',\n",
       " (933, 1449): u'baronial',\n",
       " (956, 2672): u'entire',\n",
       " (961, 2583): u'colored',\n",
       " (971, 1625): u'aureate',\n",
       " (995, 2025): u'calm',\n",
       " (1001, 3001): u'chubby',\n",
       " (1015, 2036): u'deserving',\n",
       " (1016, 1719): u'huge',\n",
       " (1023, 3322): u'fried',\n",
       " (1041, 1505): u'icky',\n",
       " (1041, 1947): u'icky',\n",
       " (1054, 1537): u'barbarous',\n",
       " (1054, 2487): u'barbarous',\n",
       " (1061, 3378): u'eighth',\n",
       " (1069, 1556): u'nightlong',\n",
       " (1076, 2697): u'cunning',\n",
       " (1078, 2342): u'bitty',\n",
       " (1078, 3156): u'bitty',\n",
       " (1083, 3336): u'aroused',\n",
       " (1096, 1211): u'grey',\n",
       " (1160, 1508): u'grim',\n",
       " (1169, 2810): u'extremist',\n",
       " (1204, 1633): u'curious',\n",
       " (1213, 1554): u'sixth',\n",
       " (1232, 1718): u'greek',\n",
       " (1265, 2917): u'exclusive',\n",
       " (1296, 1542): u'wide',\n",
       " (1320, 1667): u'farthermost',\n",
       " (1364, 1459): u'blasted',\n",
       " (1379, 2410): u'frigid',\n",
       " (1381, 2938): u'laden',\n",
       " (1417, 2436): u'apparent',\n",
       " (1417, 2687): u'apparent',\n",
       " (1436, 1597): u'everyday',\n",
       " (1436, 3052): u'everyday',\n",
       " (1438, 2640): u'amusing',\n",
       " (1484, 2670): u'bogus',\n",
       " (1484, 3014): u'bogus',\n",
       " (1490, 1630): u'red',\n",
       " (1490, 1727): u'red',\n",
       " (1498, 1655): u'bum',\n",
       " (1505, 1947): u'icky',\n",
       " (1512, 2882): u'fantastic',\n",
       " (1520, 1757): u'ill-famed',\n",
       " (1537, 2487): u'barbarous',\n",
       " (1551, 2352): u'conceited',\n",
       " (1551, 2892): u'conceited',\n",
       " (1569, 2823): u'eighteenth',\n",
       " (1581, 1687): u'grateful',\n",
       " (1594, 3126): u'far-out',\n",
       " (1597, 3052): u'everyday',\n",
       " (1613, 1754): u'brumous',\n",
       " (1630, 1727): u'red',\n",
       " (1639, 3120): u'enamored',\n",
       " (1660, 2634): u'ageless',\n",
       " (1660, 3215): u'ageless',\n",
       " (1663, 2898): u'hurt',\n",
       " (1710, 3148): u'null',\n",
       " (1792, 2055): u'chunky',\n",
       " (1861, 2716): u'incredible',\n",
       " (2012, 2855): u'bushy',\n",
       " (2027, 2812): u'cockamamie',\n",
       " (2059, 2785): u'chief',\n",
       " (2111, 2268): u'fifth',\n",
       " (2166, 2584): u'jammed',\n",
       " (2198, 2517): u'ill',\n",
       " (2211, 2834): u'gay',\n",
       " (2216, 2922): u'humble',\n",
       " (2218, 2265): u'blond',\n",
       " (2228, 2739): u'bantam',\n",
       " (2240, 2304): u'cheery',\n",
       " (2303, 2866): u'bang-up',\n",
       " (2342, 3156): u'bitty',\n",
       " (2348, 3122): u'bigger',\n",
       " (2352, 2892): u'conceited',\n",
       " (2423, 2732): u'edgy',\n",
       " (2433, 2711): u'slender',\n",
       " (2436, 2687): u'apparent',\n",
       " (2438, 2601): u'deluxe',\n",
       " (2464, 2787): u'immaculate',\n",
       " (2475, 3160): u'aged',\n",
       " (2491, 2816): u'average',\n",
       " (2516, 2556): u'particular',\n",
       " (2634, 3215): u'ageless',\n",
       " (2670, 3014): u'bogus',\n",
       " (2759, 3012): u'classy',\n",
       " (2803, 3127): u'dizzy',\n",
       " (2821, 2893): u'difficult',\n",
       " (3065, 3313): u'fine-looking',\n",
       " (3095, 3275): u'permanent',\n",
       " (3096, 3348): u'coincident',\n",
       " (3161, 3188): u'coarse'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Noun Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find noun hypernyms\n",
    "nhypes = lowestCommonHypernyms(nsimatrix, nsyns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many noun hypernyms?  293\n",
      "how many valid noun hypernyms?  293\n",
      "how many invalid noun hypernyms?  0\n",
      "example key: (1172, 5051), value: bent\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"how many noun hypernyms? \", countHypernyms(nhypes)\n",
    "print \"how many valid noun hypernyms? \", countHypernyms(nhypes, count_valid=True, count_invalid=False)\n",
    "print \"how many invalid noun hypernyms? \", countHypernyms(nhypes, count_valid=False, count_invalid=True)\n",
    "print \"example key: {}, value: {}\".format(nhypes.keys()[0],nhypes[nhypes.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 1664): u'sleep',\n",
       " (13, 2406): u'asshole',\n",
       " (13, 3216): u'asshole',\n",
       " (13, 3859): u'asshole',\n",
       " (26, 98): u'yak',\n",
       " (27, 532): u'pit',\n",
       " (32, 4653): u'subject',\n",
       " (33, 449): u'buttocks',\n",
       " (33, 711): u'buttocks',\n",
       " (33, 1995): u'buttocks',\n",
       " (75, 225): u'attempt',\n",
       " (75, 313): u'attempt',\n",
       " (78, 4399): u'phase',\n",
       " (94, 4646): u'battle',\n",
       " (113, 1044): u'kingdom',\n",
       " (131, 295): u'chap',\n",
       " (131, 1767): u'chap',\n",
       " (131, 5081): u'chap',\n",
       " (144, 2608): u'scream',\n",
       " (153, 4740): u'amour_propre',\n",
       " (177, 704): u'purpose',\n",
       " (177, 2491): u'purpose',\n",
       " (180, 1039): u'bartender',\n",
       " (182, 2506): u'idea',\n",
       " (187, 3998): u'career',\n",
       " (197, 1600): u'fellow',\n",
       " (214, 223): u'baby',\n",
       " (218, 4225): u'component',\n",
       " (219, 1091): u'grief',\n",
       " (219, 4797): u'grief',\n",
       " (225, 313): u'attempt',\n",
       " (229, 300): u'millimeter',\n",
       " (231, 4022): u'past',\n",
       " (237, 1964): u'boom',\n",
       " (237, 2495): u'boom',\n",
       " (237, 4053): u'boom',\n",
       " (244, 3828): u'laugh',\n",
       " (260, 4034): u'fall',\n",
       " (273, 3240): u'play',\n",
       " (282, 969): u'dad',\n",
       " (282, 1293): u'dad',\n",
       " (282, 3641): u'dad',\n",
       " (282, 4485): u'dad',\n",
       " (282, 4667): u'dad',\n",
       " (295, 1767): u'chap',\n",
       " (295, 5081): u'chap',\n",
       " (299, 478): u'topographic_point',\n",
       " (319, 3081): u'narrative',\n",
       " (321, 4401): u'eating',\n",
       " (322, 3812): u'inside',\n",
       " (335, 843): u'dunce',\n",
       " (341, 3121): u'lookout',\n",
       " (341, 3957): u'lookout',\n",
       " (344, 2377): u'sofa',\n",
       " (344, 4093): u'sofa',\n",
       " (346, 402): u'wage',\n",
       " (346, 1640): u'wage',\n",
       " (366, 2289): u'person',\n",
       " (366, 5129): u'person',\n",
       " (373, 2787): u'hate',\n",
       " (376, 1441): u'answer',\n",
       " (400, 2232): u'violin',\n",
       " (402, 1640): u'wage',\n",
       " (412, 1162): u'adieu',\n",
       " (412, 3242): u'adieu',\n",
       " (422, 869): u'ace',\n",
       " (422, 4348): u'ace',\n",
       " (449, 711): u'buttocks',\n",
       " (449, 1995): u'buttocks',\n",
       " (467, 2641): u'animal',\n",
       " (467, 4066): u'animal',\n",
       " (471, 1190): u'girl',\n",
       " (471, 3044): u'girl',\n",
       " (474, 615): u'hood',\n",
       " (474, 3130): u'hood',\n",
       " (503, 3513): u'loot',\n",
       " (504, 4327): u'aroma',\n",
       " (521, 1294): u'ma',\n",
       " (521, 2771): u'ma',\n",
       " (521, 3642): u'ma',\n",
       " (521, 3759): u'ma',\n",
       " (523, 4309): u'filth',\n",
       " (545, 3649): u'rumor',\n",
       " (551, 2159): u'chump',\n",
       " (563, 1577): u'information',\n",
       " (584, 3458): u'second',\n",
       " (593, 2294): u'bait',\n",
       " (615, 3130): u'hood',\n",
       " (622, 3757): u'sphere',\n",
       " (646, 2217): u'sunset',\n",
       " (649, 1973): u'grandfather',\n",
       " (653, 3188): u'shop',\n",
       " (655, 4409): u'shooting',\n",
       " (656, 2996): u'crap',\n",
       " (656, 3847): u'crap',\n",
       " (657, 2227): u'ecstasy',\n",
       " (704, 2491): u'purpose',\n",
       " (711, 1995): u'buttocks',\n",
       " (713, 1263): u'cast',\n",
       " (716, 3020): u'motivation',\n",
       " (717, 3276): u'barroom',\n",
       " (742, 4275): u'touch',\n",
       " (757, 4316): u'morning',\n",
       " (763, 3947): u'grandma',\n",
       " (793, 2582): u'semen',\n",
       " (808, 2202): u'expression',\n",
       " (817, 1885): u'speaker',\n",
       " (847, 4459): u'marriage',\n",
       " (848, 2829): u'sister',\n",
       " (869, 4348): u'ace',\n",
       " (935, 1347): u'buddy',\n",
       " (940, 1071): u'eternity',\n",
       " (941, 2442): u'thunderbolt',\n",
       " (953, 3729): u'cheep',\n",
       " (958, 3848): u'opportunity',\n",
       " (960, 4116): u'cocoa',\n",
       " (969, 1293): u'dad',\n",
       " (969, 3641): u'dad',\n",
       " (969, 4485): u'dad',\n",
       " (969, 4667): u'dad',\n",
       " (974, 2212): u'clasp',\n",
       " (974, 3938): u'clasp',\n",
       " (980, 3732): u'vicinity',\n",
       " (1000, 2712): u'crop',\n",
       " (1001, 2396): u'prisoner',\n",
       " (1005, 2837): u'jesus',\n",
       " (1016, 3373): u'palette',\n",
       " (1018, 3800): u'pile',\n",
       " (1035, 1950): u'dark',\n",
       " (1061, 2642): u'bulge',\n",
       " (1065, 4577): u'seashore',\n",
       " (1081, 1244): u'freak',\n",
       " (1091, 4797): u'grief',\n",
       " (1154, 5102): u'guarantee',\n",
       " (1162, 3242): u'adieu',\n",
       " (1172, 5051): u'bent',\n",
       " (1175, 4265): u'twilight',\n",
       " (1179, 1365): u'urine',\n",
       " (1179, 4546): u'urine',\n",
       " (1181, 2917): u'macintosh',\n",
       " (1190, 3044): u'girl',\n",
       " (1221, 3038): u'hush',\n",
       " (1223, 2868): u'spirit',\n",
       " (1226, 1493): u'limousine',\n",
       " (1242, 3175): u'kind',\n",
       " (1268, 4858): u'breast',\n",
       " (1281, 2340): u'ballyhoo',\n",
       " (1293, 3641): u'dad',\n",
       " (1293, 4485): u'dad',\n",
       " (1293, 4667): u'dad',\n",
       " (1294, 2771): u'ma',\n",
       " (1294, 3642): u'ma',\n",
       " (1294, 3759): u'ma',\n",
       " (1310, 3697): u'clang',\n",
       " (1314, 1956): u'moonlight',\n",
       " (1323, 3894): u'anguish',\n",
       " (1365, 4546): u'urine',\n",
       " (1367, 4789): u'doctor',\n",
       " (1386, 1464): u'die',\n",
       " (1413, 4033): u'position',\n",
       " (1415, 1947): u'manner',\n",
       " (1415, 2969): u'manner',\n",
       " (1415, 3156): u'manner',\n",
       " (1415, 4462): u'manner',\n",
       " (1454, 4096): u'rug',\n",
       " (1503, 4258): u'rotter',\n",
       " (1503, 4413): u'rotter',\n",
       " (1504, 2245): u'ice_lolly',\n",
       " (1527, 2224): u'telephone',\n",
       " (1529, 2613): u'adult',\n",
       " (1530, 2863): u'smile',\n",
       " (1540, 1828): u'car',\n",
       " (1568, 1789): u'fabric',\n",
       " (1605, 4189): u'criminal',\n",
       " (1605, 4600): u'criminal',\n",
       " (1703, 1875): u'hallway',\n",
       " (1751, 1983): u'lurch',\n",
       " (1767, 5081): u'chap',\n",
       " (1784, 4059): u'baggage',\n",
       " (1790, 2269): u'suburb',\n",
       " (1830, 4772): u'waist',\n",
       " (1832, 3577): u'wanderer',\n",
       " (1846, 4277): u'miniskirt',\n",
       " (1853, 2358): u'universe',\n",
       " (1873, 1936): u'calamity',\n",
       " (1873, 3186): u'calamity',\n",
       " (1889, 2776): u'smoke',\n",
       " (1912, 4269): u'enchantment',\n",
       " (1927, 4461): u'drunkard',\n",
       " (1936, 3186): u'calamity',\n",
       " (1942, 4767): u'plan',\n",
       " (1947, 2969): u'manner',\n",
       " (1947, 3156): u'manner',\n",
       " (1947, 4462): u'manner',\n",
       " (1964, 2495): u'boom',\n",
       " (1964, 4053): u'boom',\n",
       " (1966, 2238): u'consequence',\n",
       " (1968, 2303): u'impression',\n",
       " (1972, 2199): u'matter',\n",
       " (2018, 3015): u'sweetheart',\n",
       " (2029, 2464): u'drip',\n",
       " (2029, 4854): u'drip',\n",
       " (2064, 2278): u'longing',\n",
       " (2075, 3631): u'destiny',\n",
       " (2078, 3201): u'movie',\n",
       " (2078, 4114): u'movie',\n",
       " (2100, 4361): u'strut',\n",
       " (2120, 4780): u'state',\n",
       " (2163, 3000): u'knock',\n",
       " (2175, 4079): u'shingle',\n",
       " (2210, 2585): u'center',\n",
       " (2212, 3938): u'clasp',\n",
       " (2214, 4071): u'mistake',\n",
       " (2274, 4339): u'defender',\n",
       " (2289, 5129): u'person',\n",
       " (2301, 3780): u'summer',\n",
       " (2343, 2700): u'photograph',\n",
       " (2377, 4093): u'sofa',\n",
       " (2391, 2839): u'spring',\n",
       " (2406, 3216): u'asshole',\n",
       " (2406, 3859): u'asshole',\n",
       " (2417, 2449): u'religion',\n",
       " (2447, 3897): u'bullet',\n",
       " (2459, 3844): u'base',\n",
       " (2464, 4854): u'drip',\n",
       " (2481, 3589): u'hazard',\n",
       " (2495, 4053): u'boom',\n",
       " (2507, 4028): u'boogie',\n",
       " (2554, 4878): u'check',\n",
       " (2568, 4960): u'vacation',\n",
       " (2591, 3878): u'lunch',\n",
       " (2641, 4066): u'animal',\n",
       " (2664, 4744): u'intestine',\n",
       " (2672, 3761): u'pun',\n",
       " (2689, 4016): u'menace',\n",
       " (2695, 4204): u'guy',\n",
       " (2729, 5035): u'fillet',\n",
       " (2738, 4197): u'internet',\n",
       " (2771, 3642): u'ma',\n",
       " (2771, 3759): u'ma',\n",
       " (2796, 4223): u'athlete',\n",
       " (2814, 3150): u'ball',\n",
       " (2822, 3982): u'daze',\n",
       " (2873, 2962): u'bit',\n",
       " (2883, 4201): u'airplane',\n",
       " (2885, 3035): u'fad',\n",
       " (2893, 3090): u'microphone',\n",
       " (2894, 3113): u'magazine',\n",
       " (2901, 4345): u'bandanna',\n",
       " (2957, 5122): u'fink',\n",
       " (2969, 3156): u'manner',\n",
       " (2969, 4462): u'manner',\n",
       " (2996, 3847): u'crap',\n",
       " (3030, 4433): u'injury',\n",
       " (3058, 4041): u'nigger',\n",
       " (3062, 3572): u'tune',\n",
       " (3121, 3957): u'lookout',\n",
       " (3124, 5113): u'sunlight',\n",
       " (3156, 4462): u'manner',\n",
       " (3182, 3789): u'nothing',\n",
       " (3201, 4114): u'movie',\n",
       " (3216, 3859): u'asshole',\n",
       " (3280, 4901): u'walk',\n",
       " (3289, 3658): u'liquor',\n",
       " (3359, 4195): u'package',\n",
       " (3375, 4441): u'degree',\n",
       " (3382, 3464): u'cry',\n",
       " (3420, 3628): u'ailment',\n",
       " (3451, 4367): u'flicker',\n",
       " (3482, 4710): u'thousand',\n",
       " (3535, 3999): u'concern',\n",
       " (3556, 4141): u'hideout',\n",
       " (3615, 3973): u'family',\n",
       " (3626, 3753): u'whitey',\n",
       " (3641, 4485): u'dad',\n",
       " (3641, 4667): u'dad',\n",
       " (3642, 3759): u'ma',\n",
       " (3719, 4512): u'curse',\n",
       " (3724, 4883): u'measure',\n",
       " (3734, 4298): u'rock',\n",
       " (3846, 3862): u'dawn',\n",
       " (3976, 4334): u'eden',\n",
       " (3980, 4179): u'reverie',\n",
       " (4155, 4657): u'choice',\n",
       " (4189, 4600): u'criminal',\n",
       " (4235, 4477): u'basement',\n",
       " (4258, 4413): u'rotter',\n",
       " (4344, 4599): u'material',\n",
       " (4397, 4708): u'pornography',\n",
       " (4412, 4421): u'scheme',\n",
       " (4485, 4667): u'dad',\n",
       " (4637, 4716): u'mark',\n",
       " (4738, 4826): u'child'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save adj hypernyms\n",
    "pickle.dump( ahypes, open( \"../../data/conditioned/ahypes.p\", \"wb\" ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save noun hypernyms\n",
    "pickle.dump( nhypes, open( \"../../data/conditioned/nhypes.p\", \"wb\" ) )  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
