{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vocab Shrunk Notebook\n",
    "This notebook will go through a series of shrinking efforts beginning with the noun and adjective reduced vocabs. It will first consider synonyms and the shrinkage effects. It will then work from the initial shrunken result to consider hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to sort dataframe decsending is the default\n",
    "def sortDataframe(df,sort_col,ascending=False):\n",
    "    return df.sort(columns=sort_col, ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoad(json_name,root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading list of list pairs json to columnar dataframe\n",
    "def jsonListOfPairListsToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    keys = []\n",
    "    values = []\n",
    "    for x in j:\n",
    "        keys.append(x[0])\n",
    "        values.append(x[1])\n",
    "        \n",
    "    d = {key_col_label: listAsAscii(keys), val_col_label: listAsAscii(values)}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json dict to csv\n",
    "def jsonDictToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonDictToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                             root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json list of lists containing 2 entries to csv\n",
    "def jsonListOfPairListsToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonListOfPairListsToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                                        root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoadVocabs(json_name):\n",
    "    cvocab = jsonLoad(json_name)\n",
    "    dvocabs = {}\n",
    "    for decade in decades:\n",
    "        # change root in for decade\n",
    "        drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "        dvocabs[decade] = jsonLoad(json_name,root_in=drootin)\n",
    "    \n",
    "    return cvocab, dvocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickleLoad(pickle_name,root_in=root_in):\n",
    "    return pickle.load( open( root_in + pickle_name, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickleLoadVocabs(pickle_name):\n",
    "    cvocab = pickleLoad(pickle_name)\n",
    "    dvocabs = {}\n",
    "    for decade in decades:\n",
    "        # change root in for decade\n",
    "        drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "        dvocabs[decade] = pickleLoad(pickle_name,root_in=drootin)\n",
    "    \n",
    "    return cvocab, dvocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a critical function to translate from corpus index to decade index!!!\n",
    "def findIdForWord(word,vocab):\n",
    "    for k,v in vocab:\n",
    "        if v == word:\n",
    "            return k\n",
    "    return -1 # note want to distinguish 0 from None, so using -1 for no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate a column full of a given decades values from a comp\n",
    "def compCol(comp,decade):\n",
    "    didx = decades.index(decade)\n",
    "    vs = []\n",
    "    for k,v in comp.iteritems():\n",
    "        vs.append(v[didx])\n",
    "        \n",
    "    return vs\n",
    "\n",
    "# function to convert comp to dataframe and save\n",
    "def compToDataframe(comp):\n",
    "    d = {'word': listAsAscii(comp.keys())}\n",
    "    \n",
    "    for decade in decades:\n",
    "        d[str(decade)] = compCol(comp,decade)\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD VOCABS\n",
    "cnvocab, dnvocabs = jsonLoadVocabs(\"nounvocab.json\")\n",
    "cavocab, davocabs = jsonLoadVocabs(\"adjvocab.json\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun vocab?  5144\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj vocab?  3379\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun vocab? \", len(cnvocab)\n",
    "print \"len decade keys (expect 5) --> \", len(dnvocabs.keys())\n",
    "print \"decade keys()[0] --> \",dnvocabs.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj vocab? \", len(cavocab)\n",
    "print \"len decade keys (expect 5) --> \", len(davocabs.keys())\n",
    "print \"decade keys()[0] --> \",davocabs.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD ID2WORDS\n",
    "cnid2word, dnid2words = jsonLoadVocabs(\"nounid2word.json\")\n",
    "caid2word, daid2words = jsonLoadVocabs(\"adjid2word.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun id2word?  5144\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj id2word?  3379\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun id2word? \", len(cnid2word)\n",
    "print \"len decade keys (expect 5) --> \", len(dnid2words.keys())\n",
    "print \"decade keys()[0] --> \",dnid2words.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj id2word? \", len(caid2word)\n",
    "print \"len decade keys (expect 5) --> \", len(daid2words.keys())\n",
    "print \"decade keys()[0] --> \",daid2words.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Synonyms\n",
    "**REMEMBER, the individual decade indexing will be different from the master corpus indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnvocab ['sycamore']?  4446\n",
      "cnid2word ['4446']?  sycamore\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print \"cnvocab ['sycamore']? \",cnvocab['sycamore']\n",
    "print \"cnid2word ['4446']? \",cnid2word['4446']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD SYNONYMS\n",
    "cnsyn, dnsyns = jsonLoadVocabs(\"nsyns.json\")\n",
    "casyn, dasyns = jsonLoadVocabs(\"asyns.json\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun syns?  3580\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj syns?  1707\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun syns? \", len(cnsyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dnsyns.keys())\n",
    "print \"decade keys()[0] --> \",dnsyns.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj syns? \", len(casyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dasyns.keys())\n",
    "print \"decade keys()[0] --> \",dasyns.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Shrunken-1: From Vocab Down to Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def synEval(csyn):\n",
    "    u = {} # build the synonym view\n",
    "    m = {} #multiples\n",
    "    for k,v in csyn.iteritems():\n",
    "        if v not in u:\n",
    "            u[v] = 1\n",
    "        else:\n",
    "            u[v] += 1  \n",
    "            if v in m:\n",
    "                m[v] += 1\n",
    "            else:\n",
    "                m[v] = 2 #multiples\n",
    "    return u,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  3230\n",
      "How many multiples?  292\n",
      "{u'shop': 2, u'impression': 2, u'bait': 2, u'summer': 2, u'bull': 2, u'urine': 3, u'intuition': 2, u'aroma': 2, u'chink': 2, u'catch': 2, u'fink': 2, u'sleep': 3, u'fillet': 3, u'battle': 2, u'defender': 2, u'speed': 2, u'wage': 3, u'buddy': 2, u'head': 2, u'vibration': 2, u'filth': 2, u'drive': 2, u'pickup': 2, u'pile': 2, u'fad': 2, u'daze': 2, u'crack': 2, u'tune': 2, u'smile': 2, u'criminal': 3, u'hate': 2, u'lookout': 3, u'good': 2, u'hang-up': 2, u'couple': 2, u'material': 2, u'kind': 2, u'clang': 2, u'choice': 3, u'dark': 2, u'lunch': 2, u'spoon': 2, u'buttocks': 4, u'fan': 2, u'breast': 3, u'basement': 2, u'bartender': 2, u'bit': 2, u'jesus': 2, u'twilight': 2, u'day': 2, u'rumor': 2, u'knock': 3, u'die': 2, u'bulge': 2, u'sofa': 3, u'cry': 2, u'freshness': 2, u'morning': 2, u'bag': 3, u'nigger': 2, u'phase': 2, u'macintosh': 2, u'rock': 2, u'guy': 2, u'rear': 2, u'inside': 2, u'draw': 2, u'sweetheart': 2, u'set': 2, u'ailment': 2, u'scheme': 2, u'liquor': 2, u'grandfather': 2, u'idea': 2, u'crop': 2, u'batch': 2, u'hush': 2, u'touch': 2, u'second': 2, u'ball': 3, u'measure': 2, u'pornography': 2, u'dawn': 2, u'disco': 2, u'vicinity': 2, u'concern': 3, u'closer': 2, u'semen': 2, u'palette': 2, u'slice': 2, u'destiny': 2, u'cast': 2, u'movie': 3, u'decision': 2, u'boogie': 2, u'lurch': 2, u'rotter': 3, u'religion': 2, u'state': 3, u'bang': 2, u'internet': 2, u'drunkard': 2, u'fall': 2, u'sorrow': 2, u'pun': 2, u'eating': 2, u'monster': 2, u'degree': 2, u'screen': 2, u'argument': 2, u'component': 2, u'rug': 2, u'killing': 2, u'base': 3, u'pursuit': 2, u'address': 2, u'path': 2, u'beginning': 3, u'avenue': 2, u'barroom': 2, u'promenade': 2, u'sister': 2, u'amour_propre': 2, u'ace': 3, u'package': 2, u'career': 2, u'universe': 2, u'hint': 2, u'girl': 3, u'pace': 2, u'flicker': 2, u'turn': 2, u'magazine': 2, u'nothing': 2, u'aura': 2, u'smoke': 3, u'swing': 2, u'consequence': 2, u'ice_lolly': 2, u'mistake': 2, u'expression': 2, u'plan': 2, u'whitey': 2, u'dunce': 2, u'family': 2, u'point': 2, u'information': 2, u'pot': 4, u'grandma': 2, u'motivation': 2, u'walk': 2, u'cocoa': 2, u'chump': 2, u'seashore': 2, u'laugh': 2, u'ring': 2, u'hood': 3, u'crap': 3, u'fabric': 2, u'jet': 2, u'addition': 2, u'illusion': 2, u'bite': 2, u'waist': 2, u'vacation': 2, u'sunlight': 2, u'mark': 2, u'pool': 2, u'yak': 2, u'spring': 2, u'injury': 2, u'limousine': 2, u'sensitivity': 2, u'dame': 2, u'function': 2, u'life': 3, u'intestine': 2, u'form': 2, u'reverie': 2, u'enchantment': 2, u'thousand': 2, u'frost': 2, u'award': 2, u'cabinet': 2, u'grief': 3, u'heat': 2, u'game': 2, u'adult': 2, u'child': 2, u'baby': 2, u'scribble': 2, u'spirit': 3, u'starter': 2, u'aid': 2, u'past': 2, u'photograph': 2, u'hideout': 2, u'ma': 5, u'ballyhoo': 2, u'eden': 2, u'ecstasy': 2, u'car': 2, u'athlete': 2, u'stroke': 2, u'smasher': 2, u'air': 2, u'matter': 2, u'calamity': 3, u'marriage': 2, u'shingle': 2, u'cab': 3, u'loot': 2, u'root': 2, u'care': 2, u'history': 2, u'dad': 6, u'coconut': 2, u'freak': 2, u'bent': 3, u'telephone': 2, u'fellow': 2, u'dash': 2, u'sphere': 2, u'chap': 4, u'kingdom': 2, u'manner': 5, u'violin': 2, u'airplane': 2, u'shooting': 2, u'pit': 2, u'check': 3, u'bow': 2, u'guarantee': 2, u'cheep': 2, u'microphone': 2, u'wanderer': 2, u'baggage': 2, u'anguish': 2, u'purpose': 3, u'foreigner': 2, u'speaker': 2, u'boom': 4, u'animal': 3, u'miniskirt': 2, u'answer': 2, u'sunset': 2, u'asshole': 4, u'subject': 2, u'panic': 2, u'soap': 2, u'alligator': 2, u'eternity': 2, u'hallway': 2, u'play': 2, u'adieu': 3, u'thunderbolt': 2, u'whirl': 2, u'spot': 2, u'hazard': 2, u'millimeter': 2, u'suburb': 2, u'moment': 2, u'curse': 2, u'kin': 2, u'prisoner': 2, u'coil': 2, u'hair': 2, u'strut': 2, u'opportunity': 2, u'class': 2, u'grave': 2, u'longing': 2, u'land': 2, u'attempt': 3, u'center': 2, u'bullet': 2, u'joint': 2, u'clasp': 3, u'topographic_point': 2, u'doctor': 2, u'drip': 3, u'moonlight': 2, u'person': 3, u'haste': 2, u'shade': 2, u'narrative': 2, u'position': 3, u'menace': 2, u'scream': 2, u'wind': 2, u'bandanna': 2}\n"
     ]
    }
   ],
   "source": [
    "# how many unique noun synonyms\n",
    "n_s, n_ms = synEval(cnsyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(n_s)\n",
    "print \"How many multiples? \", len(n_ms)\n",
    "\n",
    "print n_ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This means:**\n",
    "* 3,230 nouns are found within the synset, having valid synonyms, to which we standardized to the first result\n",
    "* 292 synonyms within that result have common_support or shared synonym use. \n",
    "* The remainder of the total 5,144 in the noun vocab set (1,914) are not found in the synset and may potentially be ignored to strengthen subsequent vector analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  1502\n",
      "How many multiples?  167\n",
      "{u'exclusive': 2, u'brumous': 2, u'diffident': 2, u'bum': 2, u'domestic': 2, u'lavish': 2, u'distant': 2, u'grateful': 2, u'rough': 2, u'religious': 2, u'fifth': 2, u'fit': 2, u'dramatic': 2, u'fitting': 2, u'besotted': 2, u'permanent': 2, u'black': 2, u'bushy': 2, u'bang-up': 4, u'deadly': 2, u'bigheaded': 2, u'cutting': 2, u'dreamy': 2, u'frigid': 2, u'awful': 2, u'farthermost': 2, u'grim': 2, u'bigger': 2, u'entire': 2, u'colored': 3, u'crisp': 4, u'lost': 2, u'large': 2, u'common': 2, u'double': 2, u'popular': 2, u'obscure': 2, u'ignored': 2, u'small': 2, u'colossal': 2, u'eighteenth': 2, u'dead': 2, u'extremist': 2, u'fabulous': 2, u'bare': 5, u'corrupt': 2, u'ablaze': 3, u'divine': 2, u'aroused': 4, u'casual': 2, u'blue': 4, u'bantam': 2, u'ill-famed': 2, u'instantaneous': 2, u'critical': 2, u'bogus': 3, u'crude': 2, u'burned': 2, u'red': 5, u'hairy': 2, u'ferocious': 3, u'sixth': 2, u'seventh': 2, u'broken': 2, u'icky': 4, u'conceited': 3, u'active': 2, u'blasted': 2, u'extreme': 2, u'dry': 2, u'enormous': 2, u'cryptic': 2, u'actual': 2, u'talented': 2, u'ace': 2, u'piquant': 2, u'ill': 2, u'bronzed': 2, u'favorite': 2, u'slender': 2, u'honest': 2, u'sensitive': 2, u'glorious': 2, u'chopped': 2, u'bitty': 3, u'fantastic': 2, u'boggy': 2, u'natural': 2, u'disgusting': 2, u'alone': 3, u'chunky': 2, u'jammed': 2, u'chubby': 2, u'nauseating': 2, u'open': 2, u'nightlong': 2, u'brassy': 2, u'adolescent': 3, u'capable': 2, u'faint': 2, u'lone': 2, u'imperial': 2, u'seasoned': 2, u'calm': 2, u'white': 2, u'immaculate': 2, u'coarse': 2, u'firm': 2, u'barbarous': 3, u'devilish': 2, u'aureate': 2, u'baronial': 2, u'apparent': 3, u'ageless': 4, u'hurt': 2, u'all_right': 3, u'particular': 2, u'consecrated': 2, u'cunning': 2, u'wide': 2, u'graphic': 2, u'bally': 2, u'grey': 3, u'slippery': 2, u'deserving': 2, u'wild': 2, u'fried': 2, u'enamored': 2, u'humble': 2, u'atrocious': 2, u'coincident': 2, u'certain': 2, u'juicy': 2, u'far-out': 2, u'dizzy': 3, u'blond': 2, u'curious': 2, u'null': 2, u'everyday': 3, u'huge': 2, u'aged': 2, u'gay': 2, u'incredible': 2, u'pale': 2, u'ephemeral': 2, u'amazing': 3, u'cardinal': 2, u'amusing': 2, u'difficult': 2, u'fine-looking': 2, u'chancy': 2, u'delicate': 3, u'cheery': 3, u'charming': 3, u'eighth': 2, u'cockamamie': 3, u'elusive': 2, u'untrimmed': 2, u'average': 2, u'laden': 2, u'edgy': 2, u'greek': 2, u'chief': 2, u'crazed': 2, u'classy': 2, u'fresh': 2, u'deluxe': 3}\n"
     ]
    }
   ],
   "source": [
    "# how many unique adj synonyms\n",
    "a_s, a_ms = synEval(casyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(a_s)\n",
    "print \"How many multiples? \", len(a_ms)\n",
    "\n",
    "print a_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This means:**\n",
    "* 1,502 adjectives are found within the synset, having valid synonyms, to which we standardized to the first result\n",
    "* 167 synonyms within that result have common_support or shared synonym use. \n",
    "* The remainder of the total 1,707 in the noun vocab set (205) are not found in the synset and may potentially be ignored to strengthen subsequent vector analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Viz prep for synonym use\n",
    "* `ascomp` and `nscomp` variables below will hold the presence of synonyms per decade.\n",
    "* will not use `dnsyns` and `dasyns` to avoid indexing confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each synonym\n",
    "def populateDecadeSyns(comp,decade,tsyn,tid2word):\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # set syns which have k=id, v=synonym\n",
    "    csyn = tsyn[0]\n",
    "    dsyn = tsyn[1][decade]\n",
    "    \n",
    "    # set id2word which have k=id, v=word\n",
    "    cid2word = tid2word[0]\n",
    "    did2word = tid2word[1][decade]\n",
    "    \n",
    "    #loop over corpus syns k=index in id2word, v=synonym\n",
    "    for k,v in csyn.iteritems():\n",
    "        \n",
    "        # attempt to find the id(s) reference of the synonym within `did2word` based on synonym.\n",
    "        # NOTE: this step is necessary as the ids are not matched between corpus and per decade processing\n",
    "        refs = []\n",
    "        for i,s in dsyn.iteritems():\n",
    "            if s == v:\n",
    "                refs.append(i)\n",
    "            \n",
    "        # if the synonym is present at least once in the decade then account for it in comp\n",
    "        if len(refs):            \n",
    "            #print \"for synonym: {}, {} id(s) found in decade {}\".format(v,len(refs),decade)            \n",
    "            # determine counts of synonym in decade\n",
    "            comp[v][didx] = len(refs) \n",
    "    \n",
    "    return comp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up a structure for each\n",
    "nscomp = {}\n",
    "ascomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for k,v in n_s.iteritems():    \n",
    "    nscomp[k]=[0,0,0,0,0] \n",
    "    \n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for k,v in a_s.iteritems():    \n",
    "    ascomp[k]=[0,0,0,0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comp for nouns\n",
    "for d in decades:\n",
    "    nscomp = populateDecadeSyns(nscomp,d,(cnsyn,dnsyns),(cnid2word,dnid2words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inning\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify nscomp\n",
    "print nscomp.keys()[0]\n",
    "print nscomp[nscomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comp for adjs\n",
    "for d in decades:\n",
    "    ascomp = populateDecadeSyns(ascomp,d,(casyn,dasyns),(caid2word,daid2words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limited\n",
      "[0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#verify ascomp\n",
    "print ascomp.keys()[0]\n",
    "print ascomp[ascomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Synonym Comps to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nscompdf = compToDataframe(nscomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sleet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>obstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nursery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>railing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>appetite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>captain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010         word\n",
       "0     0     0     0     1     0       inning\n",
       "1     1     1     1     1     1       yellow\n",
       "2     0     0     1     0     0        hitch\n",
       "3     1     0     0     0     0        sleet\n",
       "4     0     0     0     1     0  obstruction\n",
       "5     0     0     0     1     0      nursery\n",
       "6     1     1     1     3     1        sleep\n",
       "7     1     0     0     1     0      railing\n",
       "8     1     0     1     1     1     appetite\n",
       "9     0     0     0     1     1      captain"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nscompdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ascompdf = compToDataframe(ascomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sleek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>huffy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ill-famed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>undisputed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>eligible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unanswered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010        word\n",
       "0     0     0     0     1     1     limited\n",
       "1     0     0     1     1     0     dynamic\n",
       "2     1     1     1     1     1      yellow\n",
       "3     0     0     1     1     0       sleek\n",
       "4     1     1     1     1     1       huffy\n",
       "5     0     0     0     0     1       asian\n",
       "6     0     0     1     2     0   ill-famed\n",
       "7     0     0     1     1     0  undisputed\n",
       "8     0     0     0     1     0    eligible\n",
       "9     0     0     1     0     0  unanswered"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascompdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Synonym Comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nscompdf\n",
    "dataframeToCsv(nscompdf,'noun_decade_comp_synonyms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ascompdf\n",
    "dataframeToCsv(ascompdf,'adj_decade_comp_synonyms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Add synonym columns to master Dataframe\n",
    "**This follows from the work in [Vector-Ensemble Notebook](Vector-Ensemble.ipynb). It uses the word vector columns to shorten to synonyms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the latest master lyricsdf\n",
    "vectordf = pd.read_csv(\"../../data/conditioned/master-lyricsdf-word_vectors.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorToStr(vector):\n",
    "    return ' '.join([x.encode('ascii','ignore') if isinstance(x,unicode) else x for x in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a synonym vector from a given word vector\n",
    "def wordVectorToSynVector(wvector,csyn,cid2word):\n",
    "    \n",
    "    svector = []\n",
    "    \n",
    "    #loop over corpus syns k=index in id2word, v=synonym\n",
    "    for k,v in csyn.iteritems():\n",
    "        \n",
    "        #figure out the normal word use for the index\n",
    "        word = cid2word[k]\n",
    "        \n",
    "        #apply the synonym if present in wordvector, \n",
    "        if word and word in wvector:\n",
    "            svector.append(v)\n",
    "            \n",
    "    return svector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# work for the noun_vector and adj_vector columns to build synonyms.\n",
    "def synonymsFromVectorCol(vectordf,vector_col,syn_col,csyn,cid2word):\n",
    "    \n",
    "    syns = []\n",
    "    \n",
    "    # build the synonyms    \n",
    "    for r in vectordf.iterrows():\n",
    "        words = r[1][vector_col]\n",
    "        wvector = []\n",
    "        \n",
    "        # get words to evaluate into vector form\n",
    "        if not isinstance(words,float):\n",
    "            wvector = words.split()\n",
    "            \n",
    "        # find synonyms\n",
    "        svector = []\n",
    "        if len(wvector):\n",
    "            svector = wordVectorToSynVector(wvector,csyn,cid2word)\n",
    "        \n",
    "        # syn vector to sentence\n",
    "        s = np.nan\n",
    "        if len(svector):\n",
    "            s = vectorToStr(svector)\n",
    "        \n",
    "        # append the sentence to syns\n",
    "        syns.append(s)\n",
    "    \n",
    "    # after loop, build a dataframe that adds the column\n",
    "    vdf = pd.DataFrame({syn_col: syns})\n",
    "    \n",
    "    return vectordf.join(vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 152 ms, total: 17.6 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle noun synonyms\n",
    "snvdf = synonymsFromVectorCol(vectordf,'noun_vector','noun_syn_vector',cnsyn,cnid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snvdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.99 s, sys: 27.2 ms, total: 6.01 s\n",
      "Wall time: 6.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle adj synonyms\n",
    "sanvdf = synonymsFromVectorCol(snvdf,'adj_vector','adj_syn_vector',casyn,caid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>troubled rough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector  adj_syn_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water  troubled rough"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanvdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Dataframe Augmented with Synonym Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(sanvdf,\"master-lyricsdf-word_syn_vectors.csv\",root_out=\"../../data/conditioned/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load noun hypernyms from file\n",
    "cnhype, dnhypes = pickleLoadVocabs(\"nhypes.p\")\n",
    "\n",
    "# load adj hypernyms from file\n",
    "cahype, dahypes = pickleLoadVocabs(\"ahypes.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun hypes?  293\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj hypes?  167\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun hypes? \", len(cnhype)\n",
    "print \"len decade keys (expect 5) --> \", len(dnhypes.keys())\n",
    "print \"decade keys()[0] --> \",dnhypes.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj hypes? \", len(cahype)\n",
    "print \"len decade keys (expect 5) --> \", len(dahypes.keys())\n",
    "print \"decade keys()[0] --> \",dahypes.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypernym len is sized to the number of shared synonyms (2 or more words collapsing to a synonym)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the tuple pair from corpus noun hypernym key[0]?  (4412, 4421)\n",
      "What is the tuple pair synonyms collapsing down from corpus noun hypernym key[0]?  strategy scheme\n",
      "What is the hypernym value for corpus noun hype at key[0]?  scheme\n"
     ]
    }
   ],
   "source": [
    "print \"What is the tuple pair from corpus noun hypernym key[0]? \", cnhype.keys()[0]\n",
    "print \"What is the tuple pair synonyms collapsing down from corpus noun hypernym key[0]? \", cnid2word[str(cnhype.keys()[0][0])], cnid2word[str(cnhype.keys()[0][1])]\n",
    "print \"What is the hypernym value for corpus noun hype at key[0]? \", cnhype[cnhype.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the tuple pair from corpus adj hypernym key[0]?  (1581, 1687)\n",
      "What is the tuple pair synonyms collapsing down from corpus adj hypernym key[0]?  thankful bouncin\n",
      "What is the hypernym value for corpus adj hype at key[0]?  grateful\n"
     ]
    }
   ],
   "source": [
    "print \"What is the tuple pair from corpus adj hypernym key[0]? \", cahype.keys()[0]\n",
    "print \"What is the tuple pair synonyms collapsing down from corpus adj hypernym key[0]? \", caid2word[str(cahype.keys()[0][0])], cnid2word[str(cahype.keys()[0][1])]\n",
    "print \"What is the hypernym value for corpus adj hype at key[0]? \", cahype[cahype.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Shrunken-2: From Synonyms Down to Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperEval(chype):\n",
    "    u = {} # build the hypernym view\n",
    "    m = {} #multiples\n",
    "    for k,v in chype.iteritems():\n",
    "        if v not in u:\n",
    "            u[v] = 1\n",
    "        else:\n",
    "            u[v] += 1  \n",
    "            if v in m:\n",
    "                m[v] += 1\n",
    "            else:\n",
    "                m[v] = 2 #multiples\n",
    "    return u,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using hypernyms)?  201\n",
      "How many multiples?  27\n",
      "{u'lookout': 3, u'urine': 3, u'chap': 6, u'manner': 10, u'girl': 3, u'hood': 3, u'wage': 3, u'crap': 3, u'movie': 3, u'rotter': 3, u'boom': 6, u'animal': 3, u'asshole': 6, u'criminal': 3, u'dad': 15, u'adieu': 3, u'grief': 3, u'purpose': 3, u'attempt': 3, u'clasp': 3, u'buttocks': 6, u'ma': 10, u'ace': 3, u'sofa': 3, u'drip': 3, u'person': 3, u'calamity': 3}\n"
     ]
    }
   ],
   "source": [
    "# how many unique noun hypernyms\n",
    "n_h, n_mh = hyperEval(cnhype)       \n",
    "        \n",
    "print \"How many unique nouns (when using hypernyms)? \", len(n_h)\n",
    "print \"How many multiples? \", len(n_mh)\n",
    "\n",
    "print n_mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique adjs (when using hypernyms)?  118\n",
      "How many multiples?  16\n",
      "{u'cockamamie': 3, u'bitty': 3, u'ferocious': 3, u'all_right': 3, u'barbarous': 3, u'apparent': 3, u'ageless': 6, u'dizzy': 3, u'bare': 4, u'bogus': 3, u'icky': 6, u'cheery': 3, u'conceited': 3, u'everyday': 3, u'red': 10, u'bang-up': 6}\n"
     ]
    }
   ],
   "source": [
    "# how many unique adj hypernyms\n",
    "a_h, a_mh = hyperEval(cahype)       \n",
    "        \n",
    "print \"How many unique adjs (when using hypernyms)? \", len(a_h)\n",
    "print \"How many multiples? \", len(a_mh)\n",
    "\n",
    "print a_mh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Viz prep for hypernym use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each synonym\n",
    "def populateDecadeHypes(comp,decade,thype,tsyn):\n",
    "    \n",
    "    #TODO: CONVERT FROM SYNS\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # set hypes which have k=id1,id2, v=synonym\n",
    "    chype = thype[0]\n",
    "    dhype = thype[1][decade]\n",
    "    \n",
    "    # set syns which have k=id, v=synonym\n",
    "    csyn = tsyn[0]\n",
    "    dsyn = tsyn[1][decade]\n",
    "    \n",
    "    #loop over corpus hype\n",
    "    for k,v in chype.iteritems():\n",
    "        \n",
    "        # attempt to find the id(s) reference of the hypernym within `dhype`.\n",
    "        # NOTE: this step is necessary as the ids are not matched between corpus and per decade processing\n",
    "        refs = []\n",
    "        for i,h in dhype.iteritems():\n",
    "            if h == v:\n",
    "                refs.append(i)\n",
    "            \n",
    "        # if the hypernym is present at least once in the decade then account for it in comp\n",
    "        if len(refs):            \n",
    "            #print \"for hypernym: {}, {} id(s) found in decade {}\".format(v,len(refs),decade)            \n",
    "            # determine counts of hypernym in decade\n",
    "            comp[v][didx] = len(refs) \n",
    "    \n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a structure for each\n",
    "nhcomp = {}\n",
    "ahcomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for k,v in n_h.iteritems():    \n",
    "    nhcomp[k]=[0,0,0,0,0] \n",
    "    \n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for k,v in a_h.iteritems():    \n",
    "    ahcomp[k]=[0,0,0,0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comp for nouns\n",
    "for d in decades:\n",
    "    nhcomp = populateDecadeHypes(nhcomp,d,(cnhype,dnhypes),(cnsyn,dnsyns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop\n",
      "[1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify nhcomp\n",
    "print nhcomp.keys()[0]\n",
    "print nhcomp[nhcomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comp for adjs\n",
    "for d in decades:\n",
    "    ahcomp = populateDecadeHypes(ahcomp,d,(cahype,dahypes),(casyn,dasyns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclusive\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify ahcomp\n",
    "print ahcomp.keys()[0]\n",
    "print ahcomp[ahcomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hypernym Comps to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhcompdf = compToDataframe(nhcomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>flicker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010        word\n",
       "0     1     1     1     1     0        shop\n",
       "1     0     0     0     0     0  impression\n",
       "2     0     0     0     0     0        bait\n",
       "3     1     1     1     1     1      summer\n",
       "4     0     1     1     1     0     flicker"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhcompdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ahcompdf = compToDataframe(ahcomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>brumous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>diffident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>particular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>grateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010        word\n",
       "0     0     0     0     1     0   exclusive\n",
       "1     0     0     1     1     1     brumous\n",
       "2     0     1     1     0     0   diffident\n",
       "3     0     1     1     0     0  particular\n",
       "4     0     0     1     1     0    grateful"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahcompdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Hypernym Comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nhcompdf\n",
    "dataframeToCsv(nhcompdf,'noun_decade_comp_hypernyms.csv')\n",
    "\n",
    "# ahcompdf\n",
    "dataframeToCsv(ahcompdf,'adj_decade_comp_hypernyms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Add Hypernym columns to master Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build hypernym replacement dict\n",
    "def synToHypeDict(syn,hype,debug=False):\n",
    "    d = {}\n",
    "    \n",
    "    #loop over hypes k=id 2tuple found in syns, v=hypernym\n",
    "    for k,v in hype.iteritems():\n",
    "        \n",
    "        #open the key which is a tuple for hypes\n",
    "        #syns uses a string key!!!\n",
    "        id1=str(k[0]) \n",
    "        id2=str(k[1])\n",
    "                \n",
    "        #lookup the ids in syns         \n",
    "        if id1 in syn:\n",
    "            word1 = syn[id1]            \n",
    "            d[word1] = v\n",
    "            if debug:\n",
    "                print \"syn: {}, hype: {}\".format(word1,v)\n",
    "            \n",
    "        if id2 in syn:\n",
    "            word2 = syn[id2]            \n",
    "            d[word2] = v\n",
    "            if debug:\n",
    "                print \"syn: {}, hype: {}\".format(word2,v)\n",
    "        elif debug:\n",
    "            print \"hypernym not in syns... \", v\n",
    "            \n",
    "    return d           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn: scheme, hype: scheme\n",
      "syn: scheme, hype: scheme\n",
      "syn: waist, hype: waist\n",
      "syn: waist, hype: waist\n",
      "syn: matter, hype: matter\n",
      "syn: matter, hype: matter\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: tune, hype: tune\n",
      "syn: tune, hype: tune\n",
      "syn: eden, hype: eden\n",
      "syn: eden, hype: eden\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: measure, hype: measure\n",
      "syn: measure, hype: measure\n",
      "syn: menace, hype: menace\n",
      "syn: menace, hype: menace\n",
      "syn: laugh, hype: laugh\n",
      "syn: laugh, hype: laugh\n",
      "syn: bulge, hype: bulge\n",
      "syn: bulge, hype: bulge\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: doctor, hype: doctor\n",
      "syn: doctor, hype: doctor\n",
      "syn: palette, hype: palette\n",
      "syn: palette, hype: palette\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: center, hype: center\n",
      "syn: center, hype: center\n",
      "syn: filth, hype: filth\n",
      "syn: filth, hype: filth\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: baby, hype: baby\n",
      "syn: baby, hype: baby\n",
      "syn: rumor, hype: rumor\n",
      "syn: rumor, hype: rumor\n",
      "syn: wage, hype: wage\n",
      "syn: wage, hype: wage\n",
      "syn: sofa, hype: sofa\n",
      "syn: sofa, hype: sofa\n",
      "syn: pile, hype: pile\n",
      "syn: pile, hype: pile\n",
      "syn: purpose, hype: purpose\n",
      "syn: purpose, hype: purpose\n",
      "syn: chump, hype: chump\n",
      "syn: chump, hype: chump\n",
      "syn: amour_propre, hype: amour_propre\n",
      "syn: amour_propre, hype: amour_propre\n",
      "syn: spring, hype: spring\n",
      "syn: spring, hype: spring\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: yak, hype: yak\n",
      "syn: yak, hype: yak\n",
      "syn: bait, hype: bait\n",
      "syn: bait, hype: bait\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: ailment, hype: ailment\n",
      "syn: ailment, hype: ailment\n",
      "syn: fabric, hype: fabric\n",
      "syn: fabric, hype: fabric\n",
      "syn: criminal, hype: criminal\n",
      "syn: criminal, hype: criminal\n",
      "syn: spirit, hype: spirit\n",
      "syn: spirit, hype: spirit\n",
      "syn: person, hype: person\n",
      "syn: person, hype: person\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: cast, hype: cast\n",
      "syn: cast, hype: cast\n",
      "syn: adieu, hype: adieu\n",
      "syn: adieu, hype: adieu\n",
      "syn: injury, hype: injury\n",
      "syn: injury, hype: injury\n",
      "syn: animal, hype: animal\n",
      "syn: animal, hype: animal\n",
      "syn: sunset, hype: sunset\n",
      "syn: sunset, hype: sunset\n",
      "syn: answer, hype: answer\n",
      "syn: answer, hype: answer\n",
      "syn: rotter, hype: rotter\n",
      "syn: rotter, hype: rotter\n",
      "syn: strut, hype: strut\n",
      "syn: strut, hype: strut\n",
      "syn: sphere, hype: sphere\n",
      "syn: sphere, hype: sphere\n",
      "syn: criminal, hype: criminal\n",
      "syn: criminal, hype: criminal\n",
      "syn: sleep, hype: sleep\n",
      "syn: sleep, hype: sleep\n",
      "syn: twilight, hype: twilight\n",
      "syn: twilight, hype: twilight\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: child, hype: child\n",
      "syn: child, hype: child\n",
      "syn: play, hype: play\n",
      "syn: play, hype: play\n",
      "syn: scream, hype: scream\n",
      "syn: scream, hype: scream\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: impression, hype: impression\n",
      "syn: impression, hype: impression\n",
      "syn: hood, hype: hood\n",
      "syn: hood, hype: hood\n",
      "syn: fink, hype: fink\n",
      "syn: fink, hype: fink\n",
      "syn: flicker, hype: flicker\n",
      "syn: flicker, hype: flicker\n",
      "syn: vacation, hype: vacation\n",
      "syn: vacation, hype: vacation\n",
      "syn: ball, hype: ball\n",
      "syn: ball, hype: ball\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: animal, hype: animal\n",
      "syn: animal, hype: animal\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: freak, hype: freak\n",
      "syn: freak, hype: freak\n",
      "syn: enchantment, hype: enchantment\n",
      "syn: enchantment, hype: enchantment\n",
      "syn: thunderbolt, hype: thunderbolt\n",
      "syn: thunderbolt, hype: thunderbolt\n",
      "syn: grief, hype: grief\n",
      "syn: grief, hype: grief\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: wanderer, hype: wanderer\n",
      "syn: wanderer, hype: wanderer\n",
      "syn: girl, hype: girl\n",
      "syn: girl, hype: girl\n",
      "syn: telephone, hype: telephone\n",
      "syn: telephone, hype: telephone\n",
      "syn: adieu, hype: adieu\n",
      "syn: adieu, hype: adieu\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: motivation, hype: motivation\n",
      "syn: motivation, hype: motivation\n",
      "syn: shingle, hype: shingle\n",
      "syn: shingle, hype: shingle\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: knock, hype: knock\n",
      "syn: knock, hype: knock\n",
      "syn: hallway, hype: hallway\n",
      "syn: hallway, hype: hallway\n",
      "syn: athlete, hype: athlete\n",
      "syn: athlete, hype: athlete\n",
      "syn: hood, hype: hood\n",
      "syn: hood, hype: hood\n",
      "syn: fall, hype: fall\n",
      "syn: fall, hype: fall\n",
      "syn: girl, hype: girl\n",
      "syn: girl, hype: girl\n",
      "syn: idea, hype: idea\n",
      "syn: idea, hype: idea\n",
      "syn: plan, hype: plan\n",
      "syn: plan, hype: plan\n",
      "syn: pun, hype: pun\n",
      "syn: pun, hype: pun\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: second, hype: second\n",
      "syn: second, hype: second\n",
      "syn: attempt, hype: attempt\n",
      "syn: attempt, hype: attempt\n",
      "syn: component, hype: component\n",
      "syn: component, hype: component\n",
      "syn: degree, hype: degree\n",
      "syn: degree, hype: degree\n",
      "syn: adieu, hype: adieu\n",
      "syn: adieu, hype: adieu\n",
      "syn: family, hype: family\n",
      "syn: family, hype: family\n",
      "syn: subject, hype: subject\n",
      "syn: subject, hype: subject\n",
      "syn: eating, hype: eating\n",
      "syn: eating, hype: eating\n",
      "syn: reverie, hype: reverie\n",
      "syn: reverie, hype: reverie\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: crap, hype: crap\n",
      "syn: crap, hype: crap\n",
      "syn: fillet, hype: fillet\n",
      "syn: fillet, hype: fillet\n",
      "syn: microphone, hype: microphone\n",
      "syn: microphone, hype: microphone\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: magazine, hype: magazine\n",
      "syn: magazine, hype: magazine\n",
      "syn: daze, hype: daze\n",
      "syn: daze, hype: daze\n",
      "syn: sister, hype: sister\n",
      "syn: sister, hype: sister\n",
      "syn: purpose, hype: purpose\n",
      "syn: purpose, hype: purpose\n",
      "syn: miniskirt, hype: miniskirt\n",
      "syn: miniskirt, hype: miniskirt\n",
      "syn: smile, hype: smile\n",
      "syn: smile, hype: smile\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: sunlight, hype: sunlight\n",
      "syn: sunlight, hype: sunlight\n",
      "syn: person, hype: person\n",
      "syn: person, hype: person\n",
      "syn: dark, hype: dark\n",
      "syn: dark, hype: dark\n",
      "syn: cocoa, hype: cocoa\n",
      "syn: cocoa, hype: cocoa\n",
      "syn: grandfather, hype: grandfather\n",
      "syn: grandfather, hype: grandfather\n",
      "syn: baggage, hype: baggage\n",
      "syn: baggage, hype: baggage\n",
      "syn: barroom, hype: barroom\n",
      "syn: barroom, hype: barroom\n",
      "syn: concern, hype: concern\n",
      "syn: concern, hype: concern\n",
      "syn: mark, hype: mark\n",
      "syn: mark, hype: mark\n",
      "syn: attempt, hype: attempt\n",
      "syn: attempt, hype: attempt\n",
      "syn: base, hype: base\n",
      "syn: base, hype: base\n",
      "syn: grandma, hype: grandma\n",
      "syn: grandma, hype: grandma\n",
      "syn: nigger, hype: nigger\n",
      "syn: nigger, hype: nigger\n",
      "syn: pit, hype: pit\n",
      "syn: pit, hype: pit\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: basement, hype: basement\n",
      "syn: basement, hype: basement\n",
      "syn: inside, hype: inside\n",
      "syn: inside, hype: inside\n",
      "syn: bent, hype: bent\n",
      "syn: bent, hype: bent\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: touch, hype: touch\n",
      "syn: touch, hype: touch\n",
      "syn: hazard, hype: hazard\n",
      "syn: hazard, hype: hazard\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: guarantee, hype: guarantee\n",
      "syn: guarantee, hype: guarantee\n",
      "syn: defender, hype: defender\n",
      "syn: defender, hype: defender\n",
      "syn: aroma, hype: aroma\n",
      "syn: aroma, hype: aroma\n",
      "syn: hood, hype: hood\n",
      "syn: hood, hype: hood\n",
      "syn: loot, hype: loot\n",
      "syn: loot, hype: loot\n",
      "syn: bit, hype: bit\n",
      "syn: bit, hype: bit\n",
      "syn: speaker, hype: speaker\n",
      "syn: speaker, hype: speaker\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: boogie, hype: boogie\n",
      "syn: boogie, hype: boogie\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: suburb, hype: suburb\n",
      "syn: suburb, hype: suburb\n",
      "syn: jesus, hype: jesus\n",
      "syn: jesus, hype: jesus\n",
      "syn: movie, hype: movie\n",
      "syn: movie, hype: movie\n",
      "syn: choice, hype: choice\n",
      "syn: choice, hype: choice\n",
      "syn: ice_lolly, hype: ice_lolly\n",
      "syn: ice_lolly, hype: ice_lolly\n",
      "syn: fad, hype: fad\n",
      "syn: fad, hype: fad\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: millimeter, hype: millimeter\n",
      "syn: millimeter, hype: millimeter\n",
      "syn: ace, hype: ace\n",
      "syn: ace, hype: ace\n",
      "syn: bandanna, hype: bandanna\n",
      "syn: bandanna, hype: bandanna\n",
      "syn: cheep, hype: cheep\n",
      "syn: cheep, hype: cheep\n",
      "syn: ace, hype: ace\n",
      "syn: ace, hype: ace\n",
      "syn: position, hype: position\n",
      "syn: position, hype: position\n",
      "syn: car, hype: car\n",
      "syn: car, hype: car\n",
      "syn: urine, hype: urine\n",
      "syn: urine, hype: urine\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: wage, hype: wage\n",
      "syn: wage, hype: wage\n",
      "syn: limousine, hype: limousine\n",
      "syn: limousine, hype: limousine\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: criminal, hype: criminal\n",
      "syn: criminal, hype: criminal\n",
      "syn: rotter, hype: rotter\n",
      "syn: rotter, hype: rotter\n",
      "syn: clasp, hype: clasp\n",
      "syn: clasp, hype: clasp\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: walk, hype: walk\n",
      "syn: walk, hype: walk\n",
      "syn: movie, hype: movie\n",
      "syn: movie, hype: movie\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: crap, hype: crap\n",
      "syn: crap, hype: crap\n",
      "syn: girl, hype: girl\n",
      "syn: girl, hype: girl\n",
      "syn: longing, hype: longing\n",
      "syn: longing, hype: longing\n",
      "syn: ecstasy, hype: ecstasy\n",
      "syn: ecstasy, hype: ecstasy\n",
      "syn: mistake, hype: mistake\n",
      "syn: mistake, hype: mistake\n",
      "syn: lookout, hype: lookout\n",
      "syn: lookout, hype: lookout\n",
      "syn: topographic_point, hype: topographic_point\n",
      "syn: topographic_point, hype: topographic_point\n",
      "syn: dunce, hype: dunce\n",
      "syn: dunce, hype: dunce\n",
      "syn: guy, hype: guy\n",
      "syn: guy, hype: guy\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: morning, hype: morning\n",
      "syn: morning, hype: morning\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: nothing, hype: nothing\n",
      "syn: nothing, hype: nothing\n",
      "syn: religion, hype: religion\n",
      "syn: religion, hype: religion\n",
      "syn: grief, hype: grief\n",
      "syn: grief, hype: grief\n",
      "syn: sofa, hype: sofa\n",
      "syn: sofa, hype: sofa\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: rug, hype: rug\n",
      "syn: rug, hype: rug\n",
      "syn: urine, hype: urine\n",
      "syn: urine, hype: urine\n",
      "syn: hate, hype: hate\n",
      "syn: hate, hype: hate\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: drip, hype: drip\n",
      "syn: drip, hype: drip\n",
      "syn: grief, hype: grief\n",
      "syn: grief, hype: grief\n",
      "syn: calamity, hype: calamity\n",
      "syn: calamity, hype: calamity\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: lookout, hype: lookout\n",
      "syn: lookout, hype: lookout\n",
      "syn: drunkard, hype: drunkard\n",
      "syn: drunkard, hype: drunkard\n",
      "syn: sofa, hype: sofa\n",
      "syn: sofa, hype: sofa\n",
      "syn: consequence, hype: consequence\n",
      "syn: consequence, hype: consequence\n",
      "syn: vicinity, hype: vicinity\n",
      "syn: vicinity, hype: vicinity\n",
      "syn: smoke, hype: smoke\n",
      "syn: smoke, hype: smoke\n",
      "syn: sweetheart, hype: sweetheart\n",
      "syn: sweetheart, hype: sweetheart\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: semen, hype: semen\n",
      "syn: semen, hype: semen\n",
      "syn: crap, hype: crap\n",
      "syn: crap, hype: crap\n",
      "syn: breast, hype: breast\n",
      "syn: breast, hype: breast\n",
      "syn: past, hype: past\n",
      "syn: past, hype: past\n",
      "syn: lurch, hype: lurch\n",
      "syn: lurch, hype: lurch\n",
      "syn: liquor, hype: liquor\n",
      "syn: liquor, hype: liquor\n",
      "syn: animal, hype: animal\n",
      "syn: animal, hype: animal\n",
      "syn: lunch, hype: lunch\n",
      "syn: lunch, hype: lunch\n",
      "syn: information, hype: information\n",
      "syn: information, hype: information\n",
      "syn: marriage, hype: marriage\n",
      "syn: marriage, hype: marriage\n",
      "syn: destiny, hype: destiny\n",
      "syn: destiny, hype: destiny\n",
      "syn: clang, hype: clang\n",
      "syn: clang, hype: clang\n",
      "syn: kingdom, hype: kingdom\n",
      "syn: kingdom, hype: kingdom\n",
      "syn: chap, hype: chap\n",
      "syn: chap, hype: chap\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: manner, hype: manner\n",
      "syn: manner, hype: manner\n",
      "syn: shooting, hype: shooting\n",
      "syn: shooting, hype: shooting\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: person, hype: person\n",
      "syn: person, hype: person\n",
      "syn: rock, hype: rock\n",
      "syn: rock, hype: rock\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: drip, hype: drip\n",
      "syn: drip, hype: drip\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: crop, hype: crop\n",
      "syn: crop, hype: crop\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: drip, hype: drip\n",
      "syn: drip, hype: drip\n",
      "syn: buddy, hype: buddy\n",
      "syn: buddy, hype: buddy\n",
      "syn: whitey, hype: whitey\n",
      "syn: whitey, hype: whitey\n",
      "syn: rotter, hype: rotter\n",
      "syn: rotter, hype: rotter\n",
      "syn: die, hype: die\n",
      "syn: die, hype: die\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: cry, hype: cry\n",
      "syn: cry, hype: cry\n",
      "syn: career, hype: career\n",
      "syn: career, hype: career\n",
      "syn: kind, hype: kind\n",
      "syn: kind, hype: kind\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: bartender, hype: bartender\n",
      "syn: bartender, hype: bartender\n",
      "syn: purpose, hype: purpose\n",
      "syn: purpose, hype: purpose\n",
      "syn: shop, hype: shop\n",
      "syn: shop, hype: shop\n",
      "syn: boom, hype: boom\n",
      "syn: boom, hype: boom\n",
      "syn: narrative, hype: narrative\n",
      "syn: narrative, hype: narrative\n",
      "syn: photograph, hype: photograph\n",
      "syn: photograph, hype: photograph\n",
      "syn: internet, hype: internet\n",
      "syn: internet, hype: internet\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: opportunity, hype: opportunity\n",
      "syn: opportunity, hype: opportunity\n",
      "syn: anguish, hype: anguish\n",
      "syn: anguish, hype: anguish\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: airplane, hype: airplane\n",
      "syn: airplane, hype: airplane\n",
      "syn: fellow, hype: fellow\n",
      "syn: fellow, hype: fellow\n",
      "syn: dawn, hype: dawn\n",
      "syn: dawn, hype: dawn\n",
      "syn: macintosh, hype: macintosh\n",
      "syn: macintosh, hype: macintosh\n",
      "syn: wage, hype: wage\n",
      "syn: wage, hype: wage\n",
      "syn: summer, hype: summer\n",
      "syn: summer, hype: summer\n",
      "syn: clasp, hype: clasp\n",
      "syn: clasp, hype: clasp\n",
      "syn: moonlight, hype: moonlight\n",
      "syn: moonlight, hype: moonlight\n",
      "syn: hush, hype: hush\n",
      "syn: hush, hype: hush\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: curse, hype: curse\n",
      "syn: curse, hype: curse\n",
      "syn: seashore, hype: seashore\n",
      "syn: seashore, hype: seashore\n",
      "syn: state, hype: state\n",
      "syn: state, hype: state\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: pornography, hype: pornography\n",
      "syn: pornography, hype: pornography\n",
      "syn: ballyhoo, hype: ballyhoo\n",
      "syn: ballyhoo, hype: ballyhoo\n",
      "syn: intestine, hype: intestine\n",
      "syn: intestine, hype: intestine\n",
      "syn: prisoner, hype: prisoner\n",
      "syn: prisoner, hype: prisoner\n",
      "syn: asshole, hype: asshole\n",
      "syn: asshole, hype: asshole\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: buttocks, hype: buttocks\n",
      "syn: adult, hype: adult\n",
      "syn: adult, hype: adult\n",
      "syn: urine, hype: urine\n",
      "syn: urine, hype: urine\n",
      "syn: attempt, hype: attempt\n",
      "syn: attempt, hype: attempt\n",
      "syn: calamity, hype: calamity\n",
      "syn: calamity, hype: calamity\n",
      "syn: thousand, hype: thousand\n",
      "syn: thousand, hype: thousand\n",
      "syn: eternity, hype: eternity\n",
      "syn: eternity, hype: eternity\n",
      "syn: check, hype: check\n",
      "syn: check, hype: check\n",
      "syn: movie, hype: movie\n",
      "syn: movie, hype: movie\n",
      "syn: lookout, hype: lookout\n",
      "syn: lookout, hype: lookout\n",
      "syn: ace, hype: ace\n",
      "syn: ace, hype: ace\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: bullet, hype: bullet\n",
      "syn: bullet, hype: bullet\n",
      "syn: calamity, hype: calamity\n",
      "syn: calamity, hype: calamity\n",
      "syn: ma, hype: ma\n",
      "syn: ma, hype: ma\n",
      "syn: expression, hype: expression\n",
      "syn: expression, hype: expression\n",
      "syn: universe, hype: universe\n",
      "syn: universe, hype: universe\n",
      "syn: dad, hype: dad\n",
      "syn: dad, hype: dad\n",
      "syn: phase, hype: phase\n",
      "syn: phase, hype: phase\n",
      "syn: hideout, hype: hideout\n",
      "syn: hideout, hype: hideout\n",
      "syn: material, hype: material\n",
      "syn: material, hype: material\n",
      "syn: clasp, hype: clasp\n",
      "syn: clasp, hype: clasp\n",
      "syn: package, hype: package\n",
      "syn: package, hype: package\n",
      "syn: violin, hype: violin\n",
      "syn: violin, hype: violin\n",
      "syn: battle, hype: battle\n",
      "syn: battle, hype: battle\n"
     ]
    }
   ],
   "source": [
    "# establish the master dicts\n",
    "cnsh_dict = synToHypeDict(cnsyn,cnhype,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn: grateful, hype: grateful\n",
      "syn: grateful, hype: grateful\n",
      "syn: casual, hype: casual\n",
      "syn: casual, hype: casual\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: bare, hype: bare\n",
      "syn: bare, hype: bare\n",
      "syn: firm, hype: firm\n",
      "syn: firm, hype: firm\n",
      "syn: cryptic, hype: cryptic\n",
      "syn: cryptic, hype: cryptic\n",
      "syn: particular, hype: particular\n",
      "syn: particular, hype: particular\n",
      "syn: amusing, hype: amusing\n",
      "syn: amusing, hype: amusing\n",
      "syn: aroused, hype: aroused\n",
      "syn: aroused, hype: aroused\n",
      "syn: nightlong, hype: nightlong\n",
      "syn: nightlong, hype: nightlong\n",
      "syn: besotted, hype: besotted\n",
      "syn: besotted, hype: besotted\n",
      "syn: bare, hype: bare\n",
      "syn: bare, hype: bare\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: colored, hype: colored\n",
      "syn: colored, hype: colored\n",
      "syn: apparent, hype: apparent\n",
      "syn: apparent, hype: apparent\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n",
      "syn: all_right, hype: all_right\n",
      "syn: all_right, hype: all_right\n",
      "syn: honest, hype: honest\n",
      "syn: honest, hype: honest\n",
      "syn: sixth, hype: sixth\n",
      "syn: sixth, hype: sixth\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: slender, hype: slender\n",
      "syn: slender, hype: slender\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: barbarous, hype: barbarous\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n",
      "syn: difficult, hype: difficult\n",
      "syn: difficult, hype: difficult\n",
      "syn: fried, hype: fried\n",
      "syn: fried, hype: fried\n",
      "syn: crazed, hype: crazed\n",
      "syn: crazed, hype: crazed\n",
      "syn: bitty, hype: bitty\n",
      "syn: bitty, hype: bitty\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: bigheaded, hype: bigheaded\n",
      "syn: bigheaded, hype: bigheaded\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n",
      "syn: brassy, hype: brassy\n",
      "syn: brassy, hype: brassy\n",
      "syn: fantastic, hype: fantastic\n",
      "syn: fantastic, hype: fantastic\n",
      "syn: bum, hype: bum\n",
      "syn: bum, hype: bum\n",
      "syn: all_right, hype: all_right\n",
      "syn: all_right, hype: all_right\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: aged, hype: aged\n",
      "syn: aged, hype: aged\n",
      "syn: colossal, hype: colossal\n",
      "syn: colossal, hype: colossal\n",
      "syn: farthermost, hype: farthermost\n",
      "syn: farthermost, hype: farthermost\n",
      "syn: cheery, hype: cheery\n",
      "syn: cheery, hype: cheery\n",
      "syn: ablaze, hype: ablaze\n",
      "syn: ablaze, hype: ablaze\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: cardinal, hype: cardinal\n",
      "syn: cardinal, hype: cardinal\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: awful, hype: awful\n",
      "syn: awful, hype: awful\n",
      "syn: enamored, hype: enamored\n",
      "syn: enamored, hype: enamored\n",
      "syn: apparent, hype: apparent\n",
      "syn: apparent, hype: apparent\n",
      "syn: bitty, hype: bitty\n",
      "syn: bitty, hype: bitty\n",
      "syn: incredible, hype: incredible\n",
      "syn: incredible, hype: incredible\n",
      "syn: favorite, hype: favorite\n",
      "syn: favorite, hype: favorite\n",
      "syn: talented, hype: talented\n",
      "syn: talented, hype: talented\n",
      "syn: far-out, hype: far-out\n",
      "syn: far-out, hype: far-out\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: huge, hype: huge\n",
      "syn: huge, hype: huge\n",
      "syn: instantaneous, hype: instantaneous\n",
      "syn: instantaneous, hype: instantaneous\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: small, hype: small\n",
      "syn: small, hype: small\n",
      "syn: ignored, hype: ignored\n",
      "syn: ignored, hype: ignored\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: large, hype: large\n",
      "syn: large, hype: large\n",
      "syn: null, hype: null\n",
      "syn: null, hype: null\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: coarse, hype: coarse\n",
      "syn: coarse, hype: coarse\n",
      "syn: edgy, hype: edgy\n",
      "syn: edgy, hype: edgy\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: deserving, hype: deserving\n",
      "syn: deserving, hype: deserving\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: aureate, hype: aureate\n",
      "syn: aureate, hype: aureate\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: blue, hype: blue\n",
      "syn: blue, hype: blue\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: cutting, hype: cutting\n",
      "syn: cutting, hype: cutting\n",
      "syn: cunning, hype: cunning\n",
      "syn: cunning, hype: cunning\n",
      "syn: ephemeral, hype: ephemeral\n",
      "syn: ephemeral, hype: ephemeral\n",
      "syn: devilish, hype: devilish\n",
      "syn: devilish, hype: devilish\n",
      "syn: bitty, hype: bitty\n",
      "syn: bitty, hype: bitty\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: extreme, hype: extreme\n",
      "syn: extreme, hype: extreme\n",
      "syn: bally, hype: bally\n",
      "syn: bally, hype: bally\n",
      "syn: curious, hype: curious\n",
      "syn: curious, hype: curious\n",
      "syn: chunky, hype: chunky\n",
      "syn: chunky, hype: chunky\n",
      "syn: chief, hype: chief\n",
      "syn: chief, hype: chief\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: cheery, hype: cheery\n",
      "syn: cheery, hype: cheery\n",
      "syn: jammed, hype: jammed\n",
      "syn: jammed, hype: jammed\n",
      "syn: crisp, hype: crisp\n",
      "syn: crisp, hype: crisp\n",
      "syn: ace, hype: ace\n",
      "syn: ace, hype: ace\n",
      "syn: seventh, hype: seventh\n",
      "syn: seventh, hype: seventh\n",
      "syn: everyday, hype: everyday\n",
      "syn: everyday, hype: everyday\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: apparent, hype: apparent\n",
      "syn: apparent, hype: apparent\n",
      "syn: everyday, hype: everyday\n",
      "syn: everyday, hype: everyday\n",
      "syn: chopped, hype: chopped\n",
      "syn: chopped, hype: chopped\n",
      "syn: baronial, hype: baronial\n",
      "syn: baronial, hype: baronial\n",
      "syn: bronzed, hype: bronzed\n",
      "syn: bronzed, hype: bronzed\n",
      "syn: ill-famed, hype: ill-famed\n",
      "syn: ill-famed, hype: ill-famed\n",
      "syn: deluxe, hype: deluxe\n",
      "syn: deluxe, hype: deluxe\n",
      "syn: diffident, hype: diffident\n",
      "syn: diffident, hype: diffident\n",
      "syn: bigger, hype: bigger\n",
      "syn: bigger, hype: bigger\n",
      "syn: laden, hype: laden\n",
      "syn: laden, hype: laden\n",
      "syn: grey, hype: grey\n",
      "syn: grey, hype: grey\n",
      "syn: religious, hype: religious\n",
      "syn: religious, hype: religious\n",
      "syn: chubby, hype: chubby\n",
      "syn: chubby, hype: chubby\n",
      "syn: bogus, hype: bogus\n",
      "syn: bogus, hype: bogus\n",
      "syn: conceited, hype: conceited\n",
      "syn: conceited, hype: conceited\n",
      "syn: alone, hype: alone\n",
      "syn: alone, hype: alone\n",
      "syn: permanent, hype: permanent\n",
      "syn: permanent, hype: permanent\n",
      "syn: frigid, hype: frigid\n",
      "syn: frigid, hype: frigid\n",
      "syn: all_right, hype: all_right\n",
      "syn: all_right, hype: all_right\n",
      "syn: bogus, hype: bogus\n",
      "syn: bogus, hype: bogus\n",
      "syn: calm, hype: calm\n",
      "syn: calm, hype: calm\n",
      "syn: bare, hype: bare\n",
      "syn: bare, hype: bare\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: enormous, hype: enormous\n",
      "syn: enormous, hype: enormous\n",
      "syn: bushy, hype: bushy\n",
      "syn: bushy, hype: bushy\n",
      "syn: ill, hype: ill\n",
      "syn: ill, hype: ill\n",
      "syn: disgusting, hype: disgusting\n",
      "syn: disgusting, hype: disgusting\n",
      "syn: average, hype: average\n",
      "syn: average, hype: average\n",
      "syn: exclusive, hype: exclusive\n",
      "syn: exclusive, hype: exclusive\n",
      "syn: gay, hype: gay\n",
      "syn: gay, hype: gay\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: cockamamie, hype: cockamamie\n",
      "syn: bare, hype: bare\n",
      "syn: bare, hype: bare\n",
      "syn: eighteenth, hype: eighteenth\n",
      "syn: eighteenth, hype: eighteenth\n",
      "syn: extremist, hype: extremist\n",
      "syn: extremist, hype: extremist\n",
      "syn: cheery, hype: cheery\n",
      "syn: cheery, hype: cheery\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: immaculate, hype: immaculate\n",
      "syn: immaculate, hype: immaculate\n",
      "syn: coincident, hype: coincident\n",
      "syn: coincident, hype: coincident\n",
      "syn: nauseating, hype: nauseating\n",
      "syn: nauseating, hype: nauseating\n",
      "syn: fine-looking, hype: fine-looking\n",
      "syn: fine-looking, hype: fine-looking\n",
      "syn: untrimmed, hype: untrimmed\n",
      "syn: untrimmed, hype: untrimmed\n",
      "syn: bogus, hype: bogus\n",
      "syn: bogus, hype: bogus\n",
      "syn: blasted, hype: blasted\n",
      "syn: blasted, hype: blasted\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: ferocious, hype: ferocious\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: bang-up, hype: bang-up\n",
      "syn: conceited, hype: conceited\n",
      "syn: conceited, hype: conceited\n",
      "syn: fifth, hype: fifth\n",
      "syn: fifth, hype: fifth\n",
      "syn: hairy, hype: hairy\n",
      "syn: hairy, hype: hairy\n",
      "syn: red, hype: red\n",
      "syn: red, hype: red\n",
      "syn: hurt, hype: hurt\n",
      "syn: hurt, hype: hurt\n",
      "syn: entire, hype: entire\n",
      "syn: entire, hype: entire\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: wide, hype: wide\n",
      "syn: wide, hype: wide\n",
      "syn: blond, hype: blond\n",
      "syn: blond, hype: blond\n",
      "syn: ageless, hype: ageless\n",
      "syn: ageless, hype: ageless\n",
      "syn: greek, hype: greek\n",
      "syn: greek, hype: greek\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: dizzy, hype: dizzy\n",
      "syn: boggy, hype: boggy\n",
      "syn: boggy, hype: boggy\n",
      "syn: bantam, hype: bantam\n",
      "syn: bantam, hype: bantam\n",
      "syn: amazing, hype: amazing\n",
      "syn: amazing, hype: amazing\n",
      "syn: conceited, hype: conceited\n",
      "syn: conceited, hype: conceited\n",
      "syn: grim, hype: grim\n",
      "syn: grim, hype: grim\n",
      "syn: adolescent, hype: adolescent\n",
      "syn: adolescent, hype: adolescent\n",
      "syn: everyday, hype: everyday\n",
      "syn: everyday, hype: everyday\n",
      "syn: eighth, hype: eighth\n",
      "syn: eighth, hype: eighth\n",
      "syn: humble, hype: humble\n",
      "syn: humble, hype: humble\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n",
      "syn: classy, hype: classy\n",
      "syn: classy, hype: classy\n",
      "syn: brumous, hype: brumous\n",
      "syn: brumous, hype: brumous\n",
      "syn: charming, hype: charming\n",
      "syn: charming, hype: charming\n",
      "syn: icky, hype: icky\n",
      "syn: icky, hype: icky\n"
     ]
    }
   ],
   "source": [
    "cash_dict = synToHypeDict(casyn,cahype,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is cnsh_dict?  201\n",
      "How big is cash_dict?  118\n"
     ]
    }
   ],
   "source": [
    "print \"How big is cnsh_dict? \", len(cnsh_dict)\n",
    "print \"How big is cash_dict? \", len(cash_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a combined synonym + hypernym vector from a given synonym vector\n",
    "def synVectorToHypeVector(svector,cnsh_dict):    \n",
    "    u = [] # the return vector    \n",
    "        \n",
    "    #loop over the provided vector\n",
    "    for s in svector:\n",
    "        \n",
    "        # initialize v to s\n",
    "        v = s \n",
    "        \n",
    "        # swap out for hypernym if present\n",
    "        if s in cnsh_dict:\n",
    "            v = cnsh_dict[s]\n",
    "\n",
    "        # only add v if not already in u    \n",
    "        if v not in u:\n",
    "            u.append(v) \n",
    "            \n",
    "    return sorted(u) # return sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# work for the noun_vector and adj_hypernym vector columns from corresponding synonym column.\n",
    "def hypernymsFromSynonymVectorCol(syndf,syn_col,hype_col,cnsh_dict):\n",
    "    \n",
    "    hypes = []\n",
    "    \n",
    "    # build the hypernyms    \n",
    "    for r in syndf.iterrows():\n",
    "        syns = r[1][syn_col]\n",
    "        svector = []\n",
    "        \n",
    "        # get words to evaluate into vector form\n",
    "        if not isinstance(syns,float):\n",
    "            svector = syns.split()\n",
    "            \n",
    "        # find hypernyms\n",
    "        hvector = []\n",
    "        if len(svector):\n",
    "            hvector = synVectorToHypeVector(svector,cnsh_dict)\n",
    "        \n",
    "        # hype vector to sentence\n",
    "        h = np.nan\n",
    "        if len(hvector):\n",
    "            h = vectorToStr(hvector)\n",
    "        \n",
    "        # append the sentence to hypes\n",
    "        hypes.append(h)\n",
    "    \n",
    "    # after loop, build a dataframe that adds the column\n",
    "    vdf = pd.DataFrame({hype_col: hypes})\n",
    "    \n",
    "    return syndf.join(vdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_vdf = hypernymsFromSynonymVectorCol(sanvdf.head(50),'noun_syn_vector','noun_syn_hype_vector',cnsh_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 252 ms, sys: 12.1 ms, total: 265 ms\n",
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle noun hypernyms (starting from synonym df above)\n",
    "hnvdf = hypernymsFromSynonymVectorCol(sanvdf,'noun_syn_vector','noun_syn_hype_vector',cnsh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "      <th>noun_syn_hype_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>troubled rough</td>\n",
       "      <td>bridge time water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector  adj_syn_vector noun_syn_hype_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water  troubled rough    bridge time water"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnvdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 241 ms, sys: 4.02 ms, total: 245 ms\n",
      "Wall time: 244 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle adj hypernyms (picking up from hypernym noun df)\n",
    "hanvdf = hypernymsFromSynonymVectorCol(hnvdf,'adj_syn_vector','adj_syn_hype_vector',cash_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "      <th>noun_syn_hype_vector</th>\n",
       "      <th>adj_syn_hype_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>troubled rough</td>\n",
       "      <td>bridge time water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector  adj_syn_vector noun_syn_hype_vector adj_syn_hype_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water  troubled rough    bridge time water      rough troubled"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanvdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Dataframe Augmented with Hypernym Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(hanvdf,\"master-lyricsdf-word_syn_hype_vectors.csv\",root_out=\"../../data/conditioned/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
