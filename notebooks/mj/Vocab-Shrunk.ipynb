{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vocab Shrunk Notebook\n",
    "This notebook will go through a series of shrinking efforts beginning with the noun and adjective reduced vocabs. It will first consider synonyms and the shrinkage effects. It will then work from the initial shrunken result to consider hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to sort dataframe decsending is the default\n",
    "def sortDataframe(df,sort_col,ascending=False):\n",
    "    return df.sort(columns=sort_col, ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoad(json_name,root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading list of list pairs json to columnar dataframe\n",
    "def jsonListOfPairListsToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    keys = []\n",
    "    values = []\n",
    "    for x in j:\n",
    "        keys.append(x[0])\n",
    "        values.append(x[1])\n",
    "        \n",
    "    d = {key_col_label: listAsAscii(keys), val_col_label: listAsAscii(values)}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json dict to csv\n",
    "def jsonDictToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonDictToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                             root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json list of lists containing 2 entries to csv\n",
    "def jsonListOfPairListsToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonListOfPairListsToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                                        root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoadVocabs(json_name):\n",
    "    cvocab = jsonLoad(json_name)\n",
    "    dvocabs = {}\n",
    "    for decade in decades:\n",
    "        # change root in for decade\n",
    "        drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "        dvocabs[decade] = jsonLoad(json_name,root_in=drootin)\n",
    "    \n",
    "    return cvocab, dvocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD VOCABS\n",
    "cnvocab, dnvocabs = jsonLoadVocabs(\"nounvocab.json\")\n",
    "cavocab, davocabs = jsonLoadVocabs(\"adjvocab.json\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun vocab?  5144\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj vocab?  3379\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun vocab? \", len(cnvocab)\n",
    "print \"len decade keys (expect 5) --> \", len(dnvocabs.keys())\n",
    "print \"decade keys()[0] --> \",dnvocabs.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj vocab? \", len(cavocab)\n",
    "print \"len decade keys (expect 5) --> \", len(davocabs.keys())\n",
    "print \"decade keys()[0] --> \",davocabs.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD SYNONYMS\n",
    "cnsyn, dnsyns = jsonLoadVocabs(\"nsyns.json\")\n",
    "casyn, dasyns = jsonLoadVocabs(\"asyns.json\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun syns?  3580\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj syns?  1707\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun syns? \", len(cnsyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dnsyns.keys())\n",
    "print \"decade keys()[0] --> \",dnsyns.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj syns? \", len(casyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dasyns.keys())\n",
    "print \"decade keys()[0] --> \",dasyns.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Shrunken-1: From Vocab Down to Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def synEval(csyn):\n",
    "    u = {}\n",
    "    m = {} #multiples\n",
    "    for k,v in csyn.iteritems():\n",
    "        if v not in u:\n",
    "            u[v] = 1\n",
    "        else:\n",
    "            u[v] += 1  \n",
    "            if v in m:\n",
    "                m[v] += 1\n",
    "            else:\n",
    "                m[v] = 2 #multiples\n",
    "    return u,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  3230\n",
      "How many multiples?  292\n",
      "{u'shop': 2, u'impression': 2, u'bait': 2, u'summer': 2, u'bull': 2, u'urine': 3, u'intuition': 2, u'aroma': 2, u'chink': 2, u'catch': 2, u'fink': 2, u'sleep': 3, u'fillet': 3, u'battle': 2, u'defender': 2, u'speed': 2, u'wage': 3, u'buddy': 2, u'head': 2, u'vibration': 2, u'filth': 2, u'drive': 2, u'pickup': 2, u'pile': 2, u'fad': 2, u'daze': 2, u'crack': 2, u'tune': 2, u'smile': 2, u'criminal': 3, u'hate': 2, u'lookout': 3, u'good': 2, u'hang-up': 2, u'couple': 2, u'material': 2, u'kind': 2, u'clang': 2, u'choice': 3, u'dark': 2, u'lunch': 2, u'spoon': 2, u'buttocks': 4, u'fan': 2, u'breast': 3, u'basement': 2, u'bartender': 2, u'bit': 2, u'jesus': 2, u'twilight': 2, u'day': 2, u'rumor': 2, u'knock': 3, u'die': 2, u'bulge': 2, u'sofa': 3, u'cry': 2, u'freshness': 2, u'morning': 2, u'bag': 3, u'nigger': 2, u'phase': 2, u'macintosh': 2, u'rock': 2, u'guy': 2, u'rear': 2, u'inside': 2, u'draw': 2, u'sweetheart': 2, u'set': 2, u'ailment': 2, u'scheme': 2, u'liquor': 2, u'grandfather': 2, u'idea': 2, u'crop': 2, u'batch': 2, u'hush': 2, u'touch': 2, u'second': 2, u'ball': 3, u'measure': 2, u'pornography': 2, u'dawn': 2, u'disco': 2, u'vicinity': 2, u'concern': 3, u'closer': 2, u'semen': 2, u'palette': 2, u'slice': 2, u'destiny': 2, u'cast': 2, u'movie': 3, u'decision': 2, u'boogie': 2, u'lurch': 2, u'rotter': 3, u'religion': 2, u'state': 3, u'bang': 2, u'internet': 2, u'drunkard': 2, u'fall': 2, u'sorrow': 2, u'pun': 2, u'eating': 2, u'monster': 2, u'degree': 2, u'screen': 2, u'argument': 2, u'component': 2, u'rug': 2, u'killing': 2, u'base': 3, u'pursuit': 2, u'address': 2, u'path': 2, u'beginning': 3, u'avenue': 2, u'barroom': 2, u'promenade': 2, u'sister': 2, u'amour_propre': 2, u'ace': 3, u'package': 2, u'career': 2, u'universe': 2, u'hint': 2, u'girl': 3, u'pace': 2, u'flicker': 2, u'turn': 2, u'magazine': 2, u'nothing': 2, u'aura': 2, u'smoke': 3, u'swing': 2, u'consequence': 2, u'ice_lolly': 2, u'mistake': 2, u'expression': 2, u'plan': 2, u'whitey': 2, u'dunce': 2, u'family': 2, u'point': 2, u'information': 2, u'pot': 4, u'grandma': 2, u'motivation': 2, u'walk': 2, u'cocoa': 2, u'chump': 2, u'seashore': 2, u'laugh': 2, u'ring': 2, u'hood': 3, u'crap': 3, u'fabric': 2, u'jet': 2, u'addition': 2, u'illusion': 2, u'bite': 2, u'waist': 2, u'vacation': 2, u'sunlight': 2, u'mark': 2, u'pool': 2, u'yak': 2, u'spring': 2, u'injury': 2, u'limousine': 2, u'sensitivity': 2, u'dame': 2, u'function': 2, u'life': 3, u'intestine': 2, u'form': 2, u'reverie': 2, u'enchantment': 2, u'thousand': 2, u'frost': 2, u'award': 2, u'cabinet': 2, u'grief': 3, u'heat': 2, u'game': 2, u'adult': 2, u'child': 2, u'baby': 2, u'scribble': 2, u'spirit': 3, u'starter': 2, u'aid': 2, u'past': 2, u'photograph': 2, u'hideout': 2, u'ma': 5, u'ballyhoo': 2, u'eden': 2, u'ecstasy': 2, u'car': 2, u'athlete': 2, u'stroke': 2, u'smasher': 2, u'air': 2, u'matter': 2, u'calamity': 3, u'marriage': 2, u'shingle': 2, u'cab': 3, u'loot': 2, u'root': 2, u'care': 2, u'history': 2, u'dad': 6, u'coconut': 2, u'freak': 2, u'bent': 3, u'telephone': 2, u'fellow': 2, u'dash': 2, u'sphere': 2, u'chap': 4, u'kingdom': 2, u'manner': 5, u'violin': 2, u'airplane': 2, u'shooting': 2, u'pit': 2, u'check': 3, u'bow': 2, u'guarantee': 2, u'cheep': 2, u'microphone': 2, u'wanderer': 2, u'baggage': 2, u'anguish': 2, u'purpose': 3, u'foreigner': 2, u'speaker': 2, u'boom': 4, u'animal': 3, u'miniskirt': 2, u'answer': 2, u'sunset': 2, u'asshole': 4, u'subject': 2, u'panic': 2, u'soap': 2, u'alligator': 2, u'eternity': 2, u'hallway': 2, u'play': 2, u'adieu': 3, u'thunderbolt': 2, u'whirl': 2, u'spot': 2, u'hazard': 2, u'millimeter': 2, u'suburb': 2, u'moment': 2, u'curse': 2, u'kin': 2, u'prisoner': 2, u'coil': 2, u'hair': 2, u'strut': 2, u'opportunity': 2, u'class': 2, u'grave': 2, u'longing': 2, u'land': 2, u'attempt': 3, u'center': 2, u'bullet': 2, u'joint': 2, u'clasp': 3, u'topographic_point': 2, u'doctor': 2, u'drip': 3, u'moonlight': 2, u'person': 3, u'haste': 2, u'shade': 2, u'narrative': 2, u'position': 3, u'menace': 2, u'scream': 2, u'wind': 2, u'bandanna': 2}\n"
     ]
    }
   ],
   "source": [
    "# how many unique noun synonyms\n",
    "n_s, n_ms = synEval(cnsyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(n_s)\n",
    "print \"How many multiples? \", len(n_ms)\n",
    "\n",
    "print n_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  1502\n",
      "How many multiples?  167\n",
      "{u'exclusive': 2, u'brumous': 2, u'diffident': 2, u'bum': 2, u'domestic': 2, u'lavish': 2, u'distant': 2, u'grateful': 2, u'rough': 2, u'religious': 2, u'fifth': 2, u'fit': 2, u'dramatic': 2, u'fitting': 2, u'besotted': 2, u'permanent': 2, u'black': 2, u'bushy': 2, u'bang-up': 4, u'deadly': 2, u'bigheaded': 2, u'cutting': 2, u'dreamy': 2, u'frigid': 2, u'awful': 2, u'farthermost': 2, u'grim': 2, u'bigger': 2, u'entire': 2, u'colored': 3, u'crisp': 4, u'lost': 2, u'large': 2, u'common': 2, u'double': 2, u'popular': 2, u'obscure': 2, u'ignored': 2, u'small': 2, u'colossal': 2, u'eighteenth': 2, u'dead': 2, u'extremist': 2, u'fabulous': 2, u'bare': 5, u'corrupt': 2, u'ablaze': 3, u'divine': 2, u'aroused': 4, u'casual': 2, u'blue': 4, u'bantam': 2, u'ill-famed': 2, u'instantaneous': 2, u'critical': 2, u'bogus': 3, u'crude': 2, u'burned': 2, u'red': 5, u'hairy': 2, u'ferocious': 3, u'sixth': 2, u'seventh': 2, u'broken': 2, u'icky': 4, u'conceited': 3, u'active': 2, u'blasted': 2, u'extreme': 2, u'dry': 2, u'enormous': 2, u'cryptic': 2, u'actual': 2, u'talented': 2, u'ace': 2, u'piquant': 2, u'ill': 2, u'bronzed': 2, u'favorite': 2, u'slender': 2, u'honest': 2, u'sensitive': 2, u'glorious': 2, u'chopped': 2, u'bitty': 3, u'fantastic': 2, u'boggy': 2, u'natural': 2, u'disgusting': 2, u'alone': 3, u'chunky': 2, u'jammed': 2, u'chubby': 2, u'nauseating': 2, u'open': 2, u'nightlong': 2, u'brassy': 2, u'adolescent': 3, u'capable': 2, u'faint': 2, u'lone': 2, u'imperial': 2, u'seasoned': 2, u'calm': 2, u'white': 2, u'immaculate': 2, u'coarse': 2, u'firm': 2, u'barbarous': 3, u'devilish': 2, u'aureate': 2, u'baronial': 2, u'apparent': 3, u'ageless': 4, u'hurt': 2, u'all_right': 3, u'particular': 2, u'consecrated': 2, u'cunning': 2, u'wide': 2, u'graphic': 2, u'bally': 2, u'grey': 3, u'slippery': 2, u'deserving': 2, u'wild': 2, u'fried': 2, u'enamored': 2, u'humble': 2, u'atrocious': 2, u'coincident': 2, u'certain': 2, u'juicy': 2, u'far-out': 2, u'dizzy': 3, u'blond': 2, u'curious': 2, u'null': 2, u'everyday': 3, u'huge': 2, u'aged': 2, u'gay': 2, u'incredible': 2, u'pale': 2, u'ephemeral': 2, u'amazing': 3, u'cardinal': 2, u'amusing': 2, u'difficult': 2, u'fine-looking': 2, u'chancy': 2, u'delicate': 3, u'cheery': 3, u'charming': 3, u'eighth': 2, u'cockamamie': 3, u'elusive': 2, u'untrimmed': 2, u'average': 2, u'laden': 2, u'edgy': 2, u'greek': 2, u'chief': 2, u'crazed': 2, u'classy': 2, u'fresh': 2, u'deluxe': 3}\n"
     ]
    }
   ],
   "source": [
    "# how many unique adj synonyms\n",
    "a_s, a_ms = synEval(casyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(a_s)\n",
    "print \"How many multiples? \", len(a_ms)\n",
    "\n",
    "print a_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WHAT ELSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD HYPERNYMS\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# set up a structure for each\n",
    "ncomp = {}\n",
    "acomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for x in offensives:    \n",
    "    ncomp[x]=[0,0,0,0,0] \n",
    "    \n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for x in offensives:    \n",
    "    ncomp[x]=[0,0,0,0,0] \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
