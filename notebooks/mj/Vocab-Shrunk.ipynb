{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vocab Shrunk Notebook\n",
    "This notebook will go through a series of shrinking efforts beginning with the noun and adjective reduced vocabs. It will first consider synonyms and the shrinkage effects. It will then work from the initial shrunken result to consider hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MLJ: Additional Extras\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decades = [1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root in\n",
    "root_in = \"../../data/conditioned/corpus_vocabs/\"\n",
    "# root out\n",
    "root_out = \"../../viz/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://justgagan.wordpress.com/2010/09/22/python-create-path-or-directories-if-not-exist/\n",
    "def assureDirExists(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure key directories exist\n",
    "assureDirExists(root_in)\n",
    "assureDirExists(root_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to ensure elements in list are ascii\n",
    "def listAsAscii(lst):\n",
    "    return [x.encode('ascii','ignore') if isinstance(x, unicode) else x for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to sort dataframe decsending is the default\n",
    "def sortDataframe(df,sort_col,ascending=False):\n",
    "    return df.sort(columns=sort_col, ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoad(json_name,root_in=root_in):\n",
    "    # read to json\n",
    "    with open(root_in + json_name, 'r') as fp:\n",
    "        j = json.load(fp)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading dictionary json to columnar dataframe\n",
    "def jsonDictToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    d = {key_col_label: listAsAscii(j.keys()), val_col_label: listAsAscii(j.values())}\n",
    "    return pd.DataFrame(data=d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading list of list pairs json to columnar dataframe\n",
    "def jsonListOfPairListsToDataframe(json_name, key_col_label=\"key\", val_col_label=\"value\", root_in=root_in):\n",
    "    \n",
    "    j = jsonLoad(json_name,root_in)\n",
    "    \n",
    "    keys = []\n",
    "    values = []\n",
    "    for x in j:\n",
    "        keys.append(x[0])\n",
    "        values.append(x[1])\n",
    "        \n",
    "    d = {key_col_label: listAsAscii(keys), val_col_label: listAsAscii(values)}\n",
    "    return pd.DataFrame(data=d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for saving dataframe to csv\n",
    "def dataframeToCsv(df, csv_name, root_out=root_out, index=False):\n",
    "    df.to_csv(root_out+csv_name,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json dict to csv\n",
    "def jsonDictToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonDictToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                             root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for json list of lists containing 2 entries to csv\n",
    "def jsonListOfPairListsToCsv(json_name, csv_name, key_col_label=\"key\", val_col_label=\"value\",\n",
    "                  root_in=root_in, root_out=root_out, index=False, sort_col=None):\n",
    "    # json to df\n",
    "    df = jsonListOfPairListsToDataframe(json_name, key_col_label=key_col_label, val_col_label=val_col_label,\n",
    "                                        root_in=root_in)\n",
    "    # handle sort\n",
    "    if sort_col:\n",
    "        df = sortDataframe(df,sort_col)\n",
    "    \n",
    "    # df to csv\n",
    "    dataframeToCsv(df, csv_name, root_out=root_out, index=index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsonLoadVocabs(json_name):\n",
    "    cvocab = jsonLoad(json_name)\n",
    "    dvocabs = {}\n",
    "    for decade in decades:\n",
    "        # change root in for decade\n",
    "        drootin = \"../../data/conditioned/decades/\"+str(decade)+\"/\"\n",
    "        dvocabs[decade] = jsonLoad(json_name,root_in=drootin)\n",
    "    \n",
    "    return cvocab, dvocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a critical function to translate from corpus index to decade index!!!\n",
    "def findIdForWord(word,vocab):\n",
    "    for k,v in vocab:\n",
    "        if v == word:\n",
    "            return k\n",
    "    return -1 # note want to distinguish 0 from None, so using -1 for no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate a column full of a given decades values from a comp\n",
    "def compCol(comp,decade):\n",
    "    didx = decades.index(decade)\n",
    "    vs = []\n",
    "    for k,v in comp.iteritems():\n",
    "        vs.append(v[didx])\n",
    "        \n",
    "    return vs\n",
    "\n",
    "# function to convert comp to dataframe and save\n",
    "def compToDataframe(comp):\n",
    "    d = {'word': listAsAscii(comp.keys())}\n",
    "    \n",
    "    for decade in decades:\n",
    "        d[str(decade)] = compCol(comp,decade)\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD VOCABS\n",
    "cnvocab, dnvocabs = jsonLoadVocabs(\"nounvocab.json\")\n",
    "cavocab, davocabs = jsonLoadVocabs(\"adjvocab.json\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun vocab?  5144\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj vocab?  3379\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun vocab? \", len(cnvocab)\n",
    "print \"len decade keys (expect 5) --> \", len(dnvocabs.keys())\n",
    "print \"decade keys()[0] --> \",dnvocabs.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj vocab? \", len(cavocab)\n",
    "print \"len decade keys (expect 5) --> \", len(davocabs.keys())\n",
    "print \"decade keys()[0] --> \",davocabs.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD ID2WORDS\n",
    "cnid2word, dnid2words = jsonLoadVocabs(\"nounid2word.json\")\n",
    "caid2word, daid2words = jsonLoadVocabs(\"adjid2word.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun id2word?  5144\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj id2word?  3379\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun id2word? \", len(cnid2word)\n",
    "print \"len decade keys (expect 5) --> \", len(dnid2words.keys())\n",
    "print \"decade keys()[0] --> \",dnid2words.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj id2word? \", len(caid2word)\n",
    "print \"len decade keys (expect 5) --> \", len(daid2words.keys())\n",
    "print \"decade keys()[0] --> \",daid2words.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Synonyms\n",
    "**REMEMBER, the individual decade indexing will be different from the master corpus indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the count for each synonym\n",
    "def populateDecadeSyns(comp,decade,tsyn,tid2word):\n",
    "    \n",
    "    # set decade\n",
    "    didx = decades.index(decade)\n",
    "    \n",
    "    # set syns which have k=id, v=synonym\n",
    "    csyn = tsyn[0]\n",
    "    dsyn = tsyn[1][decade]\n",
    "    \n",
    "    # set id2word which have k=id, v=word\n",
    "    cid2word = tid2word[0]\n",
    "    did2word = tid2word[1][decade]\n",
    "    \n",
    "    #loop over corpus syns k=index in id2word, v=synonym\n",
    "    for k,v in csyn.iteritems():\n",
    "        \n",
    "        # attempt to find the id(s) reference of the synonym within `did2word` based on synonym.\n",
    "        # NOTE: this step is necessary as the ids are not matched between corpus and per decade processing\n",
    "        refs = []\n",
    "        for i,s in dsyn.iteritems():\n",
    "            if s == v:\n",
    "                refs.append(i)\n",
    "            \n",
    "        # if the synonym is present at least once in the decade then account for it in comp\n",
    "        if len(refs):            \n",
    "            #print \"for synonym: {}, {} id(s) found in decade {}\".format(v,len(refs),decade)            \n",
    "            # determine counts of synonym in decade\n",
    "            comp[v][didx] = len(refs) \n",
    "    \n",
    "    return comp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnvocab [sycamore]?  4446\n",
      "cnid2word [4446]?  sycamore\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print \"cnvocab ['sycamore']? \",cnvocab['sycamore']\n",
    "print \"cnid2word ['4446']? \",cnid2word['4446']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD SYNONYMS\n",
    "cnsyn, dnsyns = jsonLoadVocabs(\"nsyns.json\")\n",
    "casyn, dasyns = jsonLoadVocabs(\"asyns.json\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big in corpus noun syns?  3580\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n",
      "\n",
      "How big in corpus adj syns?  1707\n",
      "len decade keys (expect 5) -->  5\n",
      "decade keys()[0] -->  2000\n"
     ]
    }
   ],
   "source": [
    "print \"How big in corpus noun syns? \", len(cnsyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dnsyns.keys())\n",
    "print \"decade keys()[0] --> \",dnsyns.keys()[0]\n",
    "print\n",
    "print \"How big in corpus adj syns? \", len(casyn)\n",
    "print \"len decade keys (expect 5) --> \", len(dasyns.keys())\n",
    "print \"decade keys()[0] --> \",dasyns.keys()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Shrunken-1: From Vocab Down to Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def synEval(csyn):\n",
    "    u = {} # build the synonym view\n",
    "    m = {} #multiples\n",
    "    for k,v in csyn.iteritems():\n",
    "        if v not in u:\n",
    "            u[v] = 1\n",
    "        else:\n",
    "            u[v] += 1  \n",
    "            if v in m:\n",
    "                m[v] += 1\n",
    "            else:\n",
    "                m[v] = 2 #multiples\n",
    "    return u,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  3230\n",
      "How many multiples?  292\n",
      "{u'shop': 2, u'impression': 2, u'bait': 2, u'summer': 2, u'bull': 2, u'urine': 3, u'intuition': 2, u'aroma': 2, u'chink': 2, u'catch': 2, u'fink': 2, u'sleep': 3, u'fillet': 3, u'battle': 2, u'defender': 2, u'speed': 2, u'wage': 3, u'buddy': 2, u'head': 2, u'vibration': 2, u'filth': 2, u'drive': 2, u'pickup': 2, u'pile': 2, u'fad': 2, u'daze': 2, u'crack': 2, u'tune': 2, u'smile': 2, u'criminal': 3, u'hate': 2, u'lookout': 3, u'good': 2, u'hang-up': 2, u'couple': 2, u'material': 2, u'kind': 2, u'clang': 2, u'choice': 3, u'dark': 2, u'lunch': 2, u'spoon': 2, u'buttocks': 4, u'fan': 2, u'breast': 3, u'basement': 2, u'bartender': 2, u'bit': 2, u'jesus': 2, u'twilight': 2, u'day': 2, u'rumor': 2, u'knock': 3, u'die': 2, u'bulge': 2, u'sofa': 3, u'cry': 2, u'freshness': 2, u'morning': 2, u'bag': 3, u'nigger': 2, u'phase': 2, u'macintosh': 2, u'rock': 2, u'guy': 2, u'rear': 2, u'inside': 2, u'draw': 2, u'sweetheart': 2, u'set': 2, u'ailment': 2, u'scheme': 2, u'liquor': 2, u'grandfather': 2, u'idea': 2, u'crop': 2, u'batch': 2, u'hush': 2, u'touch': 2, u'second': 2, u'ball': 3, u'measure': 2, u'pornography': 2, u'dawn': 2, u'disco': 2, u'vicinity': 2, u'concern': 3, u'closer': 2, u'semen': 2, u'palette': 2, u'slice': 2, u'destiny': 2, u'cast': 2, u'movie': 3, u'decision': 2, u'boogie': 2, u'lurch': 2, u'rotter': 3, u'religion': 2, u'state': 3, u'bang': 2, u'internet': 2, u'drunkard': 2, u'fall': 2, u'sorrow': 2, u'pun': 2, u'eating': 2, u'monster': 2, u'degree': 2, u'screen': 2, u'argument': 2, u'component': 2, u'rug': 2, u'killing': 2, u'base': 3, u'pursuit': 2, u'address': 2, u'path': 2, u'beginning': 3, u'avenue': 2, u'barroom': 2, u'promenade': 2, u'sister': 2, u'amour_propre': 2, u'ace': 3, u'package': 2, u'career': 2, u'universe': 2, u'hint': 2, u'girl': 3, u'pace': 2, u'flicker': 2, u'turn': 2, u'magazine': 2, u'nothing': 2, u'aura': 2, u'smoke': 3, u'swing': 2, u'consequence': 2, u'ice_lolly': 2, u'mistake': 2, u'expression': 2, u'plan': 2, u'whitey': 2, u'dunce': 2, u'family': 2, u'point': 2, u'information': 2, u'pot': 4, u'grandma': 2, u'motivation': 2, u'walk': 2, u'cocoa': 2, u'chump': 2, u'seashore': 2, u'laugh': 2, u'ring': 2, u'hood': 3, u'crap': 3, u'fabric': 2, u'jet': 2, u'addition': 2, u'illusion': 2, u'bite': 2, u'waist': 2, u'vacation': 2, u'sunlight': 2, u'mark': 2, u'pool': 2, u'yak': 2, u'spring': 2, u'injury': 2, u'limousine': 2, u'sensitivity': 2, u'dame': 2, u'function': 2, u'life': 3, u'intestine': 2, u'form': 2, u'reverie': 2, u'enchantment': 2, u'thousand': 2, u'frost': 2, u'award': 2, u'cabinet': 2, u'grief': 3, u'heat': 2, u'game': 2, u'adult': 2, u'child': 2, u'baby': 2, u'scribble': 2, u'spirit': 3, u'starter': 2, u'aid': 2, u'past': 2, u'photograph': 2, u'hideout': 2, u'ma': 5, u'ballyhoo': 2, u'eden': 2, u'ecstasy': 2, u'car': 2, u'athlete': 2, u'stroke': 2, u'smasher': 2, u'air': 2, u'matter': 2, u'calamity': 3, u'marriage': 2, u'shingle': 2, u'cab': 3, u'loot': 2, u'root': 2, u'care': 2, u'history': 2, u'dad': 6, u'coconut': 2, u'freak': 2, u'bent': 3, u'telephone': 2, u'fellow': 2, u'dash': 2, u'sphere': 2, u'chap': 4, u'kingdom': 2, u'manner': 5, u'violin': 2, u'airplane': 2, u'shooting': 2, u'pit': 2, u'check': 3, u'bow': 2, u'guarantee': 2, u'cheep': 2, u'microphone': 2, u'wanderer': 2, u'baggage': 2, u'anguish': 2, u'purpose': 3, u'foreigner': 2, u'speaker': 2, u'boom': 4, u'animal': 3, u'miniskirt': 2, u'answer': 2, u'sunset': 2, u'asshole': 4, u'subject': 2, u'panic': 2, u'soap': 2, u'alligator': 2, u'eternity': 2, u'hallway': 2, u'play': 2, u'adieu': 3, u'thunderbolt': 2, u'whirl': 2, u'spot': 2, u'hazard': 2, u'millimeter': 2, u'suburb': 2, u'moment': 2, u'curse': 2, u'kin': 2, u'prisoner': 2, u'coil': 2, u'hair': 2, u'strut': 2, u'opportunity': 2, u'class': 2, u'grave': 2, u'longing': 2, u'land': 2, u'attempt': 3, u'center': 2, u'bullet': 2, u'joint': 2, u'clasp': 3, u'topographic_point': 2, u'doctor': 2, u'drip': 3, u'moonlight': 2, u'person': 3, u'haste': 2, u'shade': 2, u'narrative': 2, u'position': 3, u'menace': 2, u'scream': 2, u'wind': 2, u'bandanna': 2}\n"
     ]
    }
   ],
   "source": [
    "# how many unique noun synonyms\n",
    "n_s, n_ms = synEval(cnsyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(n_s)\n",
    "print \"How many multiples? \", len(n_ms)\n",
    "\n",
    "print n_ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This means:**\n",
    "* 3,230 nouns are found within the synset, having valid synonyms, to which we standardized to the first result\n",
    "* 292 synonyms within that result have common_support or shared synonym use. \n",
    "* The remainder of the total 5,144 in the noun vocab set (1,914) are not found in the synset and may potentially be ignored to strengthen subsequent vector analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique nouns (when using synonyms)?  1502\n",
      "How many multiples?  167\n",
      "{u'exclusive': 2, u'brumous': 2, u'diffident': 2, u'bum': 2, u'domestic': 2, u'lavish': 2, u'distant': 2, u'grateful': 2, u'rough': 2, u'religious': 2, u'fifth': 2, u'fit': 2, u'dramatic': 2, u'fitting': 2, u'besotted': 2, u'permanent': 2, u'black': 2, u'bushy': 2, u'bang-up': 4, u'deadly': 2, u'bigheaded': 2, u'cutting': 2, u'dreamy': 2, u'frigid': 2, u'awful': 2, u'farthermost': 2, u'grim': 2, u'bigger': 2, u'entire': 2, u'colored': 3, u'crisp': 4, u'lost': 2, u'large': 2, u'common': 2, u'double': 2, u'popular': 2, u'obscure': 2, u'ignored': 2, u'small': 2, u'colossal': 2, u'eighteenth': 2, u'dead': 2, u'extremist': 2, u'fabulous': 2, u'bare': 5, u'corrupt': 2, u'ablaze': 3, u'divine': 2, u'aroused': 4, u'casual': 2, u'blue': 4, u'bantam': 2, u'ill-famed': 2, u'instantaneous': 2, u'critical': 2, u'bogus': 3, u'crude': 2, u'burned': 2, u'red': 5, u'hairy': 2, u'ferocious': 3, u'sixth': 2, u'seventh': 2, u'broken': 2, u'icky': 4, u'conceited': 3, u'active': 2, u'blasted': 2, u'extreme': 2, u'dry': 2, u'enormous': 2, u'cryptic': 2, u'actual': 2, u'talented': 2, u'ace': 2, u'piquant': 2, u'ill': 2, u'bronzed': 2, u'favorite': 2, u'slender': 2, u'honest': 2, u'sensitive': 2, u'glorious': 2, u'chopped': 2, u'bitty': 3, u'fantastic': 2, u'boggy': 2, u'natural': 2, u'disgusting': 2, u'alone': 3, u'chunky': 2, u'jammed': 2, u'chubby': 2, u'nauseating': 2, u'open': 2, u'nightlong': 2, u'brassy': 2, u'adolescent': 3, u'capable': 2, u'faint': 2, u'lone': 2, u'imperial': 2, u'seasoned': 2, u'calm': 2, u'white': 2, u'immaculate': 2, u'coarse': 2, u'firm': 2, u'barbarous': 3, u'devilish': 2, u'aureate': 2, u'baronial': 2, u'apparent': 3, u'ageless': 4, u'hurt': 2, u'all_right': 3, u'particular': 2, u'consecrated': 2, u'cunning': 2, u'wide': 2, u'graphic': 2, u'bally': 2, u'grey': 3, u'slippery': 2, u'deserving': 2, u'wild': 2, u'fried': 2, u'enamored': 2, u'humble': 2, u'atrocious': 2, u'coincident': 2, u'certain': 2, u'juicy': 2, u'far-out': 2, u'dizzy': 3, u'blond': 2, u'curious': 2, u'null': 2, u'everyday': 3, u'huge': 2, u'aged': 2, u'gay': 2, u'incredible': 2, u'pale': 2, u'ephemeral': 2, u'amazing': 3, u'cardinal': 2, u'amusing': 2, u'difficult': 2, u'fine-looking': 2, u'chancy': 2, u'delicate': 3, u'cheery': 3, u'charming': 3, u'eighth': 2, u'cockamamie': 3, u'elusive': 2, u'untrimmed': 2, u'average': 2, u'laden': 2, u'edgy': 2, u'greek': 2, u'chief': 2, u'crazed': 2, u'classy': 2, u'fresh': 2, u'deluxe': 3}\n"
     ]
    }
   ],
   "source": [
    "# how many unique adj synonyms\n",
    "a_s, a_ms = synEval(casyn)       \n",
    "        \n",
    "print \"How many unique nouns (when using synonyms)? \", len(a_s)\n",
    "print \"How many multiples? \", len(a_ms)\n",
    "\n",
    "print a_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This means:**\n",
    "* 1,502 adjectives are found within the synset, having valid synonyms, to which we standardized to the first result\n",
    "* 167 synonyms within that result have common_support or shared synonym use. \n",
    "* The remainder of the total 1,707 in the noun vocab set (205) are not found in the synset and may potentially be ignored to strengthen subsequent vector analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Viz prep for synonym use\n",
    "* `ascomp` and `nscomp` variables below will hold the presence of synonyms per decade.\n",
    "* will not use `dnsyns` and `dasyns` to avoid indexing confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up a structure for each\n",
    "nscomp = {}\n",
    "ascomp = {}\n",
    "\n",
    "# initialize ncomp to hold all words with 0 value for each decade\n",
    "for k,v in n_s.iteritems():    \n",
    "    nscomp[k]=[0,0,0,0,0] \n",
    "    \n",
    "# initialize acomp to hold all words with 0 value for each decade\n",
    "for k,v in a_s.iteritems():    \n",
    "    ascomp[k]=[0,0,0,0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comp for nouns\n",
    "for d in decades:\n",
    "    nscomp = populateDecadeSyns(nscomp,d,(cnsyn,dnsyns),(cnid2word,dnid2words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inning\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#verify nscomp\n",
    "print nscomp.keys()[0]\n",
    "print nscomp[nscomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comp for adjs\n",
    "for d in decades:\n",
    "    ascomp = populateDecadeSyns(ascomp,d,(casyn,dasyns),(caid2word,daid2words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limited\n",
      "[0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#verify ascomp\n",
    "print ascomp.keys()[0]\n",
    "print ascomp[ascomp.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Synonym Comps to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nscompdf = compToDataframe(nscomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sleet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>obstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nursery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>railing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>appetite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>captain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010         word\n",
       "0     0     0     0     1     0       inning\n",
       "1     1     1     1     1     1       yellow\n",
       "2     0     0     1     0     0        hitch\n",
       "3     1     0     0     0     0        sleet\n",
       "4     0     0     0     1     0  obstruction\n",
       "5     0     0     0     1     0      nursery\n",
       "6     1     1     1     3     1        sleep\n",
       "7     1     0     0     1     0      railing\n",
       "8     1     0     1     1     1     appetite\n",
       "9     0     0     0     1     1      captain"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nscompdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ascompdf = compToDataframe(ascomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sleek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>huffy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ill-famed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>undisputed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>eligible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unanswered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1970  1980  1990  2000  2010        word\n",
       "0     0     0     0     1     1     limited\n",
       "1     0     0     1     1     0     dynamic\n",
       "2     1     1     1     1     1      yellow\n",
       "3     0     0     1     1     0       sleek\n",
       "4     1     1     1     1     1       huffy\n",
       "5     0     0     0     0     1       asian\n",
       "6     0     0     1     2     0   ill-famed\n",
       "7     0     0     1     1     0  undisputed\n",
       "8     0     0     0     1     0    eligible\n",
       "9     0     0     1     0     0  unanswered"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascompdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Synonym Comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nscompdf\n",
    "dataframeToCsv(nscompdf,'noun_decade_comp_synonyms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ascompdf\n",
    "dataframeToCsv(ascompdf,'adj_decade_comp_synonyms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Add synonym column to master Dataframe\n",
    "**This follows from the work in [Vector-Ensemble Notebook](Vector-Ensemble.ipynb). It uses the word vector columns to shorten to synonyms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the latest master lyricsdf\n",
    "vectordf = pd.read_csv(\"../../data/conditioned/master-lyricsdf-word_vectors.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorToStr(vector):\n",
    "    return ' '.join([x.encode('ascii','ignore') if isinstance(x,unicode) else x for x in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a synonym vector from a given word vector\n",
    "def wordVectorToSynVector(wvector,csyn,cid2word):\n",
    "    \n",
    "    svector = []\n",
    "    \n",
    "    #loop over corpus syns k=index in id2word, v=synonym\n",
    "    for k,v in csyn.iteritems():\n",
    "        \n",
    "        #figure out the normal word use for the index\n",
    "        word = cid2word[k]\n",
    "        \n",
    "        #apply the synonym if present in wordvector, \n",
    "        if word and word in wvector:\n",
    "            svector.append(v)\n",
    "            \n",
    "    return svector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# work for the noun_vector and adj_vector columns to build synonyms.\n",
    "def synonymsFromVectorCol(vectordf,vector_col,syn_col,csyn,cid2word):\n",
    "    \n",
    "    syns = []\n",
    "    \n",
    "    # build the synonyms    \n",
    "    for r in vectordf.iterrows():\n",
    "        words = r[1][vector_col]\n",
    "        wvector = []\n",
    "        \n",
    "        # get words to evaluate into vector form\n",
    "        if not isinstance(words,float):\n",
    "            wvector = words.split()\n",
    "            \n",
    "        # find synonyms\n",
    "        svector = []\n",
    "        if len(wvector):\n",
    "            svector = wordVectorToSynVector(wvector,csyn,cid2word)\n",
    "        \n",
    "        # syn vector to sentence\n",
    "        s = np.nan\n",
    "        if len(svector):\n",
    "            s = vectorToStr(svector)\n",
    "        \n",
    "        # append the sentence to syns\n",
    "        syns.append(s)\n",
    "    \n",
    "    # after loop, build a dataframe that adds the column\n",
    "    vdf = pd.DataFrame({syn_col: syns})\n",
    "    \n",
    "    return vectordf.join(vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 0 ns, total: 16.8 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle noun synonyms\n",
    "snvdf = synonymsFromVectorCol(vectordf,'noun_vector','noun_syn_vector',cnsyn,cnid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snvdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.89 s, sys: 0 ns, total: 5.89 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#handle adj synonyms\n",
    "sanvdf = synonymsFromVectorCol(snvdf,'adj_vector','adj_syn_vector',casyn,caid2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>title.href</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>decade</th>\n",
       "      <th>song_key</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics_abstract</th>\n",
       "      <th>noun_vector</th>\n",
       "      <th>adj_vector</th>\n",
       "      <th>noun_syn_vector</th>\n",
       "      <th>adj_syn_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bridge_over_Trou...</td>\n",
       "      <td>Bridge over Troubled Water</td>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970-1</td>\n",
       "      <td>http://lyrics.wikia.com/Simon_And_Garfunkel:Br...</td>\n",
       "      <td>When you're weary. Feeling small. When tears a...</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>rough troubled</td>\n",
       "      <td>time bridge water</td>\n",
       "      <td>troubled rough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  position  year                                         title.href                       title               artist                                             lyrics  decade song_key                                         lyrics_url                                    lyrics_abstract        noun_vector      adj_vector    noun_syn_vector  adj_syn_vector\n",
       "0      0         1  1970  https://en.wikipedia.org/wiki/Bridge_over_Trou...  Bridge over Troubled Water  Simon and Garfunkel  When you're weary. Feeling small. When tears a...    1970   1970-1  http://lyrics.wikia.com/Simon_And_Garfunkel:Br...  When you're weary. Feeling small. When tears a...  time bridge water  rough troubled  time bridge water  troubled rough"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanvdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save Dataframe Augmented with Synonym Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeToCsv(sanvdf,\"master-lyricsdf-word_syn_vectors.csv\",root_out=\"../../data/conditioned/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD HYPERNYMS\n",
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
